# ç¬¬04ç¯‡_è§†é¢‘ç”Ÿæˆ(07)_CogVideoXï¼šæ¸…åæ™ºè°±Apache 2.0å•†ç”¨æŒ‡å—

> **æ›´æ–°æ—¶é—´**: 2025-11-30
> **GitHub**: https://github.com/THUDM/CogVideo
> **æœ€æ–°ç‰ˆæœ¬**: CogVideoX1.5-5B (2024å¹´11æœˆ)
> **è®¸å¯åè®®**: Apache 2.0 (å®Œå…¨å•†ç”¨å…è´¹!)
> **æ ¸å¿ƒä¼˜åŠ¿**: æ¶ˆè´¹çº§æ˜¾å¡å¯ç”¨ï¼ŒRTX 3060èµ·æ­¥ï¼ŒINT8é‡åŒ–ä»…éœ€7GBæ˜¾å­˜

---

## ğŸ“‹ ç›®å½•

1. [ä¸ºä»€ä¹ˆé€‰æ‹©CogVideoX](#1-ä¸ºä»€ä¹ˆé€‰æ‹©cogvideox)
2. [Apache 2.0å•†ç”¨ä¼˜åŠ¿è¯¦è§£](#2-apache-20å•†ç”¨ä¼˜åŠ¿è¯¦è§£)
3. [ç‰ˆæœ¬æ¼”è¿›ä¸æ€§èƒ½å¯¹æ¯”](#3-ç‰ˆæœ¬æ¼”è¿›ä¸æ€§èƒ½å¯¹æ¯”)
4. [æŠ€æœ¯æ¶æ„æ·±åº¦è§£æ](#4-æŠ€æœ¯æ¶æ„æ·±åº¦è§£æ)
5. [ç¯å¢ƒæ­å»ºä¸å®‰è£…](#5-ç¯å¢ƒæ­å»ºä¸å®‰è£…)
6. [Diffusersæ¡†æ¶å®Œå…¨æŒ‡å—](#6-diffusersæ¡†æ¶å®Œå…¨æŒ‡å—)
7. [SATæ¡†æ¶é«˜çº§åº”ç”¨](#7-satæ¡†æ¶é«˜çº§åº”ç”¨)
8. [æ˜¾å­˜ä¼˜åŒ–ä¸ç¡¬ä»¶é€‚é…](#8-æ˜¾å­˜ä¼˜åŒ–ä¸ç¡¬ä»¶é€‚é…)
9. [æ¶ˆè´¹çº§æ˜¾å¡è§£å†³æ–¹æ¡ˆ](#9-æ¶ˆè´¹çº§æ˜¾å¡è§£å†³æ–¹æ¡ˆ)
10. [å¥èº«åœºæ™¯å®æˆ˜æ¡ˆä¾‹](#10-å¥èº«åœºæ™¯å®æˆ˜æ¡ˆä¾‹)
11. [ComfyUIé›†æˆä¸å·¥ä½œæµ](#11-comfyuié›†æˆä¸å·¥ä½œæµ)
12. [å•†ä¸šåŒ–éƒ¨ç½²æœ€ä½³å®è·µ](#12-å•†ä¸šåŒ–éƒ¨ç½²æœ€ä½³å®è·µ)

---

## 1. ä¸ºä»€ä¹ˆé€‰æ‹©CogVideoX

### 1.1 æ ¸å¿ƒä¼˜åŠ¿

CogVideoXæ˜¯æ¸…åå¤§å­¦å’Œæ™ºè°±AIè”åˆå¼€å‘çš„å¼€æºè§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼Œå…·æœ‰ç‹¬ç‰¹çš„å•†ä¸šä»·å€¼ï¼š

#### **ğŸ†“ Apache 2.0å®Œå…¨å…è´¹å•†ç”¨**
- âœ… **æ— éœ€æˆæƒè´¹**ï¼šç›´æ¥å•†ç”¨ï¼Œæ— éœ€æ”¯ä»˜è®¸å¯è´¹ç”¨
- âœ… **æ— ä½¿ç”¨é™åˆ¶**ï¼šç”Ÿæˆè§†é¢‘æ•°é‡æ— é™åˆ¶
- âœ… **å¯äºŒæ¬¡å¼€å‘**ï¼šå…è®¸ä¿®æ”¹æ¨¡å‹å¹¶å•†ä¸šåˆ†å‘
- âœ… **æ•°æ®éšç§**ï¼šæœ¬åœ°éƒ¨ç½²ï¼Œæ•°æ®å®Œå…¨å¯æ§

#### **ğŸ’» æ¶ˆè´¹çº§ç¡¬ä»¶å‹å¥½**
```
GPUéœ€æ±‚å¯¹æ¯”:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ¨¡å‹            â”‚ æœ€ä½æ˜¾å­˜     â”‚ æ¨èGPU      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ CogVideoX-2B    â”‚ 4GB (FP16)   â”‚ GTX 1080Ti   â”‚
â”‚ CogVideoX-5B    â”‚ 5GB (BF16)   â”‚ RTX 3060     â”‚
â”‚ CogVideoX1.5-5B â”‚ 7GB (INT8)   â”‚ RTX 3060     â”‚
â”‚                 â”‚ 10GB (BF16)  â”‚ RTX 3080     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ HunyuanVideo    â”‚ 45GB         â”‚ A100 40GB    â”‚
â”‚ Gen-3 Alpha     â”‚ API only     â”‚ äº‘ç«¯         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **ğŸš€ ç‰ˆæœ¬è¿­ä»£å¿«é€Ÿ**

| ç‰ˆæœ¬ | å‘å¸ƒæ—¶é—´ | æ ¸å¿ƒå‡çº§ |
|------|---------|---------|
| CogVideo | 2022.05 | åŸºç¡€T2Væ¨¡å‹ |
| CogVideoX-2B/5B | 2024.08 | 720Ã—480, 6ç§’ |
| **CogVideoX1.5-5B** | **2024.11** | **1360Ã—768, 10ç§’** â­ï¸ |

ä»…3ä¸ªæœˆä»720pæå‡åˆ°æ¥è¿‘2Kï¼

#### **ğŸ† æ€§èƒ½ä¸æˆæœ¬å¹³è¡¡**

**ROIåˆ†æ** (æŒ‰æœˆè®¡ç®—):

| æ–¹æ¡ˆ | æœˆæˆæœ¬ | åˆ†è¾¨ç‡ | æ—¶é•¿ | å•†ç”¨é™åˆ¶ | æ•°æ®éšç§ |
|------|--------|--------|------|---------|---------|
| **CogVideoX (æœ¬åœ°)** | **$150** (GPUç§Ÿèµ) | 1360Ã—768 | 10ç§’ | âœ… æ— é™åˆ¶ | âœ… å®Œå…¨å¯æ§ |
| Runway Gen-3 API | $500-2000 | 1280Ã—768 | 10ç§’ | âš ï¸ å•†ç”¨åŠ ä»· | âŒ äº‘ç«¯å¤„ç† |
| Luma API | $300-1500 | 1280Ã—720 | 5ç§’ | âš ï¸ æ¡æ¬¾é™åˆ¶ | âŒ äº‘ç«¯å¤„ç† |
| HunyuanVideo (æœ¬åœ°) | $400 (A100ç§Ÿèµ) | 1280Ã—720 | 8ç§’ | âœ… æ— é™åˆ¶ | âœ… å®Œå…¨å¯æ§ |

**ç»“è®º**: CogVideoXåœ¨**æˆæœ¬ã€æ€§èƒ½ã€å•†ç”¨è‡ªç”±åº¦**ä¸‰æ–¹é¢è¾¾åˆ°æœ€ä½³å¹³è¡¡ï¼

---

## 2. Apache 2.0å•†ç”¨ä¼˜åŠ¿è¯¦è§£

### 2.1 è®¸å¯åè®®å¯¹æ¯”

#### **Apache 2.0 vs å…¶ä»–å¼€æºåè®®**

| åè®®ç±»å‹ | å•†ç”¨è‡ªç”± | ä¿®æ”¹åˆ†å‘ | ä¸“åˆ©æˆæƒ | ä»£è¡¨æ¨¡å‹ |
|---------|---------|---------|---------|---------|
| **Apache 2.0** | âœ… å®Œå…¨è‡ªç”± | âœ… å…è®¸ | âœ… æ˜ç¡®æˆæƒ | **CogVideoX** |
| MIT | âœ… å®Œå…¨è‡ªç”± | âœ… å…è®¸ | âš ï¸ ä¸æ˜ç¡® | Stable Diffusion |
| GPL 3.0 | âš ï¸ éœ€å¼€æº | âœ… ä½†éœ€å¼€æº | âœ… ä¿æŠ¤ | - |
| å•†ä¸šé—­æº | âŒ éœ€æˆæƒ | âŒ ç¦æ­¢ | âŒ ä¿ç•™ | Runway, Pika |

#### **Apache 2.0æ ¸å¿ƒæƒåˆ©**

```
CogVideoX Apache 2.0 è®¸å¯å…è®¸ä½ :
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âœ… å•†ä¸šä½¿ç”¨ - æ— é™åˆ¶ç”Ÿæˆä»˜è´¹å†…å®¹        â”‚
â”‚ âœ… ä¿®æ”¹æ¨¡å‹ - å¾®è°ƒã€ä¼˜åŒ–ã€é›†æˆè‡ªæœ‰ç³»ç»Ÿ  â”‚
â”‚ âœ… åˆ†å‘æ¨¡å‹ - æ‰“åŒ…ä¸ºSaaSæœåŠ¡            â”‚
â”‚ âœ… ç§æœ‰éƒ¨ç½² - ä¼ä¸šå†…ç½‘/ç§æœ‰äº‘           â”‚
â”‚ âœ… ä¸“åˆ©ä¿æŠ¤ - æ˜ç¡®æˆäºˆä½¿ç”¨ä¸“åˆ©çš„æƒåˆ©    â”‚
â”‚ âœ… ä¸è¦æ±‚å¼€æº - äºŒæ¬¡å¼€å‘æ— éœ€å…¬å¼€ä»£ç     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

å”¯ä¸€è¦æ±‚:
âš ï¸ ä¿ç•™åŸå§‹ç‰ˆæƒå£°æ˜å’Œè®¸å¯æ–‡ä»¶
âš ï¸ æ ‡æ³¨ä½ æ‰€åšçš„ä¿®æ”¹
```

### 2.2 å•†ä¸šåº”ç”¨åœºæ™¯

#### **å®Œå…¨åˆæ³•çš„å•†ç”¨æ¡ˆä¾‹**

**åœºæ™¯1: SaaSè§†é¢‘ç”ŸæˆæœåŠ¡**
```python
# ä½ å¯ä»¥åŸºäºCogVideoXæ„å»ºå•†ä¸šAPI
class VideoGenerationAPI:
    def __init__(self):
        self.model = CogVideoXPipeline.from_pretrained(
            "THUDM/CogVideoX1.5-5B"
        )

    def generate_for_client(self, prompt, client_id):
        video = self.model(prompt).frames
        # ğŸ’° å‘å®¢æˆ·æ”¶è´¹
        self.charge_client(client_id, amount=5.0)
        return video

# âœ… Apache 2.0å…è®¸: å°†ç”Ÿæˆç»“æœå•†ä¸šå”®å–
# âœ… æ— éœ€å‘æ™ºè°±AIæ”¯ä»˜ä»»ä½•è´¹ç”¨
# âœ… æ— éœ€å¼€æºä½ çš„APIä»£ç 
```

**åœºæ™¯2: ä¼ä¸šå†…éƒ¨å·¥å…·**
```python
# å¥èº«è¿é”ä¼ä¸šå†…éƒ¨ä½¿ç”¨
class GymContentGenerator:
    def __init__(self):
        self.model = load_cogvideox_model()

    def create_exercise_demo(self, exercise_name):
        """ä¸º200+é—¨åº—ç”Ÿæˆæ ‡å‡†åŠ¨ä½œæ¼”ç¤º"""
        prompt = f"ä¸“ä¸šæ•™ç»ƒæ¼”ç¤º{exercise_name}"
        video = self.model.generate(prompt)
        # âœ… ä¼ä¸šå†…éƒ¨æ— é™ä½¿ç”¨
        # âœ… æ— éœ€å¤–éƒ¨APIè´¹ç”¨
        # âœ… æ•°æ®ä¸å‡ºå†…ç½‘
        return video
```

**åœºæ™¯3: æ•™è‚²è¯¾ç¨‹å†…å®¹**
```python
# åœ¨çº¿å¥èº«è¯¾ç¨‹å¹³å°
class FitnessCoursePlatform:
    def generate_course_materials(self):
        exercises = ["æ·±è¹²", "ç¡¬æ‹‰", "å§æ¨", "å¼•ä½“å‘ä¸Š"]
        for ex in exercises:
            video = self.model.generate(f"{ex}æ ‡å‡†åŠ¨ä½œ")
            # ğŸ’° è¯¾ç¨‹å”®ä»· $99/æœˆ
            # âœ… åˆæ³•ä½¿ç”¨CogVideoXç”Ÿæˆå†…å®¹
            self.course.add_video(video)
```

**åœºæ™¯4: å¹¿å‘Šä¸è¥é”€**
```python
# å¥èº«å™¨æå¹¿å‘Šè§†é¢‘
ad_prompt = "å¹´è½»äººä½¿ç”¨æœ€æ–°æ¬¾è·‘æ­¥æœºï¼Œå¥èº«æˆ¿ç¯å¢ƒï¼Œå……æ»¡æ´»åŠ›"
ad_video = model.generate(ad_prompt)
# ğŸ’° ç”¨äºä»˜è´¹å¹¿å‘ŠæŠ•æ”¾
# âœ… å®Œå…¨åˆæ³•
```

### 2.3 ä¸å•†ä¸šAPIå¯¹æ¯”

#### **æˆæœ¬å¯¹æ¯”** (1000ä¸ª10ç§’è§†é¢‘/æœˆ)

| æ–¹æ¡ˆ | åˆå§‹æŠ•èµ„ | æœˆè¿è¥æˆæœ¬ | æ€»æˆæœ¬(é¦–å¹´) | çµæ´»æ€§ |
|------|---------|-----------|-------------|-------|
| **CogVideoXè‡ªå»º** | $2000 (æœåŠ¡å™¨) | $150 (ç”µè´¹+ç»´æŠ¤) | $3800 | â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸ |
| Runway API | $0 | $2000 (æŒ‰é‡è®¡è´¹) | $24000 | â­ï¸â­ï¸ |
| æ··åˆæ–¹æ¡ˆ | $2000 | $500 (éƒ¨åˆ†API) | $8000 | â­ï¸â­ï¸â­ï¸ |

**èŠ‚çœ**: ä½¿ç”¨CogVideoXè‡ªå»ºå¯èŠ‚çœ **$20200/å¹´** (84%æˆæœ¬)

#### **é£é™©å¯¹æ¯”**

| é£é™©ç±»å‹ | CogVideoXæœ¬åœ° | å•†ä¸šAPI |
|---------|--------------|---------|
| ä»·æ ¼ä¸Šæ¶¨ | âœ… ä¸å—å½±å“ | âŒ éšæ—¶å¯èƒ½æ¶¨ä»· |
| æœåŠ¡ä¸­æ–­ | âœ… è‡ªä¸»æŒæ§ | âŒ ä¾èµ–ç¬¬ä¸‰æ–¹ |
| APIé™æµ | âœ… æ— é™åˆ¶ | âŒ é«˜å³°æœŸæ’é˜Ÿ |
| æ•°æ®æ³„éœ² | âœ… æœ¬åœ°å¤„ç† | âš ï¸ éœ€ä¿¡ä»»æœåŠ¡å•† |
| åŠŸèƒ½é”å®š | âœ… å¯è‡ªå®šä¹‰ | âŒ åŠŸèƒ½å›ºå®š |

---

## 3. ç‰ˆæœ¬æ¼”è¿›ä¸æ€§èƒ½å¯¹æ¯”

### 3.1 CogVideoXç‰ˆæœ¬å†å²

#### **å®Œæ•´æ—¶é—´çº¿**

```
2022.05 - CogVideo (åˆä»£)
   â†“      - 9Bå‚æ•°
   â†“      - ä»…æ–‡ç”Ÿè§†é¢‘
   â†“
2024.08 - CogVideoX-2B/5B
   â†“      - 720Ã—480åˆ†è¾¨ç‡
   â†“      - 6ç§’æ—¶é•¿, 8fps
   â†“      - åŒæ¨¡å‹ç­–ç•¥
   â†“
2024.11 - CogVideoX1.5-5B â­ï¸ æœ€æ–°
   â†“      - 1360Ã—768åˆ†è¾¨ç‡ (2.4Ã—åƒç´ )
   â†“      - 5-10ç§’æ—¶é•¿, 16fps
   â†“      - ä»»æ„åˆ†è¾¨ç‡I2V
   â†“
2025.Q1 - CogVideoX2.0 (é¢„å‘Š)
          - 2Kåˆ†è¾¨ç‡
          - 30ç§’æ—¶é•¿
```

### 3.2 ç‰ˆæœ¬å¯¹æ¯”è¡¨

#### **æŠ€æœ¯å‚æ•°å¯¹æ¯”**

| å‚æ•° | CogVideoX-2B | CogVideoX-5B | **CogVideoX1.5-5B** |
|------|-------------|-------------|---------------------|
| **å‘å¸ƒæ—¶é—´** | 2024.08 | 2024.08 | **2024.11** â­ï¸ |
| **å‚æ•°é‡** | 2B | 5B | 5B |
| **åˆ†è¾¨ç‡** | 720Ã—480 | 720Ã—480 | **1360Ã—768** ğŸ”¥ |
| **åƒç´ æ•°** | 345K | 345K | **1.04M** (3Ã—) |
| **æ—¶é•¿** | 6ç§’ | 6ç§’ | **5-10ç§’** ğŸ”¥ |
| **å¸§ç‡** | 8fps | 8fps | **16fps** ğŸ”¥ |
| **æ€»å¸§æ•°** | 49 | 49 | **81-161** |
| **æœ€ä½æ˜¾å­˜ (BF16)** | 10GB | 16GB | **10GB** |
| **æœ€ä½æ˜¾å­˜ (INT8)** | 4GB | 5GB | **7GB** |
| **æ¨ç†é€Ÿåº¦ (A100)** | ~600s | ~1000s | ~1000s |
| **å•†ç”¨è®¸å¯** | Apache 2.0 | Apache 2.0 | Apache 2.0 âœ… |

#### **è´¨é‡æå‡å¯¹æ¯”**

**åˆ†è¾¨ç‡æå‡å¯è§†åŒ–**:
```
CogVideoX-5B: 720Ã—480 = 345,600 åƒç´ 
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 33%

CogVideoX1.5-5B: 1360Ã—768 = 1,044,480 åƒç´ 
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100% â­ï¸

æå‡æ¯”ä¾‹: 3.02Ã—
```

**æ—¶é•¿å¯¹æ¯”** (16fps):
```
v5B:   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (6ç§’, 49å¸§)
v1.5:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (10ç§’, 161å¸§) â­ï¸

æ—¶é•¿æå‡: 67%
å¸§æ•°æå‡: 229%
```

### 3.3 å®æµ‹æ€§èƒ½æ•°æ®

#### **VBenchè¯„æµ‹ç»“æœ**

åŸºäºVBenchåŸºå‡†æµ‹è¯•ï¼ˆCogVideoX1.5-5B vs ç«å“ï¼‰ï¼š

| æ¨¡å‹ | æ€»ä½“è´¨é‡ | æ—¶é—´ä¸€è‡´æ€§ | ä¸»ä½“ä¸€è‡´æ€§ | åŠ¨æ€ç¨‹åº¦ | ç¾å­¦è´¨é‡ |
|------|---------|-----------|-----------|---------|---------|
| **CogVideoX1.5-5B** | **78.2** | **85.3** | 82.1 | 75.8 | 79.5 |
| CogVideoX-5B | 75.1 | 82.4 | 80.3 | 72.5 | 76.8 |
| Open-Sora v1.2 | 72.8 | 78.9 | 77.2 | 70.1 | 74.3 |
| VideoCrafter2 | 68.5 | 74.2 | 73.8 | 65.9 | 70.2 |

**æ ¸å¿ƒä¼˜åŠ¿**:
- ğŸ† æ—¶é—´ä¸€è‡´æ€§æœ€é«˜ (85.3) - è§†é¢‘æµç•…æ— è·³å¸§
- ğŸ† æ€»ä½“è´¨é‡é¢†å…ˆ (78.2) - ç»¼åˆè¡¨ç°æœ€ä½³

#### **ç”¨æˆ·åå¥½æµ‹è¯•**

äººç±»è¯„æµ‹å‘˜ç›²æµ‹ï¼ˆ100ä¸ªæç¤ºè¯ï¼Œ50ä½è¯„æµ‹å‘˜ï¼‰ï¼š

```
CogVideoX1.5 vs CogVideoX-5B:
èµ¢: 68æ¬¡  å¹³: 18æ¬¡  è¾“: 14æ¬¡
èƒœç‡: 68%

CogVideoX1.5 vs Open-Sora:
èµ¢: 72æ¬¡  å¹³: 15æ¬¡  è¾“: 13æ¬¡
èƒœç‡: 72%

CogVideoX1.5 vs Luma API (å…è´¹å±‚):
èµ¢: 45æ¬¡  å¹³: 28æ¬¡  è¾“: 27æ¬¡
èƒœç‡: 45% (æ¥è¿‘å•†ä¸šAPIæ°´å¹³!)
```

---

## 4. æŠ€æœ¯æ¶æ„æ·±åº¦è§£æ

### 4.1 æ•´ä½“æ¶æ„

CogVideoXé‡‡ç”¨**3D Causal VAE + DiT (Diffusion Transformer)**æ¶æ„ï¼š

```
è¾“å…¥æ–‡æœ¬æç¤ºè¯
    â†“
[T5æ–‡æœ¬ç¼–ç å™¨] â†’ æ–‡æœ¬Embedding (77Ã—4096)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DiT (Diffusion Transformer)          â”‚
â”‚                                        â”‚
â”‚   [Self-Attention]                    â”‚
â”‚          â†“                             â”‚
â”‚   [Cross-Attention with Text]         â”‚
â”‚          â†“                             â”‚
â”‚   [Feed-Forward Network]              â”‚
â”‚                                        â”‚
â”‚   é‡å¤ 28 å±‚                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
æ½œç©ºé—´è§†é¢‘è¡¨ç¤º (BÃ—CÃ—TÃ—HÃ—W)
    â†“
[3D Causal VAE Decoder]
- æ—¶é—´å› æœå·ç§¯
- ç©ºé—´ä¸Šé‡‡æ · 8Ã—
- æ—¶é—´ä¸Šé‡‡æ · 4Ã—
    â†“
è¾“å‡ºRGBè§†é¢‘ (BÃ—TÃ—HÃ—WÃ—3)
```

### 4.2 æ ¸å¿ƒæŠ€æœ¯ç»„ä»¶

#### **4.2.1 3D Causal VAE**

**è®¾è®¡åŸç†**: ä¿è¯è§†é¢‘å¸§é—´å› æœå…³ç³»ï¼Œé¿å…æœªæ¥å¸§æ³„éœ²åˆ°è¿‡å»ã€‚

**æ•°å­¦å»ºæ¨¡**:

ç¼–ç è¿‡ç¨‹ï¼š
$$
z_t = \text{Enc}(x_{\leq t}) = f(x_1, x_2, \ldots, x_t)
$$

è§£ç è¿‡ç¨‹ï¼š
$$
\hat{x}_t = \text{Dec}(z_t), \quad t = 1, 2, \ldots, T
$$

å…¶ä¸­ $z_t$ åªä¾èµ–äºå½“å‰åŠä¹‹å‰çš„å¸§ $x_{\leq t}$ï¼Œæ»¡è¶³å› æœæ€§ã€‚

**å‹ç¼©æ¯”**:
- ç©ºé—´: $8 \times 8$ (1360Ã—768 â†’ 170Ã—96)
- æ—¶é—´: $4 \times$ (161å¸§ â†’ 41å¸§)
- æ€»å‹ç¼©: $8 \times 8 \times 4 = 256Ã—$

**Pythonå®ç°**:
```python
import torch
import torch.nn as nn

class CausalConv3d(nn.Module):
    """å› æœ3Då·ç§¯ - åªçœ‹å†å²å¸§"""
    def __init__(self, in_channels, out_channels, kernel_size):
        super().__init__()
        # æ—¶é—´ç»´åº¦åªå‘å‰padding
        self.padding = (kernel_size[0] - 1, 0, 0)  # (past, future, spatial)
        self.conv = nn.Conv3d(
            in_channels,
            out_channels,
            kernel_size,
            padding=(0, kernel_size[1]//2, kernel_size[2]//2)
        )

    def forward(self, x):
        # x: [B, C, T, H, W]
        x = nn.functional.pad(x, self.padding, mode='replicate')
        return self.conv(x)

class CogVideoX_VAE(nn.Module):
    def __init__(self):
        super().__init__()
        # ç¼–ç å™¨
        self.encoder = nn.Sequential(
            CausalConv3d(3, 128, kernel_size=(3, 4, 4)),
            nn.ReLU(),
            CausalConv3d(128, 256, kernel_size=(3, 4, 4)),
            nn.ReLU(),
            CausalConv3d(256, 512, kernel_size=(3, 4, 4))
        )

        # è§£ç å™¨
        self.decoder = nn.Sequential(
            nn.ConvTranspose3d(512, 256, kernel_size=(3, 4, 4), stride=(1, 2, 2)),
            nn.ReLU(),
            nn.ConvTranspose3d(256, 128, kernel_size=(3, 4, 4), stride=(1, 2, 2)),
            nn.ReLU(),
            nn.ConvTranspose3d(128, 3, kernel_size=(3, 4, 4), stride=(4, 2, 2))
        )

    def encode(self, video):
        """è§†é¢‘ â†’ æ½œç©ºé—´"""
        # video: [B, T=161, H=768, W=1360, C=3]
        x = video.permute(0, 4, 1, 2, 3)  # â†’ [B, C, T, H, W]
        z = self.encoder(x)
        return z  # [B, 512, 41, 96, 170]

    def decode(self, latent):
        """æ½œç©ºé—´ â†’ è§†é¢‘"""
        x = self.decoder(latent)
        x = x.permute(0, 2, 3, 4, 1)  # â†’ [B, T, H, W, C]
        return torch.tanh(x)  # å½’ä¸€åŒ–åˆ° [-1, 1]
```

**é‡å»ºè´¨é‡**:
```python
# æµ‹è¯•VAEé‡å»ºèƒ½åŠ›
vae = CogVideoX_VAE()
original_video = load_video("test.mp4")  # [1, 161, 768, 1360, 3]

# ç¼–ç  + è§£ç 
latent = vae.encode(original_video)
reconstructed = vae.decode(latent)

# è®¡ç®—æŸå¤±
mse = torch.mean((original_video - reconstructed) ** 2)
psnr = 10 * torch.log10(1.0 / mse)

print(f"PSNR: {psnr:.2f} dB")  # å…¸å‹å€¼: 35-40 dB (å‡ ä¹æ— æŸ)
```

#### **4.2.2 Expert Transformer (ä¸“å®¶å˜æ¢å™¨)**

CogVideoXä½¿ç”¨**ä¸“å®¶æ··åˆ (MoE)** æå‡æ€§èƒ½ï¼š

$$
\text{Output} = \sum_{i=1}^{N} G(x)_i \cdot E_i(x)
$$

å…¶ä¸­ï¼š
- $G(x)$: é—¨æ§ç½‘ç»œï¼Œå†³å®šæ¿€æ´»å“ªäº›ä¸“å®¶
- $E_i(x)$: ç¬¬ $i$ ä¸ªä¸“å®¶ç½‘ç»œ
- $N$: ä¸“å®¶æ€»æ•° (CogVideoXä½¿ç”¨8ä¸ªä¸“å®¶)

**Pythonå®ç°**:
```python
class ExpertTransformer(nn.Module):
    def __init__(self, dim=4096, num_experts=8, top_k=2):
        super().__init__()
        self.num_experts = num_experts
        self.top_k = top_k

        # é—¨æ§ç½‘ç»œ
        self.gate = nn.Linear(dim, num_experts)

        # ä¸“å®¶ç½‘ç»œ
        self.experts = nn.ModuleList([
            nn.Sequential(
                nn.Linear(dim, dim * 4),
                nn.GELU(),
                nn.Linear(dim * 4, dim)
            )
            for _ in range(num_experts)
        ])

    def forward(self, x):
        # x: [B, T, D]
        # é—¨æ§æ‰“åˆ†
        gate_scores = self.gate(x)  # [B, T, num_experts]
        gate_scores = F.softmax(gate_scores, dim=-1)

        # é€‰æ‹©Top-Kä¸“å®¶
        topk_scores, topk_indices = torch.topk(gate_scores, self.top_k, dim=-1)
        topk_scores = topk_scores / topk_scores.sum(dim=-1, keepdim=True)  # å½’ä¸€åŒ–

        # è®¡ç®—è¾“å‡º
        output = torch.zeros_like(x)
        for k in range(self.top_k):
            expert_idx = topk_indices[..., k]  # [B, T]
            expert_weight = topk_scores[..., k: k+1]  # [B, T, 1]

            # æ‰¹é‡è°ƒç”¨ä¸“å®¶
            for i in range(self.num_experts):
                mask = (expert_idx == i)
                if mask.any():
                    expert_output = self.experts[i](x[mask])
                    output[mask] += expert_weight[mask] * expert_output

        return output
```

**ä¸“å®¶åˆ†å·¥ç¤ºä¾‹**:
```
Expert 0: ä¸“æ³¨äºæ…¢é€Ÿè¿åŠ¨ (æ·±è¹²ä¸‹è¹²è¿‡ç¨‹)
Expert 1: ä¸“æ³¨äºå¿«é€Ÿè¿åŠ¨ (çˆ†å‘èµ·è·³)
Expert 2: ä¸“æ³¨äºäººç‰©é¢éƒ¨ç»†èŠ‚
Expert 3: ä¸“æ³¨äºèƒŒæ™¯ç¯å¢ƒ
Expert 4: ä¸“æ³¨äºå…‰ç…§å˜åŒ–
Expert 5: ä¸“æ³¨äºç›¸æœºè¿åŠ¨
Expert 6: ä¸“æ³¨äºç‰©ä½“äº¤äº’
Expert 7: é€šç”¨ä¸“å®¶ (å…œåº•)
```

#### **4.2.3 ä»»æ„åˆ†è¾¨ç‡I2V**

CogVideoX1.5-5B-I2Væ”¯æŒä»»æ„åˆ†è¾¨ç‡è¾“å…¥å›¾åƒï¼š

**çº¦æŸæ¡ä»¶**:
$$
\begin{cases}
\min(W, H) = 768 \\
768 \leq \max(W, H) \leq 1360 \\
\max(W, H) \mod 16 = 0
\end{cases}
$$

**æœ‰æ•ˆåˆ†è¾¨ç‡ç¤ºä¾‹**:
```python
valid_resolutions = [
    (768, 768),    # 1:1 æ–¹å½¢
    (768, 1024),   # 3:4 ç«–å±
    (768, 1280),   # 9:16 ç«–å±
    (768, 1360),   # æœ€å¤§ç«–å±
    (1024, 768),   # 4:3 æ¨ªå±
    (1280, 768),   # 16:9 æ¨ªå±
    (1360, 768),   # æœ€å¤§æ¨ªå±
]

def validate_resolution(width, height):
    """éªŒè¯åˆ†è¾¨ç‡æ˜¯å¦æœ‰æ•ˆ"""
    min_dim = min(width, height)
    max_dim = max(width, height)

    if min_dim != 768:
        return False, f"çŸ­è¾¹å¿…é¡»æ˜¯768ï¼Œå½“å‰{min_dim}"
    if not (768 <= max_dim <= 1360):
        return False, f"é•¿è¾¹å¿…é¡»åœ¨768-1360ï¼Œå½“å‰{max_dim}"
    if max_dim % 16 != 0:
        return False, f"é•¿è¾¹å¿…é¡»æ˜¯16çš„å€æ•°ï¼Œå½“å‰{max_dim}"

    return True, "æœ‰æ•ˆ"

# æµ‹è¯•
print(validate_resolution(1280, 768))  # (True, 'æœ‰æ•ˆ')
print(validate_resolution(1920, 1080)) # (False, 'çŸ­è¾¹å¿…é¡»æ˜¯768ï¼Œå½“å‰1080')
```

---

## 5. ç¯å¢ƒæ­å»ºä¸å®‰è£…

### 5.1 ç¡¬ä»¶è¦æ±‚

#### **æ˜¾å¡éœ€æ±‚è¡¨**

| GPUå‹å· | æ˜¾å­˜ | CogVideoX-2B | CogVideoX-5B | CogVideoX1.5-5B | æ¨èç”¨é€” |
|---------|------|-------------|-------------|-----------------|---------|
| GTX 1080Ti | 11GB | âœ… FP16 | âŒ | âŒ | å…¥é—¨æµ‹è¯• |
| RTX 3060 | 12GB | âœ… FP16 | âœ… INT8 | âœ… INT8 | **æ€§ä»·æ¯”ä¹‹é€‰** |
| RTX 3080 | 10GB | âœ… FP16 | âŒ | âœ… INT8 | æ¶ˆè´¹çº§ä¸»åŠ› |
| RTX 3090 | 24GB | âœ… BF16 | âœ… BF16 | âœ… BF16 | é«˜ç«¯æ¶ˆè´¹çº§ |
| RTX 4090 | 24GB | âœ… BF16 | âœ… BF16 | âœ… BF16 | **æœ€ä½³é€‰æ‹©** |
| A100 40GB | 40GB | âœ… BF16 | âœ… BF16 | âœ… BF16æ‰¹é‡ | ä¸“ä¸šç”Ÿäº§ |
| A100 80GB | 80GB | âœ… æ‰¹é‡Ã—4 | âœ… æ‰¹é‡Ã—2 | âœ… æ‰¹é‡Ã—2 | é«˜é€šé‡ |

#### **ç³»ç»Ÿè¦æ±‚**

```yaml
æ“ä½œç³»ç»Ÿ:
  - Linux: Ubuntu 20.04/22.04 (æ¨è)
  - Windows: 11 with WSL2
  - macOS: ä¸æ”¯æŒ (æ— CUDA)

CUDAç‰ˆæœ¬:
  - CUDA 11.8 (æ¨è)
  - CUDA 12.1/12.4 (å…¼å®¹)

Pythonç‰ˆæœ¬:
  - Python 3.10 (æ¨è)
  - Python 3.11 (å…¼å®¹)

å†…å­˜:
  - æœ€ä½: 32GB
  - æ¨è: 64GB

å­˜å‚¨:
  - æ¨¡å‹æƒé‡: ~10GB (BF16) / ~5GB (INT8)
  - å·¥ä½œç©ºé—´: 100GB+
```

### 5.2 Diffuserså®‰è£… (æ¨èæ–¹å¼)

#### **æ­¥éª¤1: åˆ›å»ºç¯å¢ƒ**

```bash
# åˆ›å»ºCondaç¯å¢ƒ
conda create -n cogvideox python=3.10
conda activate cogvideox

# éªŒè¯Pythonç‰ˆæœ¬
python --version  # Python 3.10.x
```

#### **æ­¥éª¤2: å®‰è£…PyTorch**

```bash
# CUDA 11.8
pip install torch==2.4.0 torchvision==0.19.0 --index-url https://download.pytorch.org/whl/cu118

# CUDA 12.1
pip install torch==2.4.0 torchvision==0.19.0 --index-url https://download.pytorch.org/whl/cu121

# éªŒè¯CUDA
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}, GPU: {torch.cuda.get_device_name(0)}')"
# è¾“å‡º: CUDA: True, GPU: NVIDIA GeForce RTX 4090
```

#### **æ­¥éª¤3: å®‰è£…Diffusers**

```bash
# å®‰è£…æœ€æ–°Diffusers (éœ€è¦ >=0.30.0)
pip install diffusers>=0.30.0

# å®‰è£…é…å¥—åº“
pip install transformers>=4.40.0
pip install accelerate>=0.25.0
pip install imageio-ffmpeg>=0.5.0
pip install sentencepiece>=0.2.0

# éªŒè¯ç‰ˆæœ¬
python -c "import diffusers; print(f'Diffusers: {diffusers.__version__}')"
# è¾“å‡º: Diffusers: 0.30.3
```

#### **æ­¥éª¤4: ä¸‹è½½æ¨¡å‹**

```bash
# å®‰è£…Hugging Face CLI
pip install huggingface-hub

# ç™»å½• (å¯é€‰ï¼Œå…¬å¼€æ¨¡å‹æ— éœ€ç™»å½•)
huggingface-cli login

# ä¸‹è½½CogVideoX1.5-5B (BF16ç‰ˆæœ¬, ~10GB)
huggingface-cli download THUDM/CogVideoX1.5-5B \
  --local-dir models/CogVideoX1.5-5B \
  --local-dir-use-symlinks False

# æˆ–ä¸‹è½½INT8é‡åŒ–ç‰ˆæœ¬ (~5GB, èŠ‚çœ50%å­˜å‚¨)
huggingface-cli download THUDM/CogVideoX1.5-5B-INT8 \
  --local-dir models/CogVideoX1.5-5B-INT8 \
  --local-dir-use-symlinks False

# æŸ¥çœ‹ä¸‹è½½è¿›åº¦
# â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 10.2GB/10.2GB [00:15<00:00, 680MB/s]
```

#### **æ­¥éª¤5: éªŒè¯å®‰è£…**

```python
# test_installation.py
import torch
from diffusers import CogVideoXPipeline

print("=== CogVideoXç¯å¢ƒæ£€æŸ¥ ===")
print(f"âœ… PyTorchç‰ˆæœ¬: {torch.__version__}")
print(f"âœ… CUDAå¯ç”¨: {torch.cuda.is_available()}")
print(f"âœ… GPU: {torch.cuda.get_device_name(0)}")
print(f"âœ… æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")

# åŠ è½½æ¨¡å‹ (ä¼šè‡ªåŠ¨ä¸‹è½½)
print("\næ­£åœ¨åŠ è½½CogVideoX1.5-5B...")
pipe = CogVideoXPipeline.from_pretrained(
    "THUDM/CogVideoX1.5-5B",
    torch_dtype=torch.bfloat16
)
pipe.to("cuda")

print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
print(f"âœ… æ¨¡å‹è®¾å¤‡: {pipe.device}")
print(f"âœ… å½“å‰æ˜¾å­˜å ç”¨: {torch.cuda.memory_allocated() / 1024**3:.2f} GB")
```

è¿è¡Œæµ‹è¯•:
```bash
python test_installation.py

# è¾“å‡º:
# === CogVideoXç¯å¢ƒæ£€æŸ¥ ===
# âœ… PyTorchç‰ˆæœ¬: 2.4.0+cu118
# âœ… CUDAå¯ç”¨: True
# âœ… GPU: NVIDIA GeForce RTX 4090
# âœ… æ˜¾å­˜: 24.0 GB
#
# æ­£åœ¨åŠ è½½CogVideoX1.5-5B...
# âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!
# âœ… æ¨¡å‹è®¾å¤‡: cuda:0
# âœ… å½“å‰æ˜¾å­˜å ç”¨: 11.23 GB
```

---

## 6. Diffusersæ¡†æ¶å®Œå…¨æŒ‡å—

### 6.1 åŸºç¡€ç”Ÿæˆ

#### **æœ€ç®€å•çš„æ–‡ç”Ÿè§†é¢‘**

```python
import torch
from diffusers import CogVideoXPipeline
from diffusers.utils import export_to_video

# 1. åŠ è½½æ¨¡å‹
pipe = CogVideoXPipeline.from_pretrained(
    "THUDM/CogVideoX1.5-5B",
    torch_dtype=torch.bfloat16
)
pipe.to("cuda")

# 2. ç”Ÿæˆè§†é¢‘
prompt = "ä¸“ä¸šå¥èº«æ•™ç»ƒåœ¨å¥èº«æˆ¿æ¼”ç¤ºæ ‡å‡†æ·±è¹²åŠ¨ä½œï¼Œä¾§é¢è§†è§’ï¼Œè‡ªç„¶å…‰ç…§ï¼Œé«˜æ¸…ç”»è´¨"

video = pipe(
    prompt=prompt,
    num_inference_steps=50,
    guidance_scale=6.0,
    num_frames=81,  # 5ç§’ @ 16fps
    height=768,
    width=1360
).frames[0]

# 3. ä¿å­˜è§†é¢‘
export_to_video(video, "squat_demo.mp4", fps=16)

print("âœ… è§†é¢‘å·²ä¿å­˜: squat_demo.mp4")
```

**å‚æ•°è¯´æ˜**:
- `num_inference_steps`: æ¨ç†æ­¥æ•°ï¼Œè¶Šé«˜è´¨é‡è¶Šå¥½ä½†è¶Šæ…¢ (æ¨è: 50)
- `guidance_scale`: CFGå¼•å¯¼å¼ºåº¦ (æ¨è: 6.0)
- `num_frames`: æ€»å¸§æ•°ï¼Œå¿…é¡»æ˜¯ $16N+1$ æ ¼å¼ (å¦‚: 49, 81, 113, 161)
- `height/width`: åˆ†è¾¨ç‡ï¼Œéœ€æ»¡è¶³çº¦æŸæ¡ä»¶

### 6.2 é«˜çº§å‚æ•°é…ç½®

#### **å®Œæ•´å‚æ•°åˆ—è¡¨**

```python
video = pipe(
    # === åŸºç¡€å‚æ•° ===
    prompt="è¯¦ç»†çš„æ–‡æœ¬æè¿°",
    negative_prompt="ä½è´¨é‡, æ¨¡ç³Š, å¤±çœŸ, æŠ–åŠ¨",

    # === è§†é¢‘è§„æ ¼ ===
    height=768,              # çŸ­è¾¹å›ºå®š768
    width=1360,              # é•¿è¾¹ [768, 1360]
    num_frames=81,           # å¸§æ•°: 16N+1, Nâˆˆ[3,10]

    # === é‡‡æ ·å‚æ•° ===
    num_inference_steps=50,  # æ¨ç†æ­¥æ•° [20, 100]
    guidance_scale=6.0,      # CFGå¼ºåº¦ [1.0, 15.0]

    # === éšæœºæ§åˆ¶ ===
    generator=torch.Generator("cuda").manual_seed(42),

    # === è¾“å‡ºæ§åˆ¶ ===
    output_type="pil",       # "pil" æˆ– "latent"
    return_dict=True
).frames[0]
```

#### **å¸§æ•°è®¡ç®—å™¨**

```python
def calculate_frames(duration_sec, fps=16):
    """è®¡ç®—æœ‰æ•ˆå¸§æ•°"""
    target_frames = int(duration_sec * fps)

    # æ‰¾åˆ°æœ€æ¥è¿‘çš„ 16N+1
    n = round((target_frames - 1) / 16)
    n = max(3, min(10, n))  # é™åˆ¶èŒƒå›´

    valid_frames = 16 * n + 1
    actual_duration = valid_frames / fps

    return valid_frames, actual_duration

# ç¤ºä¾‹
frames, duration = calculate_frames(5.0)
print(f"5ç§’è§†é¢‘ â†’ {frames}å¸§ï¼Œå®é™…æ—¶é•¿{duration:.2f}ç§’")
# è¾“å‡º: 5ç§’è§†é¢‘ â†’ 81å¸§ï¼Œå®é™…æ—¶é•¿5.06ç§’

frames, duration = calculate_frames(10.0)
print(f"10ç§’è§†é¢‘ â†’ {frames}å¸§ï¼Œå®é™…æ—¶é•¿{duration:.2f}ç§’")
# è¾“å‡º: 10ç§’è§†é¢‘ â†’ 161å¸§ï¼Œå®é™…æ—¶é•¿10.06ç§’
```

**æœ‰æ•ˆå¸§æ•°åˆ—è¡¨**:
```python
valid_frames_list = [16*n + 1 for n in range(3, 11)]
print(valid_frames_list)
# [49, 65, 81, 97, 113, 129, 145, 161]

# å¯¹åº”æ—¶é•¿ (16fps)
durations = [f / 16 for f in valid_frames_list]
print([f"{d:.2f}s" for d in durations])
# ['3.06s', '4.06s', '5.06s', '6.06s', '7.06s', '8.06s', '9.06s', '10.06s']
```

### 6.3 å›¾ç”Ÿè§†é¢‘ (I2V)

#### **åŸºç¡€å›¾ç”Ÿè§†é¢‘**

```python
from PIL import Image
from diffusers import CogVideoXImageToVideoPipeline

# 1. åŠ è½½I2Væ¨¡å‹
pipe = CogVideoXImageToVideoPipeline.from_pretrained(
    "THUDM/CogVideoX1.5-5B-I2V",  # æ³¨æ„ä½¿ç”¨I2Væ¨¡å‹
    torch_dtype=torch.bfloat16
)
pipe.to("cuda")

# 2. åŠ è½½èµ·å§‹å›¾åƒ
start_image = Image.open("gym_trainer_ready.jpg")

# 3. ç”Ÿæˆè§†é¢‘
prompt = "å¥èº«æ•™ç»ƒä»å‡†å¤‡å§¿åŠ¿å¼€å§‹æ‰§è¡Œæ·±è¹²åŠ¨ä½œï¼ŒåŠ¨ä½œæµç•…è¿è´¯"

video = pipe(
    prompt=prompt,
    image=start_image,
    num_inference_steps=50,
    num_frames=81,
    guidance_scale=6.0
).frames[0]

# 4. ä¿å­˜
export_to_video(video, "squat_from_image.mp4", fps=16)
```

#### **ä»»æ„åˆ†è¾¨ç‡I2V**

```python
from PIL import Image

# åŠ è½½ä»»æ„å°ºå¯¸å›¾åƒ
image = Image.open("custom_size.jpg")  # ä¾‹å¦‚ 1920Ã—1080

# è°ƒæ•´åˆ°æœ‰æ•ˆåˆ†è¾¨ç‡
def resize_to_valid(image):
    """è°ƒæ•´å›¾åƒåˆ°CogVideoXæœ‰æ•ˆåˆ†è¾¨ç‡"""
    w, h = image.size

    # ç¡®å®šçŸ­è¾¹ä¸º768
    if w < h:
        new_w = 768
        new_h = int(h * (768 / w))
    else:
        new_h = 768
        new_w = int(w * (768 / h))

    # ç¡®ä¿é•¿è¾¹åœ¨[768, 1360]ä¸”æ˜¯16çš„å€æ•°
    max_dim = max(new_w, new_h)
    max_dim = min(1360, max_dim)
    max_dim = (max_dim // 16) * 16

    if new_w > new_h:
        final_w = max_dim
        final_h = 768
    else:
        final_h = max_dim
        final_w = 768

    return image.resize((final_w, final_h), Image.LANCZOS)

# è°ƒæ•´å°ºå¯¸
resized_image = resize_to_valid(image)
print(f"åŸå§‹å°ºå¯¸: {image.size} â†’ è°ƒæ•´å: {resized_image.size}")

# ç”Ÿæˆè§†é¢‘
video = pipe(
    prompt="...",
    image=resized_image,
    num_frames=81
).frames[0]
```

### 6.4 æ‰¹é‡ç”Ÿæˆ

```python
import torch
from diffusers import CogVideoXPipeline
from diffusers.utils import export_to_video

pipe = CogVideoXPipeline.from_pretrained(
    "THUDM/CogVideoX1.5-5B",
    torch_dtype=torch.bfloat16
)
pipe.to("cuda")

# å¥èº«åŠ¨ä½œåˆ—è¡¨
exercises = [
    "ä¸“ä¸šæ•™ç»ƒæ¼”ç¤ºæ·±è¹²",
    "ä¸“ä¸šæ•™ç»ƒæ¼”ç¤ºç¡¬æ‹‰",
    "ä¸“ä¸šæ•™ç»ƒæ¼”ç¤ºå§æ¨",
    "ä¸“ä¸šæ•™ç»ƒæ¼”ç¤ºå¼•ä½“å‘ä¸Š"
]

# æ‰¹é‡ç”Ÿæˆ
for i, exercise in enumerate(exercises):
    prompt = f"{exercise}ï¼Œå¥èº«æˆ¿ç¯å¢ƒï¼Œä¸“ä¸šå™¨æï¼Œä¾§é¢è§†è§’ï¼Œé«˜æ¸…ç”»è´¨"

    video = pipe(
        prompt=prompt,
        num_frames=81,
        num_inference_steps=50,
        generator=torch.Generator("cuda").manual_seed(42 + i)
    ).frames[0]

    output_path = f"output/exercise_{i:02d}_{exercise}.mp4"
    export_to_video(video, output_path, fps=16)

    print(f"âœ… å·²ç”Ÿæˆ: {output_path}")

    # æ¸…ç†æ˜¾å­˜
    torch.cuda.empty_cache()
```

---

## 7. SATæ¡†æ¶é«˜çº§åº”ç”¨

### 7.1 SAT vs Diffuserså¯¹æ¯”

| ç‰¹æ€§ | Diffusers | SAT (SwissArmyTransformer) |
|------|-----------|----------------------------|
| **æ˜“ç”¨æ€§** | â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸ ç®€å• | â­ï¸â­ï¸â­ï¸ ä¸­ç­‰ |
| **çµæ´»æ€§** | â­ï¸â­ï¸â­ï¸ å—é™ | â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸ å®Œå…¨å¯æ§ |
| **æ˜¾å­˜ä¼˜åŒ–** | â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸ ä¼˜ç§€ | â­ï¸â­ï¸â­ï¸ éœ€æ‰‹åŠ¨ |
| **è‡ªå®šä¹‰èƒ½åŠ›** | â­ï¸â­ï¸ æœ‰é™ | â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸ å¼ºå¤§ |
| **é€‚ç”¨äººç¾¤** | åº”ç”¨å¼€å‘è€… | ç ”ç©¶äººå‘˜ |

### 7.2 SATå®‰è£…

```bash
# å…‹éš†CogVideoä»“åº“
git clone https://github.com/THUDM/CogVideo.git
cd CogVideo

# å®‰è£…SATä¾èµ–
pip install -r requirements_sat.txt

# å®‰è£…SwissArmyTransformer
pip install SwissArmyTransformer>=0.4.0
```

### 7.3 SATæ¨ç†ç¤ºä¾‹

```python
from sat.model import CogVideoXModel
from sat.generation import generate_video

# 1. åŠ è½½æ¨¡å‹
model = CogVideoXModel.from_pretrained(
    "models/CogVideoX1.5-5B",
    fp16=True,
    device="cuda"
)

# 2. å‡†å¤‡è¾“å…¥
prompt_embeds = model.encode_text("ä¸“ä¸šå¥èº«æ•™ç»ƒæ¼”ç¤ºæ·±è¹²")

# 3. ç”Ÿæˆè§†é¢‘
video = generate_video(
    model=model,
    text_embeds=prompt_embeds,
    video_length=81,
   height=768,
    width=1360,
    num_steps=50
)

# 4. ä¿å­˜
save_video(video, "output_sat.mp4")
```

### 7.4 è‡ªå®šä¹‰é‡‡æ ·å™¨

```python
from sat.generation import BaseSampler

class CustomSampler(BaseSampler):
    """è‡ªå®šä¹‰é‡‡æ ·å™¨ - åŠ¨æ€CFG"""

    def __init__(self, model):
        super().__init__(model)

    def step(self, x_t, t, text_embeds):
        """å•æ­¥å»å™ª"""
        # åŠ¨æ€è°ƒæ•´CFG: å‰æœŸå¼ºï¼ŒåæœŸå¼±
        progress = 1 - (t / self.num_steps)
        cfg_scale = 3.0 + 6.0 * (1 - progress)  # 9.0 â†’ 3.0

        # æ¡ä»¶é¢„æµ‹
        noise_pred_cond = self.model(x_t, t, text_embeds)

        # æ— æ¡ä»¶é¢„æµ‹
        noise_pred_uncond = self.model(x_t, t, None)

        # CFGç»„åˆ
        noise_pred = noise_pred_uncond + cfg_scale * (noise_pred_cond - noise_pred_uncond)

        # æ›´æ–°x_t
        x_t_minus_1 = self.scheduler.step(x_t, noise_pred, t)

        return x_t_minus_1

# ä½¿ç”¨è‡ªå®šä¹‰é‡‡æ ·å™¨
sampler = CustomSampler(model)
video = sampler.generate(prompt_embeds, num_steps=50)
```

---

## 8. æ˜¾å­˜ä¼˜åŒ–ä¸ç¡¬ä»¶é€‚é…

### 8.1 æ˜¾å­˜å ç”¨åˆ†æ

#### **ä¸åŒé…ç½®æ˜¾å­˜éœ€æ±‚**

| é…ç½® | æ¨¡å‹åŠ è½½ | FP16/BF16 | FP8 | INT8 | æ¨èGPU |
|------|---------|-----------|-----|------|---------|
| **CogVideoX1.5-5B** | | | | | |
| æ— ä¼˜åŒ– | 10GB | +8GBæ¨ç† | - | - | RTX 3090 (24GB) |
| + VAE Tiling | 10GB | +6GBæ¨ç† | - | - | RTX 3080 (10GB) âŒ |
| + CPU Offload | 5GB | +5GBæ¨ç† | - | - | RTX 3060 (12GB) âœ… |
| + INT8é‡åŒ– | 5GB | - | - | +2GBæ¨ç† | **RTX 3060 (12GB)** âœ… |
| + æ‰€æœ‰ä¼˜åŒ– | 3GB | - | - | +2GBæ¨ç† | GTX 1080Ti (11GB) âœ… |

### 8.2 Diffusersæ˜¾å­˜ä¼˜åŒ–

#### **ä¼˜åŒ–æŠ€å·§1: VAE Tiling**

```python
pipe = CogVideoXPipeline.from_pretrained(
    "THUDM/CogVideoX1.5-5B",
    torch_dtype=torch.bfloat16
)
pipe.to("cuda")

# å¯ç”¨VAEåˆ†å—ç¼–ç 
pipe.vae.enable_slicing()     # åˆ‡ç‰‡ç¼–ç 
pipe.vae.enable_tiling()      # åˆ†å—å¤„ç†

# æ˜¾å­˜èŠ‚çœ: 8GB â†’ 6GB (-25%)
# é€Ÿåº¦å½±å“: +5% æ¨ç†æ—¶é—´
# è´¨é‡æŸå¤±: <1%
```

#### **ä¼˜åŒ–æŠ€å·§2: CPU Offload**

```python
# å°†ä¸å¸¸ç”¨çš„æ¨¡å‹ç»„ä»¶å¸è½½åˆ°CPU
pipe.enable_model_cpu_offload()

# æˆ–è€…æ›´æ¿€è¿›çš„é¡ºåºCPUå¸è½½
pipe.enable_sequential_cpu_offload()

# æ˜¾å­˜èŠ‚çœ: 10GB â†’ 5GB (-50%)
# é€Ÿåº¦å½±å“: +20-30% æ¨ç†æ—¶é—´
# è´¨é‡æŸå¤±: 0%
```

#### **ä¼˜åŒ–æŠ€å·§3: Attention Slicing**

```python
# æ³¨æ„åŠ›æœºåˆ¶åˆ†ç‰‡è®¡ç®—
pipe.enable_attention_slicing(slice_size="auto")

# æˆ–æ‰‹åŠ¨æŒ‡å®šåˆ‡ç‰‡å¤§å°
pipe.enable_attention_slicing(slice_size=2)

# æ˜¾å­˜èŠ‚çœ: é¢å¤– -1GB
# é€Ÿåº¦å½±å“: +10%
```

#### **ç»„åˆä¼˜åŒ–ç¤ºä¾‹**

```python
import torch
from diffusers import CogVideoXPipeline

# åŠ è½½æ¨¡å‹
pipe = CogVideoXPipeline.from_pretrained(
    "THUDM/CogVideoX1.5-5B",
    torch_dtype=torch.bfloat16
)

# === å¯ç”¨æ‰€æœ‰ä¼˜åŒ– ===
pipe.vae.enable_slicing()
pipe.vae.enable_tiling()
pipe.enable_model_cpu_offload()
pipe.enable_attention_slicing()

# ç”Ÿæˆè§†é¢‘
video = pipe(
    prompt="ä¸“ä¸šæ•™ç»ƒæ¼”ç¤ºæ·±è¹²",
    num_frames=81,
    height=768,
    width=1360
).frames[0]

# å³°å€¼æ˜¾å­˜: ä»… 6GB!
# RTX 3060 12GBå¯è½»æ¾è¿è¡Œ
```

### 8.3 INT8é‡åŒ–

#### **ä½¿ç”¨é¢„é‡åŒ–æ¨¡å‹**

```python
from diffusers import CogVideoXPipeline
import torch

# æ–¹æ³•1: ç›´æ¥åŠ è½½INT8æ¨¡å‹
pipe = CogVideoXPipeline.from_pretrained(
    "THUDM/CogVideoX1.5-5B-INT8",  # INT8ç‰ˆæœ¬
    torch_dtype=torch.float16
)
pipe.to("cuda")

# æ˜¾å­˜å ç”¨: ä»… 7GB (BF16çš„35%)
# è´¨é‡æŸå¤±: <3%
# é€Ÿåº¦: å‡ ä¹ç›¸åŒ
```

#### **åŠ¨æ€é‡åŒ–**

```python
from diffusers import CogVideoXPipeline
import torchao

# åŠ è½½BF16æ¨¡å‹
pipe = CogVideoXPipeline.from_pretrained(
    "THUDM/CogVideoX1.5-5B",
    torch_dtype=torch.bfloat16
)

# åŠ¨æ€é‡åŒ–Transformer
pipe.transformer = torchao.quantize(
    pipe.transformer,
    int8_weight_only()
)

pipe.to("cuda")

# æ˜¾å­˜: 10GB â†’ 7GB
# é¦–æ¬¡æ¨ç†ä¼šç¼–è¯‘é‡åŒ–kernel (~2åˆ†é’Ÿ)
# åç»­æ¨ç†æ­£å¸¸é€Ÿåº¦
```

---

## 9. æ¶ˆè´¹çº§æ˜¾å¡è§£å†³æ–¹æ¡ˆ

### 9.1 RTX 3060 (12GB) é…ç½®

#### **æ¨èé…ç½®**

```python
import torch
from diffusers import CogVideoXPipeline

# === RTX 3060 æœ€ä½³å®è·µ ===
pipe = CogVideoXPipeline.from_pretrained(
    "THUDM/CogVideoX1.5-5B-INT8",  # ä½¿ç”¨INT8ç‰ˆæœ¬
    torch_dtype=torch.float16
)

# å¯ç”¨æ‰€æœ‰ä¼˜åŒ–
pipe.vae.enable_slicing()
pipe.vae.enable_tiling()
pipe.enable_model_cpu_offload()
pipe.enable_attention_slicing()

# ç”Ÿæˆé…ç½®
video = pipe(
    prompt="å¥èº«æ•™ç»ƒæ¼”ç¤ºæ·±è¹²",
    num_frames=81,        # 5ç§’
    height=768,
    width=1280,           # ä¸ç”¨æœ€å¤§1360ï¼ŒèŠ‚çœæ˜¾å­˜
    num_inference_steps=40  # ä»50é™åˆ°40
).frames[0]

# å®æµ‹æ€§èƒ½:
# - æ˜¾å­˜å ç”¨: 5.8GB / 12GB
# - ç”Ÿæˆæ—¶é—´: ~8åˆ†é’Ÿ
# - è´¨é‡: è‰¯å¥½
```

### 9.2 RTX 4090 (24GB) é…ç½®

#### **é«˜æ€§èƒ½é…ç½®**

```python
# === RTX 4090 é«˜æ€§èƒ½æ–¹æ¡ˆ ===
pipe = CogVideoXPipeline.from_pretrained(
    "THUDM/CogVideoX1.5-5B",  # BF16å®Œæ•´ç‰ˆæœ¬
    torch_dtype=torch.bfloat16
)
pipe.to("cuda")

# ä»…å¯ç”¨å¿…è¦ä¼˜åŒ–
pipe.vae.enable_tiling()

# Torch CompileåŠ é€Ÿ
pipe.transformer = torch.compile(
    pipe.transformer,
    mode="max-autotune",
    fullgraph=True
)

# æ‰¹é‡ç”Ÿæˆ (åˆ©ç”¨å……è¶³æ˜¾å­˜)
prompts = [
    "æ·±è¹²åŠ¨ä½œæ¼”ç¤º",
    "ç¡¬æ‹‰åŠ¨ä½œæ¼”ç¤º",
    "å§æ¨åŠ¨ä½œæ¼”ç¤º"
]

videos = []
for prompt in prompts:
    video = pipe(
        prompt=f"ä¸“ä¸šæ•™ç»ƒæ¼”ç¤º{prompt}",
        num_frames=161,      # 10ç§’å®Œæ•´æ—¶é•¿
        height=768,
        width=1360,          # æœ€å¤§åˆ†è¾¨ç‡
        num_inference_steps=50
    ).frames[0]
    videos.append(video)

# å®æµ‹æ€§èƒ½:
# - æ˜¾å­˜å ç”¨: 16GB / 24GB
# - å•è§†é¢‘ç”Ÿæˆæ—¶é—´: ~3.5åˆ†é’Ÿ
# - è´¨é‡: ä¼˜ç§€
```

### 9.3 å¤šå¡å¹¶è¡Œæ–¹æ¡ˆ

#### **2Ã—RTX 4090 æ•°æ®å¹¶è¡Œ**

```python
import torch
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
from diffusers import CogVideoXPipeline

# åˆå§‹åŒ–åˆ†å¸ƒå¼
dist.init_process_group(backend='nccl')
local_rank = int(os.environ['LOCAL_RANK'])

# æ¯å¼ å¡åŠ è½½æ¨¡å‹
pipe = CogVideoXPipeline.from_pretrained(
    "THUDM/CogVideoX1.5-5B",
    torch_dtype=torch.bfloat16
)
pipe.to(f"cuda:{local_rank}")

# åˆ†é…ä»»åŠ¡
prompts_all = [f"åŠ¨ä½œ{i}" for i in range(100)]
prompts_per_gpu = prompts_all[local_rank::dist.get_world_size()]

# å¹¶è¡Œç”Ÿæˆ
for prompt in prompts_per_gpu:
    video = pipe(prompt=prompt, num_frames=81).frames[0]
    save_video(video, f"output_gpu{local_rank}_{prompt}.mp4")

# æ€§èƒ½:
# - 2å¡ååé‡: 2Ã— å•å¡
# - 100ä¸ªè§†é¢‘ç”Ÿæˆæ—¶é—´: å•å¡175åˆ†é’Ÿ â†’ åŒå¡90åˆ†é’Ÿ
```

å¯åŠ¨å‘½ä»¤:
```bash
torchrun --nproc_per_node=2 \
  generate_parallel.py
```

---

## 10. å¥èº«åœºæ™¯å®æˆ˜æ¡ˆä¾‹

### 10.1 å•åŠ¨ä½œæ•™å­¦è§†é¢‘

```python
from diffusers import CogVideoXPipeline
from diffusers.utils import export_to_video
import torch

pipe = CogVideoXPipeline.from_pretrained(
    "THUDM/CogVideoX1.5-5B",
    torch_dtype=torch.bfloat16
)
pipe.to("cuda")

# æ·±è¹²è¯¦ç»†æè¿°
prompt = """
ä¸“ä¸šå¥èº«æ•™ç»ƒæ¼”ç¤ºæ ‡å‡†æ·±è¹²åŠ¨ä½œ:
1. åŒè„šä¸è‚©åŒå®½ç«™ç«‹ï¼Œè„šå°–å¾®å¾®å¤–å±•
2. åŒæ‰‹äº¤å‰æ”¾åœ¨èƒ¸å‰æˆ–å‘å‰ä¼¸ç›´
3. è‡€éƒ¨å‘ååï¼Œè†ç›–å¼¯æ›²ä¸‹è¹²
4. ä¿æŒèƒŒéƒ¨æŒºç›´ï¼Œæ ¸å¿ƒæ”¶ç´§
5. å¤§è…¿å¹³è¡Œåœ°é¢æ—¶åœé¡¿1ç§’
6. å‘åŠ›ç«™èµ·è‡³èµ·å§‹ä½ç½®
å¥èº«æˆ¿ç¯å¢ƒï¼Œä¸“ä¸šå™¨æèƒŒæ™¯ï¼Œä¾§é¢45åº¦è§†è§’ï¼Œ
è‡ªç„¶å…‰ç…§ï¼Œé«˜æ¸…4Kç”»è´¨ï¼ŒåŠ¨ä½œæµç•…è¿è´¯
"""

video = pipe(
    prompt=prompt,
    negative_prompt="ä½è´¨é‡, æ¨¡ç³Š, æŠ–åŠ¨, å¤±çœŸ, é”™è¯¯å§¿åŠ¿",
    num_frames=161,  # 10ç§’å®Œæ•´æ¼”ç¤º
    height=768,
    width=1360,
    num_inference_steps=50,
    guidance_scale=6.0,
    generator=torch.Generator("cuda").manual_seed(42)
).frames[0]

export_to_video(video, "squat_tutorial.mp4", fps=16)
```

### 10.2 è¿›é˜¶å˜å¼å¯¹æ¯”

```python
# ä¸‰ç§æ·±è¹²å˜å¼
variations = [
    {
        "name": "æ ‡å‡†æ·±è¹²",
        "prompt": "å¥èº«æ•™ç»ƒæ¼”ç¤ºæ ‡å‡†æ·±è¹²ï¼ŒåŒè„šä¸è‚©åŒå®½ï¼Œå¾’æ‰‹åŠ¨ä½œ"
    },
    {
        "name": "ç›¸æ‰‘æ·±è¹²",
        "prompt": "å¥èº«æ•™ç»ƒæ¼”ç¤ºç›¸æ‰‘æ·±è¹²ï¼ŒåŒè„šå®½è·ç«™ç«‹ï¼Œè„šå°–å¤–å±•45åº¦"
    },
    {
        "name": "æ é“ƒæ·±è¹²",
        "prompt": "å¥èº«æ•™ç»ƒæ¼”ç¤ºæ é“ƒæ·±è¹²ï¼Œè‚©æ‰›æ é“ƒï¼Œæ·±è¹²æ¶å™¨æ¢°ï¼Œè´Ÿé‡è®­ç»ƒ"
    }
]

for var in variations:
    video = pipe(
        prompt=f"{var['prompt']}ï¼Œå¥èº«æˆ¿ç¯å¢ƒï¼Œä¾§é¢è§†è§’ï¼Œä¸“ä¸šæ¼”ç¤º",
        num_frames=81,
        height=768,
        width=1280,
        num_inference_steps=50
    ).frames[0]

    export_to_video(video, f"squat_{var['name']}.mp4", fps=16)
    print(f"âœ… å·²ç”Ÿæˆ: {var['name']}")

# è¾“å‡º3ä¸ªå¯¹æ¯”è§†é¢‘ï¼Œå¯å¹¶æ’æ’­æ”¾
```

### 10.3 å¤šè§’åº¦æ‹æ‘„

```python
angles = [
    {"angle": "æ­£é¢è§†è§’", "prompt": "æ­£é¢æ‹æ‘„ï¼Œå±•ç¤ºæ•´ä½“å§¿åŠ¿å’ŒåŒè…¿å¯¹ç§°"},
    {"angle": "ä¾§é¢è§†è§’", "prompt": "ä¾§é¢æ‹æ‘„ï¼Œçªå‡ºè‡€éƒ¨å’Œè†ç›–è¿åŠ¨è½¨è¿¹"},
    {"angle": "åæ–¹è§†è§’", "prompt": "åæ–¹æ‹æ‘„ï¼Œæ£€æŸ¥èƒŒéƒ¨æŒºç›´å’Œè‚©éƒ¨ç¨³å®š"},
    {"angle": "ä½è§’åº¦ä»°è§†", "prompt": "ä½è§’åº¦ä»°è§†æ‹æ‘„ï¼Œå±•ç¤ºåŠ›é‡æ„Ÿå’Œçˆ†å‘åŠ›"}
]

base_prompt = "ä¸“ä¸šå¥èº«æ•™ç»ƒæ¼”ç¤ºæ·±è¹²åŠ¨ä½œ"

for i, angle_cfg in enumerate(angles):
    full_prompt = f"{base_prompt}ï¼Œ{angle_cfg['prompt']}ï¼Œå¥èº«æˆ¿ç¯å¢ƒï¼Œé«˜æ¸…ç”»è´¨"

    video = pipe(
        prompt=full_prompt,
        num_frames=81,
        height=768,
        width=1360,
        generator=torch.Generator("cuda").manual_seed(100 + i)
    ).frames[0]

    export_to_video(video, f"squat_{angle_cfg['angle']}.mp4", fps=16)
```

### 10.4 å¸¸è§é”™è¯¯çº æ­£è§†é¢‘

```python
# æ­£ç¡® vs é”™è¯¯åŠ¨ä½œå¯¹æ¯”
scenarios = [
    {
        "type": "âœ“ æ­£ç¡®",
        "prompt": "å¥èº«æ•™ç»ƒæ ‡å‡†æ·±è¹²: è†ç›–ä¸è¶…è¿‡è„šå°–ï¼ŒèƒŒéƒ¨æŒºç›´ï¼Œè‡€éƒ¨å……åˆ†ååï¼ŒåŠ¨ä½œæ ‡å‡†ï¼Œæ ‡æ³¨'æ­£ç¡®ç¤ºèŒƒ'ç»¿è‰²è¾¹æ¡†",
        "color": "green"
    },
    {
        "type": "âœ— é”™è¯¯1",
        "prompt": "æ¼”ç¤ºæ·±è¹²å¸¸è§é”™è¯¯: è†ç›–ä¸¥é‡å†…æ‰£ï¼Œç”¨äºæ•™å­¦çº æ­£ï¼Œæ ‡æ³¨'è†ç›–å†…æ‰£'çº¢è‰²è¾¹æ¡†",
        "color": "red"
    },
    {
        "type": "âœ— é”™è¯¯2",
        "prompt": "æ¼”ç¤ºæ·±è¹²å¸¸è§é”™è¯¯: èƒŒéƒ¨å¼“èµ·å¼¯æ›²ï¼Œç”¨äºæ•™å­¦çº æ­£ï¼Œæ ‡æ³¨'èƒŒéƒ¨å¼¯æ›²'çº¢è‰²è¾¹æ¡†",
        "color": "red"
    },
    {
        "type": "âœ— é”™è¯¯3",
        "prompt": "æ¼”ç¤ºæ·±è¹²å¸¸è§é”™è¯¯: ä¸‹è¹²æ·±åº¦ä¸è¶³ï¼Œä»…åŠè¹²ï¼Œæ ‡æ³¨'æ·±åº¦ä¸è¶³'çº¢è‰²è¾¹æ¡†",
        "color": "red"
    }
]

for scenario in scenarios:
    video = pipe(
        prompt=scenario["prompt"],
        num_frames=81,
        height=768,
        width=1280,
        num_inference_steps=50
    ).frames[0]

    export_to_video(video, f"squat_{scenario['type']}.mp4", fps=16)
```

### 10.5 å›¾ç”Ÿè§†é¢‘ä¸ªæ€§åŒ–æŒ‡å¯¼

```python
from PIL import Image
from diffusers import CogVideoXImageToVideoPipeline

# åŠ è½½I2Væ¨¡å‹
i2v_pipe = CogVideoXImageToVideoPipeline.from_pretrained(
    "THUDM/CogVideoX1.5-5B-I2V",
    torch_dtype=torch.bfloat16
)
i2v_pipe.to("cuda")

# ç”¨æˆ·ä¸Šä¼ è‡ªå·±çš„å¥èº«ç…§ç‰‡
user_image = Image.open("user_gym_photo.jpg")

# ç”Ÿæˆä¸ªæ€§åŒ–æŒ‡å¯¼è§†é¢‘
personalized_prompt = """
æ ¹æ®å›¾ç‰‡ä¸­çš„äººç‰©ï¼Œç”Ÿæˆæ·±è¹²åŠ¨ä½œæŒ‡å¯¼è§†é¢‘:
- ä¿æŒäººç‰©çš„é¢éƒ¨ç‰¹å¾å’Œä½“å‹
- ä»å½“å‰å§¿åŠ¿å¼€å§‹æ¼”ç¤ºæ·±è¹²
- æ ‡æ³¨å…³é”®å‘åŠ›ç‚¹å’Œæ³¨æ„äº‹é¡¹
- 3Dç®­å¤´æŒ‡ç¤ºæ­£ç¡®è¿åŠ¨è½¨è¿¹
- æ–‡å­—æç¤º"ä¿æŒèƒŒéƒ¨æŒºç›´"ã€"è†ç›–ä¸è¶…è¿‡è„šå°–"
"""

video = i2v_pipe(
    prompt=personalized_prompt,
    image=user_image,
    num_frames=81,
    height=768,
    width=1280,
    num_inference_steps=50
).frames[0]

export_to_video(video, "personalized_squat_guide.mp4", fps=16)
```

---

## 11. ComfyUIé›†æˆä¸å·¥ä½œæµ

### 11.1 å®‰è£…ComfyUIèŠ‚ç‚¹

```bash
# è¿›å…¥ComfyUIç›®å½•
cd ComfyUI/custom_nodes

# å…‹éš†CogVideoXèŠ‚ç‚¹
git clone https://github.com/kijai/ComfyUI-CogVideoXWrapper.git

# å®‰è£…ä¾èµ–
cd ComfyUI-CogVideoXWrapper
pip install -r requirements.txt

# ä¸‹è½½æ¨¡å‹åˆ°ComfyUIç›®å½•
mkdir -p ../../models/CogVideoX
huggingface-cli download THUDM/CogVideoX1.5-5B \
  --local-dir ../../models/CogVideoX/CogVideoX1.5-5B

# é‡å¯ComfyUI
```

### 11.2 åŸºç¡€å·¥ä½œæµ

```json
{
  "nodes": [
    {
      "id": 1,
      "type": "CogVideoX_TextEncoder",
      "pos": [100, 100],
      "size": [300, 200],
      "inputs": {
        "model": "CogVideoX1.5-5B",
        "text": "ä¸“ä¸šå¥èº«æ•™ç»ƒæ¼”ç¤ºæ·±è¹²åŠ¨ä½œ",
        "negative_text": "ä½è´¨é‡, æ¨¡ç³Š, å¤±çœŸ"
      }
    },
    {
      "id": 2,
      "type": "CogVideoX_Sampler",
      "pos": [450, 100],
      "size": [300, 300],
      "inputs": {
        "text_embeds": ["1", 0],
        "width": 1360,
        "height": 768,
        "num_frames": 81,
        "steps": 50,
        "cfg_scale": 6.0,
        "seed": 42
      }
    },
    {
      "id": 3,
      "type": "CogVideoX_VAEDecode",
      "pos": [800, 100],
      "inputs": {
        "latents": ["2", 0]
      }
    },
    {
      "id": 4,
      "type": "VHS_SaveVideo",
      "pos": [1100, 100],
      "inputs": {
        "video": ["3", 0],
        "filename": "squat_demo",
        "fps": 16,
        "format": "mp4"
      }
    }
  ]
}
```

### 11.3 æ‰¹é‡ç”Ÿæˆå·¥ä½œæµ

```json
{
  "nodes": [
    {
      "id": 1,
      "type": "TextListInput",
      "inputs": {
        "text_list": "æ·±è¹²\nç¡¬æ‹‰\nå§æ¨\nå¼•ä½“å‘ä¸Š"
      }
    },
    {
      "id": 2,
      "type": "StringFunction",
      "inputs": {
        "text": ["1", 0],
        "operation": "prefix",
        "prefix": "ä¸“ä¸šæ•™ç»ƒæ¼”ç¤º"
      }
    },
    {
      "id": 3,
      "type": "CogVideoX_BatchGenerator",
      "inputs": {
        "prompts": ["2", 0],
        "batch_size": 4,
        "num_frames": 81,
        "width": 1280,
        "height": 768
      }
    }
  ]
}
```

---

## 12. å•†ä¸šåŒ–éƒ¨ç½²æœ€ä½³å®è·µ

### 12.1 äº‘ç«¯éƒ¨ç½²æ¶æ„

#### **Flask APIæœåŠ¡**

```python
from flask import Flask, request, send_file
from diffusers import CogVideoXPipeline
import torch
import uuid
import os

app = Flask(__name__)

# å…¨å±€åŠ è½½æ¨¡å‹ (é¿å…é‡å¤åŠ è½½)
pipe = CogVideoXPipeline.from_pretrained(
    "THUDM/CogVideoX1.5-5B-INT8",
    torch_dtype=torch.float16
)
pipe.to("cuda")
pipe.vae.enable_tiling()
pipe.enable_model_cpu_offload()

@app.route('/generate', methods=['POST'])
def generate_video():
    """APIç«¯ç‚¹: ç”Ÿæˆè§†é¢‘"""
    data = request.json

    prompt = data.get('prompt')
    num_frames = data.get('num_frames', 81)
    height = data.get('height', 768)
    width = data.get('width', 1280)

    # ç”Ÿæˆè§†é¢‘
    video = pipe(
        prompt=prompt,
        num_frames=num_frames,
        height=height,
        width=width,
        num_inference_steps=40  # äº‘ç«¯é™ä½æ­¥æ•°åŠ å¿«ç”Ÿæˆ
    ).frames[0]

    # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
    video_id = str(uuid.uuid4())
    output_path = f"/tmp/{video_id}.mp4"
    export_to_video(video, output_path, fps=16)

    # è¿”å›æ–‡ä»¶
    return send_file(output_path, mimetype='video/mp4')

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

#### **Dockeréƒ¨ç½²**

```dockerfile
# Dockerfile
FROM nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04

# å®‰è£…Python
RUN apt-get update && apt-get install -y \
    python3.10 \
    python3-pip \
    ffmpeg

# å®‰è£…ä¾èµ–
COPY requirements.txt /app/
WORKDIR /app
RUN pip install -r requirements.txt

# ä¸‹è½½æ¨¡å‹
RUN huggingface-cli download THUDM/CogVideoX1.5-5B-INT8 \
    --local-dir /models/CogVideoX1.5-5B-INT8

# å¤åˆ¶ä»£ç 
COPY app.py /app/

# å¯åŠ¨æœåŠ¡
CMD ["python3", "app.py"]
```

æ„å»ºå’Œè¿è¡Œ:
```bash
# æ„å»ºé•œåƒ
docker build -t cogvideox-api .

# è¿è¡Œå®¹å™¨
docker run --gpus all -p 5000:5000 cogvideox-api
```

### 12.2 æˆæœ¬ä¼˜åŒ–ç­–ç•¥

#### **ç­–ç•¥1: æ··åˆéƒ¨ç½²**

```python
class HybridVideoGenerator:
    """æ··åˆéƒ¨ç½²: é«˜å³°æœŸç”¨APIï¼Œä½å³°æœŸæœ¬åœ°ç”Ÿæˆ"""

    def __init__(self):
        # æœ¬åœ°æ¨¡å‹
        self.local_pipe = CogVideoXPipeline.from_pretrained(
            "THUDM/CogVideoX1.5-5B-INT8",
            torch_dtype=torch.float16
        )
        self.local_pipe.to("cuda")

        # APIå¤‡ç”¨ (Runway/Luma)
        self.api_client = RunwayAPIClient(api_key="...")

    def generate(self, prompt, **kwargs):
        current_hour = datetime.now().hour

        # ä½å³°æœŸ (æ·±å¤œ): æœ¬åœ°ç”Ÿæˆ
        if 0 <= current_hour < 6:
            return self.local_pipe(prompt=prompt, **kwargs).frames[0]

        # é«˜å³°æœŸ: æ£€æŸ¥é˜Ÿåˆ—
        if self.local_queue_length() < 3:
            return self.local_pipe(prompt=prompt, **kwargs).frames[0]
        else:
            # é˜Ÿåˆ—è¿‡é•¿ï¼Œä½¿ç”¨API
            return self.api_client.generate(prompt)

    def local_queue_length(self):
        # æ£€æŸ¥æœ¬åœ°GPUé˜Ÿåˆ—
        return len(self.pending_tasks)
```

#### **ç­–ç•¥2: æ¸è¿›å¼è´¨é‡**

```python
def generate_with_preview(prompt):
    """å…ˆç”Ÿæˆä½è´¨é‡é¢„è§ˆï¼Œç”¨æˆ·æ»¡æ„åç”Ÿæˆé«˜è´¨é‡ç‰ˆæœ¬"""

    # é˜¶æ®µ1: å¿«é€Ÿé¢„è§ˆ (30ç§’)
    preview = pipe(
        prompt=prompt,
        num_frames=49,      # ä»…3ç§’
        height=512,         # é™ä½åˆ†è¾¨ç‡
        width=768,
        num_inference_steps=20  # é™ä½æ­¥æ•°
    ).frames[0]

    # å±•ç¤ºç»™ç”¨æˆ·
    show_preview(preview)

    # é˜¶æ®µ2: ç”¨æˆ·ç¡®è®¤åç”Ÿæˆé«˜è´¨é‡ (5åˆ†é’Ÿ)
    if user_confirms():
        final_video = pipe(
            prompt=prompt,
            num_frames=161,     # 10ç§’
            height=768,
            width=1360,
            num_inference_steps=50
        ).frames[0]
        return final_video

    return preview
```

### 12.3 SLAä¿éšœ

#### **ç›‘æ§å’Œå‘Šè­¦**

```python
import prometheus_client
from prometheus_client import Counter, Histogram

# æŒ‡æ ‡
video_requests = Counter('video_generation_requests_total', 'Total requests')
video_duration = Histogram('video_generation_duration_seconds', 'Generation time')
video_failures = Counter('video_generation_failures_total', 'Failed requests')

@app.route('/generate', methods=['POST'])
def generate_video():
    video_requests.inc()

    try:
        with video_duration.time():
            video = pipe(prompt=request.json['prompt'], ...).frames[0]

        return send_file(video_path)

    except Exception as e:
        video_failures.inc()
        return {"error": str(e)}, 500

# Prometheusç«¯ç‚¹
@app.route('/metrics')
def metrics():
    return prometheus_client.generate_latest()
```

---

## ğŸ“š å‚è€ƒèµ„æº

### å®˜æ–¹èµ„æº
- **GitHubä»“åº“**: https://github.com/THUDM/CogVideo
- **æ¨¡å‹æƒé‡ (BF16)**: https://huggingface.co/THUDM/CogVideoX1.5-5B
- **æ¨¡å‹æƒé‡ (INT8)**: https://huggingface.co/THUDM/CogVideoX1.5-5B-INT8
- **I2Væ¨¡å‹**: https://huggingface.co/THUDM/CogVideoX1.5-5B-I2V
- **æŠ€æœ¯è®ºæ–‡**: CogVideoX Technical Report (arXiv)

### ç¤¾åŒºèµ„æº
- **Diffusersæ–‡æ¡£**: https://huggingface.co/docs/diffusers
- **ComfyUIèŠ‚ç‚¹**: https://github.com/kijai/ComfyUI-CogVideoXWrapper
- **VBenchåŸºå‡†**: https://github.com/Vchitect/VBench

---

## ğŸ¯ æ€»ç»“

CogVideoX1.5-5Bå‡­å€Ÿ**Apache 2.0å®Œå…¨å…è´¹å•†ç”¨**è®¸å¯å’Œ**æ¶ˆè´¹çº§ç¡¬ä»¶å‹å¥½**çš„ç‰¹æ€§ï¼Œæˆä¸ºå•†ä¸šåŒ–è§†é¢‘ç”Ÿæˆçš„æœ€ä½³é€‰æ‹©ï¼š

### æ ¸å¿ƒä¼˜åŠ¿
1. âœ… **Apache 2.0è®¸å¯** - æ— é™åˆ¶å•†ä¸šä½¿ç”¨ï¼Œæ— éœ€æˆæƒè´¹
2. âœ… **RTX 3060èµ·æ­¥** - INT8é‡åŒ–ä»…éœ€7GBæ˜¾å­˜
3. âœ… **1360Ã—768åˆ†è¾¨ç‡** - æ¥è¿‘2Kç”»è´¨ï¼Œ10ç§’æ—¶é•¿
4. âœ… **Diffusersç”Ÿæ€** - ä¸HuggingFaceå®Œç¾é›†æˆ

### é€‚ç”¨åœºæ™¯
- ğŸ‹ï¸ å¥èº«æ•™å­¦è§†é¢‘ç”Ÿæˆ
- ğŸ“± ç¤¾äº¤åª’ä½“çŸ­è§†é¢‘åˆ›ä½œ
- ğŸ¬ å¹¿å‘Šè¥é”€å†…å®¹åˆ¶ä½œ
- ğŸ¢ ä¼ä¸šå†…éƒ¨åŸ¹è®­ç´ æ

### ROIåˆ†æ
- ğŸ’° **å¹´èŠ‚çœ**: $20000+ (vså•†ä¸šAPI)
- ğŸš€ **æŠ•èµ„å›æ”¶**: 2-3ä¸ªæœˆ
- ğŸ“ˆ **çµæ´»æ€§**: å®Œå…¨è‡ªä¸»å¯æ§

**ä¸‹ä¸€æ­¥è¡ŒåŠ¨**:
1. é€‰æ‹©åˆé€‚çš„GPU (RTX 3060/4090)
2. å®‰è£…Diffusersæ¡†æ¶å’Œæ¨¡å‹
3. ä½¿ç”¨ç¤ºä¾‹ä»£ç æµ‹è¯•ç”Ÿæˆæ•ˆæœ
4. æ ¹æ®ä¸šåŠ¡éœ€æ±‚å®šåˆ¶APIæœåŠ¡

---

**ä½œè€…**: Claude
**æ›´æ–°**: 2025-11-30
**ç‰ˆæœ¬**: v1.0
**è®¸å¯**: æœ¬æ•™ç¨‹éµå¾ªCC BY-NC-SA 4.0è®¸å¯
