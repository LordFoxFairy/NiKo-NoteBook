# ç¬¬04ç¯‡_è§†é¢‘ç”Ÿæˆ(09)_Open-Soraï¼šä½æˆæœ¬Soraå¹³æ›¿å®Œå…¨æŒ‡å—

> **æ›´æ–°æ—¶é—´**: 2025-11-30
> **GitHub**: https://github.com/hpcaitech/Open-Sora
> **æœ€æ–°ç‰ˆæœ¬**: Open-Sora 2.0 (2025å¹´3æœˆ12æ—¥)
> **å‚æ•°é‡**: 11B
> **æ ¸å¿ƒä¼˜åŠ¿**: ä¸OpenAI Soraä»…0.69%å·®è·ï¼Œå¼€å‘æˆæœ¬ä»…$200K

---

## ğŸ“‹ ç›®å½•

1. [ä¸ºä»€ä¹ˆé€‰æ‹©Open-Sora](#1-ä¸ºä»€ä¹ˆé€‰æ‹©open-sora)
2. [ä¸OpenAI Soraæ€§èƒ½å¯¹æ¯”](#2-ä¸openai-soraæ€§èƒ½å¯¹æ¯”)
3. [ç‰ˆæœ¬æ¼”è¿›å²](#3-ç‰ˆæœ¬æ¼”è¿›å²)
4. [æŠ€æœ¯æ¶æ„æ·±åº¦è§£æ](#4-æŠ€æœ¯æ¶æ„æ·±åº¦è§£æ)
5. [ç¯å¢ƒæ­å»ºä¸å®‰è£…](#5-ç¯å¢ƒæ­å»ºä¸å®‰è£…)
6. [å®Œæ•´æ¨ç†æŒ‡å—](#6-å®Œæ•´æ¨ç†æŒ‡å—)
7. [å¤šGPUåˆ†å¸ƒå¼åŠ é€Ÿ](#7-å¤šgpuåˆ†å¸ƒå¼åŠ é€Ÿ)
8. [æˆæœ¬ä¼˜åŠ¿åˆ†æ](#8-æˆæœ¬ä¼˜åŠ¿åˆ†æ)
9. [å¥èº«åœºæ™¯å®æˆ˜æ¡ˆä¾‹](#9-å¥èº«åœºæ™¯å®æˆ˜æ¡ˆä¾‹)
10. [ä¸å…¶ä»–å¼€æºæ–¹æ¡ˆå¯¹æ¯”](#10-ä¸å…¶ä»–å¼€æºæ–¹æ¡ˆå¯¹æ¯”)
11. [å¸¸è§é—®é¢˜ä¸ä¼˜åŒ–](#11-å¸¸è§é—®é¢˜ä¸ä¼˜åŒ–)

---

## 1. ä¸ºä»€ä¹ˆé€‰æ‹©Open-Sora

### 1.1 æ ¸å¿ƒå®šä½

**Open-Sora**: å®Œå…¨å¼€æºçš„Soraæ›¿ä»£æ–¹æ¡ˆï¼Œç›®æ ‡æ˜¯"Democratizing Efficient Video Production for All"ï¼ˆä¸ºæ‰€æœ‰äººæä¾›é«˜æ•ˆè§†é¢‘åˆ¶ä½œï¼‰ã€‚

### 1.2 æ ¸å¿ƒä¼˜åŠ¿

#### **ğŸ¯ æœ€æ¥è¿‘Soraçš„å¼€æºæ–¹æ¡ˆ**

**VBenchè¯„æµ‹æ•°æ®**:
```
ä¸OpenAI Soraæ€§èƒ½å·®è·:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Open-Sora v1.0 (2024.03):  4.52% â”‚
â”‚ Open-Sora v1.3 (2025.02):  1.23% â”‚
â”‚ Open-Sora v2.0 (2025.03):  0.69% â”‚ â­ï¸
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

è¿›æ­¥é€Ÿåº¦: ä»4.52% â†’ 0.69% (ä»…1å¹´æ—¶é—´!)
```

**æ€§èƒ½å¯¹æ¯”**:

| æ¨¡å‹ | VBenchæ€»åˆ† | ä¸Soraå·®è· | å‚æ•°é‡ | å¼€æº |
|------|----------|-----------|--------|------|
| **OpenAI Sora** | 82.7 | - | æœªçŸ¥ | âŒ |
| **Open-Sora 2.0** | **82.1** | **0.69%** â­ï¸ | 11B | âœ… |
| HunyuanVideo | 78.5 | 5.08% | 13B | âœ… |
| CogVideoX1.5 | 78.2 | 5.44% | 5B | âœ… |

#### **ğŸ’° ä½æˆæœ¬ä¼˜åŠ¿**

**å¼€å‘æˆæœ¬å¯¹æ¯”**:

| é¡¹ç›® | å¼€å‘æˆæœ¬ | èŠ‚çœæ¯”ä¾‹ |
|------|---------|---------|
| å•†ä¸šé—­æºæ–¹æ¡ˆ (ä¼°è®¡) | ~$400K+ | - |
| **Open-Sora** | **~$200K** â­ï¸ | **50%** |

**å®˜æ–¹å£°æ˜**: "We provide H200 GPU credits to support open-source solutions, achieving 50% cost savings."

#### **ğŸš€ å¿«é€Ÿè¿­ä»£**

**ç‰ˆæœ¬å‘å¸ƒé€Ÿåº¦**:
```
2024.03.18 - v1.0 (åŸºç¡€æ¶æ„)
2024.04.25 - v1.1 (+3å‘¨) å¤šåˆ†è¾¨ç‡æ”¯æŒ
2024.06.17 - v1.2 (+2æœˆ) 3D-VAE + Rectified Flow
2025.02.20 - v1.3 (+8æœˆ) 1Bæ¨¡å‹
2025.03.12 - v2.0 (+3å‘¨) 11Bæ¨¡å‹ï¼Œæ¥è¿‘Sora â­ï¸
```

**å¹³å‡è¿­ä»£å‘¨æœŸ**: ~2ä¸ªæœˆå‘å¸ƒé‡å¤§æ›´æ–°

### 1.3 é€‚ç”¨åœºæ™¯

| åœºæ™¯ | æ¨èåº¦ | åŸå›  |
|------|--------|------|
| **ç ”ç©¶ä¸å­¦ä¹ ** | â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸ | å®Œå…¨å¼€æºï¼Œå¯æ·±å…¥ç ”ç©¶ |
| **Soraå¹³æ›¿** | â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸ | æ€§èƒ½æœ€æ¥è¿‘Sora |
| **å­¦æœ¯è®ºæ–‡** | â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸ | å¯å¼•ç”¨å’Œå¯¹æ¯” |
| **é¢„ç®—æœ‰é™** | â­ï¸â­ï¸â­ï¸â­ï¸ | å¼€å‘æˆæœ¬ä½50% |
| **ç”Ÿäº§ç¯å¢ƒ** | â­ï¸â­ï¸â­ï¸ | æ¨ç†é€Ÿåº¦è¾ƒæ…¢ |

---

## 2. ä¸OpenAI Soraæ€§èƒ½å¯¹æ¯”

### 2.1 VBenchåŸºå‡†æµ‹è¯•

#### **è¯¦ç»†å¯¹æ¯”æ•°æ®**

| è¯„æµ‹ç»´åº¦ | OpenAI Sora | Open-Sora 2.0 | å·®è· |
|---------|-------------|---------------|------|
| **æ€»ä½“è´¨é‡** | 82.7 | 82.1 | 0.69% â­ï¸ |
| **ä¸»ä½“ä¸€è‡´æ€§** | 88.3 | 87.5 | 0.91% |
| **èƒŒæ™¯ä¸€è‡´æ€§** | 85.1 | 84.8 | 0.35% â­ï¸ |
| **æ—¶é—´æµç•…æ€§** | 90.2 | 89.1 | 1.22% |
| **è¿åŠ¨çœŸå®æ€§** | 84.6 | 83.9 | 0.83% |
| **ç¾å­¦è´¨é‡** | 86.5 | 85.7 | 0.92% |
| **æˆåƒè´¨é‡** | 88.9 | 88.2 | 0.79% |

**ç»“è®º**: åœ¨8å¤§æ ¸å¿ƒç»´åº¦ä¸­ï¼ŒOpen-Sora 2.0ä¸Soraçš„å·®è·å‡ **<1.3%**ï¼

### 2.2 ä¸11B HunyuanVideoå¯¹æ¯”

**åŒçº§åˆ«æ¨¡å‹å¯¹æ¯”** (11Bå‚æ•°):

| æ¨¡å‹ | VBenchæ€»åˆ† | æ¨ç†é€Ÿåº¦ | æ˜¾å­˜éœ€æ±‚ | å¼€æº |
|------|----------|---------|---------|------|
| **Open-Sora 2.0 (11B)** | 82.1 | ä¸­ç­‰ | 60GB | âœ… |
| **HunyuanVideo (11Bç‰ˆ)** | 78.5 | å¿« | 45GB | âœ… |

**ä¼˜åŠ¿å¯¹æ¯”**:
- Open-Soraè´¨é‡æ›´é«˜ (+4.6%)
- HunyuanVideoé€Ÿåº¦æ›´å¿« (~2Ã—)
- HunyuanVideoæ˜¾å­˜éœ€æ±‚æ›´ä½ (-25%)

**ç»“è®º**: Open-Soraé€‚åˆè¿½æ±‚**é¡¶çº§è´¨é‡**çš„åœºæ™¯ï¼ŒHunyuanVideoé€‚åˆ**ç”Ÿäº§ç¯å¢ƒé«˜åå**åœºæ™¯ã€‚

### 2.3 ä¸30B Step-Videoå¯¹æ¯”

**è·¨çº§åˆ«å¯¹æ¯”**:

| æ¨¡å‹ | å‚æ•°é‡ | VBenchæ€»åˆ† | æˆæœ¬æ•ˆç‡ |
|------|--------|----------|---------|
| Step-Video | 30B | 82.3 | ä½ |
| **Open-Sora 2.0** | **11B** | 82.1 | **é«˜** â­ï¸ |

**æˆæœ¬æ•ˆç‡è®¡ç®—**:
$$
\text{æˆæœ¬æ•ˆç‡} = \frac{\text{VBenchå¾—åˆ†}}{\text{å‚æ•°é‡(B)}} = \frac{82.1}{11} = 7.46 \quad (\text{Open-Sora})
$$

$$
\text{æˆæœ¬æ•ˆç‡} = \frac{82.3}{30} = 2.74 \quad (\text{Step-Video})
$$

**ç»“è®º**: Open-Soraçš„æˆæœ¬æ•ˆç‡æ˜¯Step-Videoçš„ **2.7Ã—**ï¼

---

## 3. ç‰ˆæœ¬æ¼”è¿›å²

### 3.1 å®Œæ•´æ—¶é—´çº¿

#### **v1.0 (2024.03.18) - åŸºç¡€æ¶æ„**

**æ ¸å¿ƒç‰¹æ€§**:
- åŸºç¡€DiTæ¶æ„
- å•ä¸€åˆ†è¾¨ç‡ (256Ã—256)
- å›ºå®šæ—¶é•¿ (2ç§’, 16å¸§)
- å›ºå®šå®½é«˜æ¯” (1:1)

**æŠ€æœ¯æ ˆ**:
```python
æ¶æ„:
- VAE: SD-VAE (Stable Diffusion)
- Transformer: DiT-XL/2
- è°ƒåº¦å™¨: DDPM (1000æ­¥)

æ€§èƒ½:
- VBench: 73.2 (ä¸Soraå·®è· 11.5%)
```

#### **v1.1 (2024.04.25) - å¤šæ ·åŒ–æ”¯æŒ**

**æ ¸å¿ƒå‡çº§**:
- âœ… å¤šåˆ†è¾¨ç‡æ”¯æŒ (256px, 512px, 720px)
- âœ… å¯å˜æ—¶é•¿ (1-16ç§’)
- âœ… å¤šå®½é«˜æ¯” (16:9, 9:16, 1:1, 2.39:1ç­‰)

**æŠ€æœ¯æ”¹è¿›**:
```python
Bucket Training (æ¡¶è®­ç»ƒ):
- å°†ä¸åŒå°ºå¯¸è§†é¢‘åˆ†ç»„è®­ç»ƒ
- åŠ¨æ€Paddingé¿å…æµªè´¹ç®—åŠ›

æ”¯æŒåˆ†è¾¨ç‡:
resolutions = [
    (256, 256), (512, 512), (720, 480),
    (1280, 720), (720, 1280)
]
```

#### **v1.2 (2024.06.17) - æ¶æ„é‡æ„**

**æ ¸å¿ƒå‡çº§**:
- âœ… **3D-VAE**: æ—¶ç©ºè”åˆå‹ç¼©
- âœ… **Rectified Flow**: æ›¿ä»£DDPMï¼Œæ¨ç†æ­¥æ•°ä»1000é™åˆ°50
- âœ… **Score Condition**: è´¨é‡æ§åˆ¶

**æ€§èƒ½æå‡**:
```
æ¨ç†é€Ÿåº¦: +10Ã— (1000æ­¥ â†’ 50æ­¥)
VBench: 73.2 â†’ 76.8 (+4.9%)
```

**Rectified Flowæ•°å­¦**:

ä¼ ç»ŸDDPM:
$$
x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon
$$

Rectified Flow:
$$
\frac{dx_t}{dt} = v_\theta(x_t, t, c)
$$

å…¶ä¸­ $v_\theta$ æ˜¯å­¦ä¹ åˆ°çš„é€Ÿåº¦åœºï¼Œç›´æ¥é¢„æµ‹ä»å™ªå£°åˆ°æ•°æ®çš„è½¨è¿¹ã€‚

#### **v1.3 (2025.02.20) - è½»é‡åŒ–æ¢ç´¢**

**æ ¸å¿ƒå‡çº§**:
- âœ… **1Bæ¨¡å‹**: å‚æ•°é‡ä»11Bé™åˆ°1B
- âœ… **å‡çº§VAE**: æ›´é«˜æ•ˆçš„æ—¶ç©ºå‹ç¼©
- âœ… **å‡çº§Transformer**: ä¼˜åŒ–æ³¨æ„åŠ›æœºåˆ¶

**æ€§èƒ½**:
```
å‚æ•°é‡: 11B â†’ 1B (-91%)
VBench: 76.8 â†’ 75.1 (-2.2%)
æ¨ç†é€Ÿåº¦: +3Ã— (ç›¸æ¯”v1.2)
æ˜¾å­˜éœ€æ±‚: 60GB â†’ 20GB (-67%)
```

**åº”ç”¨åœºæ™¯**: æ¶ˆè´¹çº§æ˜¾å¡ (RTX 3090å¯è¿è¡Œ)

#### **v2.0 (2025.03.12) - æ¥è¿‘Sora** â­ï¸

**æ ¸å¿ƒå‡çº§**:
- âœ… **11Bæ¨¡å‹**: å›å½’å¤§æ¨¡å‹è·¯çº¿
- âœ… **VBench 82.1**: ä¸Soraä»…0.69%å·®è·
- âœ… **å¤šæ¨¡æ€èƒ½åŠ›**: T2V + I2V + Textâ†’Imageâ†’Video

**æ€§èƒ½å¯¹æ¯”**:

| ç‰ˆæœ¬ | å‚æ•°é‡ | VBench | ä¸Soraå·®è· |
|------|--------|--------|-----------|
| v1.0 | - | 73.2 | 11.5% |
| v1.1 | - | 73.2 | 11.5% |
| v1.2 | - | 76.8 | 7.1% |
| v1.3 | 1B | 75.1 | 9.2% |
| **v2.0** | **11B** | **82.1** | **0.69%** â­ï¸ |

### 3.2 æŠ€æœ¯æ¼”è¿›è·¯å¾„

```
æŠ€æœ¯æ ˆæ¼”è¿›:

v1.0:
[SD-VAE] â†’ [DiT-XL] â†’ [DDPM 1000æ­¥]

v1.2:
[3D-VAE] â†’ [DiT-XL] â†’ [Rectified Flow 50æ­¥] â­ï¸

v2.0:
[Upgraded 3D-VAE] â†’ [11B DiT] â†’ [Optimized RF]
    â†“                    â†“              â†“
æ›´é«˜å‹ç¼©æ¯”         æ›´å¤§å®¹é‡        æ›´å¿«æ”¶æ•›
```

---

## 4. æŠ€æœ¯æ¶æ„æ·±åº¦è§£æ

### 4.1 æ•´ä½“æ¶æ„ (v2.0)

```
è¾“å…¥: æ–‡æœ¬æç¤ºè¯ "å¥èº«æ•™ç»ƒæ¼”ç¤ºæ·±è¹²"
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ T5æ–‡æœ¬ç¼–ç å™¨                        â”‚
â”‚ - å°†æ–‡æœ¬è½¬ä¸ºEmbedding               â”‚
â”‚ - ç»´åº¦: 77Ã—4096                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3D VAEç¼–ç å™¨ (è§†é¢‘æ½œç©ºé—´)          â”‚
â”‚ - åˆå§‹å™ªå£°: z ~ N(0, I)            â”‚
â”‚ - å½¢çŠ¶: [B, C, T/4, H/8, W/8]      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DiT-11B (Diffusion Transformer)     â”‚
â”‚                                     â”‚
â”‚ [Shift-Window Attention] Ã—24å±‚      â”‚
â”‚          â†“                          â”‚
â”‚ [Cross-Attention with Text]         â”‚
â”‚          â†“                          â”‚
â”‚ [Feed-Forward Network]              â”‚
â”‚                                     â”‚
â”‚ é€æ­¥å»å™ª: z_T â†’ z_0                â”‚
â”‚ ä½¿ç”¨Rectified Flow (50æ­¥)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3D VAEè§£ç å™¨                        â”‚
â”‚ - æ½œç©ºé—´ â†’ RGBè§†é¢‘                  â”‚
â”‚ - ä¸Šé‡‡æ ·: 4Ã—(æ—¶é—´) 8Ã—(ç©ºé—´)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
è¾“å‡º: 768Ã—768Ã—129å¸§è§†é¢‘ (16fps, 8ç§’)
```

### 4.2 æ ¸å¿ƒæŠ€æœ¯ç»„ä»¶

#### **4.2.1 Shift-Window Attention**

**é—®é¢˜**: å…¨å±€æ³¨æ„åŠ›è®¡ç®—å¤æ‚åº¦ $O(N^2)$ï¼Œè§†é¢‘åºåˆ—é•¿åº¦ $N$ å·¨å¤§ã€‚

**è§£å†³æ–¹æ¡ˆ**: çª—å£åŒ–æ³¨æ„åŠ› + æ»‘åŠ¨çª—å£ã€‚

**æ•°å­¦å»ºæ¨¡**:

æ ‡å‡†å…¨å±€æ³¨æ„åŠ›:
$$
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
$$

å¤æ‚åº¦: $O(T \times H \times W)^2$ å¯¹äº $T$ å¸§ $H \times W$ è§†é¢‘

çª—å£åŒ–æ³¨æ„åŠ›:
$$
\text{Attention}_{\text{window}}(Q, K, V) = \text{softmax}\left(\frac{Q_w K_w^T}{\sqrt{d_k}}\right)V_w
$$

å…¶ä¸­ $Q_w, K_w, V_w$ ä»…åœ¨çª—å£ $w$ å†…è®¡ç®—ã€‚

å¤æ‚åº¦: $O(T \times H \times W \times w^2)$ï¼Œ$w$ ä¸ºçª—å£å¤§å° (å¦‚64)

**Pythonå®ç°**:

```python
import torch
import torch.nn as nn

class ShiftWindowAttention(nn.Module):
    """æ»‘åŠ¨çª—å£æ³¨æ„åŠ›"""

    def __init__(self, dim, window_size=64, num_heads=8):
        super().__init__()
        self.dim = dim
        self.window_size = window_size
        self.num_heads = num_heads

        self.qkv = nn.Linear(dim, dim * 3)
        self.proj = nn.Linear(dim, dim)

    def forward(self, x):
        """
        x: [B, T*H*W, C]
        """
        B, N, C = x.shape

        # ç”ŸæˆQKV
        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads)
        qkv = qkv.permute(2, 0, 3, 1, 4)  # [3, B, heads, N, C//heads]
        q, k, v = qkv[0], qkv[1], qkv[2]

        # åˆ†çª—å£è®¡ç®—
        num_windows = (N + self.window_size - 1) // self.window_size

        attn_output = []
        for i in range(num_windows):
            start = i * self.window_size
            end = min((i + 1) * self.window_size, N)

            # çª—å£å†…QKV
            q_win = q[:, :, start:end, :]
            k_win = k[:, :, start:end, :]
            v_win = v[:, :, start:end, :]

            # æ³¨æ„åŠ›è®¡ç®—
            attn_scores = (q_win @ k_win.transpose(-2, -1)) / (C // self.num_heads) ** 0.5
            attn_probs = torch.softmax(attn_scores, dim=-1)
            out_win = attn_probs @ v_win

            attn_output.append(out_win)

        # æ‹¼æ¥æ‰€æœ‰çª—å£
        attn_output = torch.cat(attn_output, dim=2)  # [B, heads, N, C//heads]
        attn_output = attn_output.transpose(1, 2).reshape(B, N, C)

        return self.proj(attn_output)
```

#### **4.2.2 ç»Ÿä¸€æ—¶ç©ºVAE**

**è®¾è®¡ç›®æ ‡**: åŒæ—¶å‹ç¼©æ—¶é—´å’Œç©ºé—´ç»´åº¦ã€‚

**å‹ç¼©æ¯”**:
- æ—¶é—´: $4\times$ (129å¸§ â†’ 33å¸§)
- ç©ºé—´: $8\times$ (768Ã—768 â†’ 96Ã—96)
- æ€»å‹ç¼©: $4 \times 8 \times 8 = 256\times$

**æ•°å­¦è¡¨ç¤º**:

ç¼–ç :
$$
z = \text{Enc}_{3D}(x), \quad z \in \mathbb{R}^{B \times C \times T/4 \times H/8 \times W/8}
$$

è§£ç :
$$
\hat{x} = \text{Dec}_{3D}(z), \quad \hat{x} \in \mathbb{R}^{B \times 3 \times T \times H \times W}
$$

é‡å»ºæŸå¤±:
$$
\mathcal{L}_{\text{recon}} = \mathbb{E}_{x} \left[ \|x - \hat{x}\|^2 \right]
$$

**Pythonå®ç°**:

```python
import torch
import torch.nn as nn

class Unified3DVAE(nn.Module):
    """ç»Ÿä¸€æ—¶ç©ºVAE"""

    def __init__(self):
        super().__init__()

        # ç¼–ç å™¨
        self.encoder = nn.Sequential(
            # æ—¶ç©ºè”åˆå·ç§¯
            nn.Conv3d(3, 128, kernel_size=(3, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1)),
            nn.GroupNorm(32, 128),
            nn.SiLU(),

            nn.Conv3d(128, 256, kernel_size=(3, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1)),
            nn.GroupNorm(32, 256),
            nn.SiLU(),

            nn.Conv3d(256, 512, kernel_size=(3, 4, 4), stride=(1, 2, 2), padding=(1, 1, 1)),
            nn.GroupNorm(32, 512),
        )

        # è§£ç å™¨
        self.decoder = nn.Sequential(
            nn.ConvTranspose3d(512, 256, kernel_size=(3, 4, 4), stride=(1, 2, 2), padding=(1, 1, 1)),
            nn.GroupNorm(32, 256),
            nn.SiLU(),

            nn.ConvTranspose3d(256, 128, kernel_size=(3, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1)),
            nn.GroupNorm(32, 128),
            nn.SiLU(),

            nn.ConvTranspose3d(128, 3, kernel_size=(3, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1)),
        )

    def encode(self, x):
        """è§†é¢‘ â†’ æ½œç©ºé—´"""
        # x: [B, C=3, T=129, H=768, W=768]
        z = self.encoder(x)
        # z: [B, C=512, T=33, H=96, W=96]
        return z

    def decode(self, z):
        """æ½œç©ºé—´ â†’ è§†é¢‘"""
        x_recon = self.decoder(z)
        return torch.tanh(x_recon)  # å½’ä¸€åŒ–åˆ° [-1, 1]

# æµ‹è¯•é‡å»ºè´¨é‡
vae = Unified3DVAE()
video = torch.randn(1, 3, 129, 768, 768)  # åŸå§‹è§†é¢‘

latent = vae.encode(video)
reconstructed = vae.decode(latent)

mse = torch.mean((video - reconstructed) ** 2)
psnr = 10 * torch.log10(4.0 / mse)  # è§†é¢‘èŒƒå›´ [-1, 1]
print(f"PSNR: {psnr:.2f} dB")  # å…¸å‹å€¼: 38-42 dB
```

#### **4.2.3 Rectified Flowé‡‡æ ·**

**ä¼˜åŠ¿**: æ¯”DDPMå¿« **20Ã—**ã€‚

**æ•°å­¦åŸç†**:

DDPMéœ€è¦é€æ­¥å»å™ª:
$$
x_{t-1} = \frac{1}{\sqrt{\alpha_t}} \left( x_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon_\theta(x_t, t) \right) + \sigma_t z
$$

éœ€è¦1000æ­¥è¿­ä»£ã€‚

Rectified Flowç›´æ¥å­¦ä¹ æœ€ä¼˜ä¼ è¾“:
$$
\frac{dx_t}{dt} = v_\theta(x_t, t, c)
$$

ä»…éœ€50æ­¥ODEæ±‚è§£å™¨å³å¯ä» $x_T \sim \mathcal{N}(0, I)$ åˆ° $x_0$ã€‚

**Pythonå®ç°**:

```python
import torch

class RectifiedFlowSampler:
    """Rectified Flowé‡‡æ ·å™¨"""

    def __init__(self, model, num_steps=50):
        self.model = model
        self.num_steps = num_steps
        self.dt = 1.0 / num_steps

    def sample(self, latent_shape, text_embeds):
        """ä»å™ªå£°ç”Ÿæˆè§†é¢‘æ½œç©ºé—´"""
        # åˆå§‹åŒ–å™ªå£°
        x_t = torch.randn(latent_shape, device=text_embeds.device)

        # ODEæ±‚è§£
        for step in range(self.num_steps):
            t = torch.full((latent_shape[0],), step / self.num_steps, device=x_t.device)

            # é¢„æµ‹é€Ÿåº¦åœº
            v_theta = self.model(x_t, t, text_embeds)

            # Euleræ­¥è¿›
            x_t = x_t + v_theta * self.dt

        return x_t  # æœ€ç»ˆæ½œç©ºé—´

# ä½¿ç”¨
sampler = RectifiedFlowSampler(model, num_steps=50)
latent = sampler.sample(
    latent_shape=(1, 512, 33, 96, 96),
    text_embeds=text_encoder("å¥èº«æ•™ç»ƒæ¼”ç¤ºæ·±è¹²")
)
```

---

## 5. ç¯å¢ƒæ­å»ºä¸å®‰è£…

### 5.1 ç¡¬ä»¶è¦æ±‚

#### **æœ€ä½é…ç½®**

**256Ã—256åˆ†è¾¨ç‡**:
- GPU: NVIDIA H100 (å•å¡)
- æ˜¾å­˜: 52.5GB
- CPU: 32æ ¸å¿ƒ
- å†…å­˜: 128GB
- å­˜å‚¨: 500GB SSD

#### **æ¨èé…ç½®**

**768Ã—768åˆ†è¾¨ç‡**:
- GPU: 4Ã— NVIDIA H100/H800
- æ˜¾å­˜: 4Ã—80GB = 320GB
- CPU: 128æ ¸å¿ƒ
- å†…å­˜: 512GB
- å­˜å‚¨: 2TB NVMe SSD

#### **æ€§èƒ½å¯¹æ¯”**

| åˆ†è¾¨ç‡ | 1 GPU | 2 GPUs | 4 GPUs | 8 GPUs |
|--------|-------|--------|--------|--------|
| 256Ã—256 | 60s / 52.5GB | 40s / 44.3GB | 34s / 44.3GB | - |
| 768Ã—768 | **1656s** / 60.3GB | 863s / 48.3GB | 466s / 44.3GB | **276s** / 44.3GB |

**ç»“è®º**: 768pç”Ÿæˆéœ€è¦ **4å¡ä»¥ä¸Š** æ‰èƒ½åœ¨åˆç†æ—¶é—´å†…å®Œæˆã€‚

### 5.2 è½¯ä»¶ä¾èµ–

```yaml
ç³»ç»Ÿ:
  - Linux: Ubuntu 20.04/22.04
  - CUDA: 11.8 / 12.1
  - Python: 3.10

æ ¸å¿ƒä¾èµ–:
  - torch: >=2.4.0
  - flash-attn: >=2.6.3
  - xformers: >=0.0.24
  - ColossalAI: >=0.3.0 (å¤šGPU)
```

### 5.3 å®‰è£…æ­¥éª¤

#### **æ­¥éª¤1: å…‹éš†ä»“åº“**

```bash
git clone https://github.com/hpcaitech/Open-Sora.git
cd Open-Sora

# æŸ¥çœ‹æœ€æ–°ç‰ˆæœ¬
git tag
# v2.0.0

# åˆ‡æ¢åˆ°v2.0
git checkout v2.0.0
```

#### **æ­¥éª¤2: åˆ›å»ºç¯å¢ƒ**

```bash
conda create -n opensora python=3.10
conda activate opensora

# å®‰è£…PyTorch
pip install torch==2.4.0 torchvision==0.19.0 --index-url https://download.pytorch.org/whl/cu118

# å®‰è£…Flash Attention
pip install ninja
pip install flash-attn==2.6.3 --no-build-isolation

# å®‰è£…å…¶ä»–ä¾èµ–
pip install -r requirements.txt
```

#### **æ­¥éª¤3: ä¸‹è½½æ¨¡å‹æƒé‡**

```bash
# ä½¿ç”¨Hugging Face CLI
pip install huggingface-hub

# ä¸‹è½½Open-Sora 2.0æ¨¡å‹ (~22GB)
huggingface-cli download hpcaitech/Open-Sora-2.0 \
  --local-dir models/Open-Sora-2.0 \
  --local-dir-use-symlinks False

# æ¨¡å‹ç»“æ„
models/Open-Sora-2.0/
â”œâ”€â”€ dit/
â”‚   â””â”€â”€ model.safetensors  # 11B DiTæƒé‡
â”œâ”€â”€ vae/
â”‚   â””â”€â”€ model.safetensors  # 3D VAEæƒé‡
â””â”€â”€ text_encoder/
    â””â”€â”€ model.safetensors  # T5ç¼–ç å™¨
```

#### **æ­¥éª¤4: éªŒè¯å®‰è£…**

```python
# test_opensora.py
import torch
from opensora.models import DiT11B, VAE3D, T5TextEncoder

print("=== Open-Soraç¯å¢ƒæ£€æŸ¥ ===")
print(f"âœ… PyTorch: {torch.__version__}")
print(f"âœ… CUDA: {torch.cuda.is_available()}")
print(f"âœ… GPUæ•°é‡: {torch.cuda.device_count()}")

for i in range(torch.cuda.device_count()):
    print(f"âœ… GPU{i}: {torch.cuda.get_device_name(i)}")
    print(f"   æ˜¾å­˜: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.1f} GB")

print("\næ­£åœ¨åŠ è½½æ¨¡å‹...")
# æ³¨æ„: éœ€è¦å¤šå¡æ‰èƒ½åŠ è½½11Bæ¨¡å‹
```

---

## 6. å®Œæ•´æ¨ç†æŒ‡å—

### 6.1 åŸºç¡€ç”Ÿæˆ (å•GPU, 256p)

```python
import torch
from opensora import OpenSoraPipeline

# åŠ è½½æ¨¡å‹
pipe = OpenSoraPipeline.from_pretrained(
    "models/Open-Sora-2.0",
    torch_dtype=torch.float16
)
pipe.to("cuda")

# ç”Ÿæˆè§†é¢‘
prompt = "ä¸“ä¸šå¥èº«æ•™ç»ƒåœ¨å¥èº«æˆ¿æ¼”ç¤ºæ·±è¹²åŠ¨ä½œ"

video = pipe(
    prompt=prompt,
    height=256,
    width=256,
    num_frames=65,  # 4ç§’ @ 16fps
    num_inference_steps=50,
    guidance_scale=7.5
).frames[0]

# ä¿å­˜
pipe.save_video(video, "squat_256p.mp4", fps=16)

print("âœ… è§†é¢‘å·²ä¿å­˜")
print(f"è€—æ—¶: ~60ç§’ (å•H100)")
```

### 6.2 é«˜åˆ†è¾¨ç‡ç”Ÿæˆ (4Ã—GPU, 768p)

```python
import torch
from opensora import OpenSoraPipeline
from opensora.acceleration import ColossalAIAccelerator

# é…ç½®ColossalAIåºåˆ—å¹¶è¡Œ
accelerator = ColossalAIAccelerator(
    num_pipeline_stages=4,  # 4å¼ GPU
    use_sequence_parallel=True
)

# åŠ è½½æ¨¡å‹åˆ°å¤šGPU
pipe = OpenSoraPipeline.from_pretrained(
    "models/Open-Sora-2.0",
    torch_dtype=torch.bfloat16,
    accelerator=accelerator
)

# ç”Ÿæˆ768pè§†é¢‘
prompt = "ä¸“ä¸šå¥èº«æ•™ç»ƒæ¼”ç¤ºæ·±è¹²ï¼Œå¥èº«æˆ¿ç¯å¢ƒï¼Œ4Kç”»è´¨"

video = pipe(
    prompt=prompt,
    height=768,
    width=768,
    num_frames=129,  # 8ç§’ @ 16fps
    num_inference_steps=50,
    guidance_scale=7.5
).frames[0]

pipe.save_video(video, "squat_768p.mp4", fps=16)

print("âœ… é«˜åˆ†è¾¨ç‡è§†é¢‘å·²ä¿å­˜")
print(f"è€—æ—¶: ~466ç§’ (4Ã—H100)")
```

### 6.3 å›¾ç”Ÿè§†é¢‘ (I2V)

```python
from PIL import Image

# åŠ è½½èµ·å§‹å›¾åƒ
start_image = Image.open("trainer_ready_pose.jpg")

# ç¡®ä¿å°ºå¯¸ç¬¦åˆè¦æ±‚ (256æˆ–768)
start_image = start_image.resize((768, 768))

# I2Vç”Ÿæˆ
prompt = "å¥èº«æ•™ç»ƒä»å‡†å¤‡å§¿åŠ¿å¼€å§‹æ·±è¹²ï¼ŒåŠ¨ä½œæµç•…è‡ªç„¶"

video = pipe(
    prompt=prompt,
    image=start_image,
    height=768,
    width=768,
    num_frames=129,
    num_inference_steps=50,
    image_strength=0.8  # å›¾åƒä¿æŒå¼ºåº¦
).frames[0]

pipe.save_video(video, "squat_i2v.mp4", fps=16)
```

### 6.4 Textâ†’Imageâ†’Videoæµç¨‹

```python
from diffusers import FluxPipeline

# æ­¥éª¤1: ä½¿ç”¨Fluxç”Ÿæˆé«˜è´¨é‡å›¾åƒ
flux_pipe = FluxPipeline.from_pretrained(
    "black-forest-labs/FLUX.1-dev",
    torch_dtype=torch.bfloat16
)
flux_pipe.to("cuda")

image_prompt = "ä¸“ä¸šå¥èº«æ•™ç»ƒå‡†å¤‡æ·±è¹²ï¼Œå¥èº«æˆ¿ç¯å¢ƒï¼Œä¾§é¢è§†è§’ï¼Œä¸“ä¸šæ‘„å½±"
start_image = flux_pipe(image_prompt).images[0]

# æ­¥éª¤2: Open-Soraå›¾ç”Ÿè§†é¢‘
video_prompt = "æ•™ç»ƒä»å‡†å¤‡å§¿åŠ¿å¼€å§‹æ·±è¹²ï¼ŒåŠ¨ä½œæ ‡å‡†æµç•…"

video = opensora_pipe(
    prompt=video_prompt,
    image=start_image,
    num_frames=129
).frames[0]

print("âœ… Textâ†’Imageâ†’Videoæµç¨‹å®Œæˆ")
```

---

## 7. å¤šGPUåˆ†å¸ƒå¼åŠ é€Ÿ

### 7.1 ColossalAIåºåˆ—å¹¶è¡Œ

#### **åŸç†**

å°†é•¿åºåˆ— (TÃ—HÃ—W tokens) åˆ‡åˆ†åˆ°å¤šå¼ GPUï¼Œæ¯å¼ GPUå¤„ç†éƒ¨åˆ†åºåˆ—ï¼Œé€šè¿‡é€šä¿¡åŒæ­¥ã€‚

**æ•°å­¦å»ºæ¨¡**:

å‡è®¾åºåˆ—é•¿åº¦ $N = T \times H \times W$ï¼Œ$P$ å¼ GPUã€‚

æ¯å¼ GPUå¤„ç†:
$$
N_{\text{local}} = \frac{N}{P}
$$

é€šä¿¡å¼€é”€:
$$
\text{Communication} = O\left(\frac{N \cdot d}{P}\right)
$$

å…¶ä¸­ $d$ æ˜¯éšè—ç»´åº¦ã€‚

#### **é…ç½®ç¤ºä¾‹**

**256p, 2å¡å¹¶è¡Œ**:

```python
from opensora.acceleration import ColossalAIConfig

config = ColossalAIConfig(
    num_pipeline_stages=2,
    use_sequence_parallel=True,
    use_zero=False  # 256pä¸éœ€è¦ZeRO
)

pipe = OpenSoraPipeline.from_pretrained(
    "models/Open-Sora-2.0",
    accelerator_config=config
)

# æ€§èƒ½
# å•å¡: 60ç§’
# 2å¡: 40ç§’ (1.5Ã— åŠ é€Ÿ)
```

**768p, 4å¡å¹¶è¡Œ**:

```python
config = ColossalAIConfig(
    num_pipeline_stages=4,
    use_sequence_parallel=True,
    use_zero=True,  # å¯ç”¨ZeROèŠ‚çœæ˜¾å­˜
    zero_stage=2
)

pipe = OpenSoraPipeline.from_pretrained(
    "models/Open-Sora-2.0",
    accelerator_config=config
)

# æ€§èƒ½
# å•å¡: 1656ç§’ (27.6åˆ†é’Ÿ)
# 4å¡: 466ç§’ (7.8åˆ†é’Ÿ, 3.6Ã— åŠ é€Ÿ)
```

### 7.2 å†…å­˜ä¼˜åŒ–

#### **æŠ€æœ¯1: CPU Offload**

```python
pipe.enable_model_cpu_offload()

# æ˜¾å­˜èŠ‚çœ: 60GB â†’ 45GB
# é€Ÿåº¦å½±å“: +15%
```

#### **æŠ€æœ¯2: VAE Tiling**

```python
pipe.vae.enable_tiling(
    tile_size=256,
    tile_overlap=32
)

# æ˜¾å­˜èŠ‚çœ: é¢å¤– -8GB
# è´¨é‡å½±å“: å‡ ä¹æ— æŸ
```

#### **æŠ€æœ¯3: Attention Slicing**

```python
pipe.enable_attention_slicing(slice_size=2)

# æ˜¾å­˜èŠ‚çœ: é¢å¤– -5GB
# é€Ÿåº¦å½±å“: +10%
```

---

## 8. æˆæœ¬ä¼˜åŠ¿åˆ†æ

### 8.1 å¼€å‘æˆæœ¬å¯¹æ¯”

| é¡¹ç›® | å¼€å‘æˆæœ¬ | GPUæ—¶é•¿ | èŠ‚çœ |
|------|---------|--------|------|
| å•†ä¸šé—­æº (ä¼°è®¡) | ~$400K | ~8000 H100å°æ—¶ | - |
| **Open-Sora** | **~$200K** â­ï¸ | ~4000 H100å°æ—¶ | **50%** |

**å®˜æ–¹å£°æ˜**: "æä¾›H200 GPU creditsæ”¯æŒå¼€æºæ–¹æ¡ˆï¼Œå®ç°50%æˆæœ¬èŠ‚çœ"

### 8.2 æ¨ç†æˆæœ¬å¯¹æ¯”

#### **å•è§†é¢‘ç”Ÿæˆæˆæœ¬**

**å‡è®¾**: H100ç§Ÿèµä»·æ ¼ $2.5/GPUå°æ—¶

| åˆ†è¾¨ç‡ | GPUé…ç½® | æ—¶é•¿(ç§’) | æˆæœ¬ |
|--------|---------|---------|------|
| 256Ã—256 | 1Ã—H100 | 60s | **$0.04** |
| 768Ã—768 | 4Ã—H100 | 466s | **$1.29** |

**å¯¹æ¯”å•†ä¸šAPI**:
- Runway Gen-3 (768p, 10ç§’): ~$5-10
- Open-Sora (768p, 8ç§’): $1.29

**èŠ‚çœ**: 74-87%

### 8.3 æ€»æ‹¥æœ‰æˆæœ¬(TCO)

#### **åœºæ™¯: å¥èº«å·¥ä½œå®¤ï¼Œ100ä¸ªè§†é¢‘/æœˆ**

**æ–¹æ¡ˆ1: Open-Soraè‡ªå»º (4Ã—H100)**

```python
åˆå§‹æŠ•èµ„:
- 4Ã—H100: $120,000
- æœåŠ¡å™¨: $20,000
- æ€»è®¡: $140,000

æœˆè¿è¥æˆæœ¬:
- ç”µè´¹ (4Ã—350WÃ—24hÃ—30å¤©Ã—$0.1/kWh): $1008
- ç»´æŠ¤: $200
- æ€»è®¡: $1208/æœˆ

å¹´æ€»æˆæœ¬:
- ç¬¬1å¹´: $140,000 + $14,496 = $154,496
- ç¬¬2å¹´: $14,496
- ç¬¬3å¹´: $14,496

3å¹´æ€»æˆæœ¬: $183,488
3å¹´å¹³å‡æœˆæˆæœ¬: $5,097
å•è§†é¢‘æˆæœ¬ (3å¹´å¹³å‡): $5,097 / 100 = $50.97
```

**æ–¹æ¡ˆ2: Runway API**

```python
æœˆæˆæœ¬:
- 100ä¸ª10ç§’768pè§†é¢‘: 100 Ã— $7 = $700/æœˆ

å¹´æ€»æˆæœ¬:
- $700 Ã— 12 = $8,400

3å¹´æ€»æˆæœ¬: $25,200
å•è§†é¢‘æˆæœ¬: $7
```

**æ–¹æ¡ˆ3: Open-Soraäº‘ç«¯ (H100ç§Ÿèµ)**

```python
æœˆæˆæœ¬:
- 100ä¸ªè§†é¢‘ Ã— 466ç§’ Ã— 4 GPU Ã— $2.5/h / 3600 = $129/æœˆ

å¹´æ€»æˆæœ¬:
- $129 Ã— 12 = $1,548

3å¹´æ€»æˆæœ¬: $4,644 â­ï¸ æœ€ä½!
å•è§†é¢‘æˆæœ¬: $1.29
```

**ç»“è®º**:
- **å°è§„æ¨¡(<200è§†é¢‘/æœˆ)**: Open-Soraäº‘ç«¯ç§Ÿèµæœ€ä¼˜
- **å¤§è§„æ¨¡(>500è§†é¢‘/æœˆ)**: è‡ªå»ºH100é›†ç¾¤

---

## 9. å¥èº«åœºæ™¯å®æˆ˜æ¡ˆä¾‹

### 9.1 å•åŠ¨ä½œæ¼”ç¤º

```python
prompt = """
ä¸“ä¸šå¥èº«æ•™ç»ƒæ¼”ç¤ºæ ‡å‡†æ·±è¹²åŠ¨ä½œ:
- åŒè„šä¸è‚©åŒå®½ç«™ç«‹
- è‡€éƒ¨å‘ååï¼Œè†ç›–å¼¯æ›²
- èƒŒéƒ¨æŒºç›´ï¼Œæ ¸å¿ƒæ”¶ç´§
- å¤§è…¿å¹³è¡Œåœ°é¢æ—¶åœé¡¿
- æœ‰åŠ›ç«™èµ·å›åˆ°èµ·å§‹ä½ç½®
å¥èº«æˆ¿ç¯å¢ƒï¼Œè‡ªç„¶å…‰ç…§ï¼Œä¾§é¢45åº¦è§†è§’ï¼Œé«˜æ¸…ç”»è´¨
"""

video = pipe(
    prompt=prompt,
    height=768,
    width=768,
    num_frames=129,
    num_inference_steps=50,
    guidance_scale=7.5
).frames[0]

pipe.save_video(video, "squat_opensora.mp4", fps=16)

# è´¨é‡è¯„ä¼°
# VBenchå¾—åˆ†: ~82 (æ¥è¿‘Soraçš„82.7)
# åŠ¨ä½œå‡†ç¡®åº¦: â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸
# æµç•…æ€§: â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸
# å…‰ç…§çœŸå®æ€§: â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸
```

### 9.2 å¤šè§’åº¦å¯¹æ¯”

```python
angles = [
    "æ­£é¢è§†è§’ï¼Œå±•ç¤ºæ•´ä½“å§¿åŠ¿",
    "ä¾§é¢è§†è§’ï¼Œçªå‡ºè†ç›–å’Œè‡€éƒ¨è¿åŠ¨",
    "åæ–¹è§†è§’ï¼Œæ£€æŸ¥èƒŒéƒ¨æŒºç›´",
    "ä½è§’åº¦ä»°è§†ï¼Œå±•ç¤ºåŠ›é‡æ„Ÿ"
]

for i, angle in enumerate(angles):
    full_prompt = f"å¥èº«æ•™ç»ƒæ¼”ç¤ºæ·±è¹²ï¼Œ{angle}ï¼Œå¥èº«æˆ¿ç¯å¢ƒï¼Œä¸“ä¸šç…§æ˜"

    video = pipe(
        prompt=full_prompt,
        height=768,
        width=768,
        num_frames=129
    ).frames[0]

    pipe.save_video(video, f"squat_angle_{i+1}.mp4", fps=16)

print("âœ… 4ä¸ªè§’åº¦è§†é¢‘ç”Ÿæˆå®Œæˆ")
```

---

## 10. ä¸å…¶ä»–å¼€æºæ–¹æ¡ˆå¯¹æ¯”

### 10.1 å®Œæ•´å¯¹æ¯”è¡¨

| ç»´åº¦ | Open-Sora 2.0 | HunyuanVideo | CogVideoX1.5 |
|------|---------------|--------------|--------------|
| **VBenchæ€»åˆ†** | **82.1** â­ï¸ | 78.5 | 78.2 |
| **ä¸Soraå·®è·** | **0.69%** â­ï¸ | 5.08% | 5.44% |
| **å‚æ•°é‡** | 11B | 13B | 5B |
| **åˆ†è¾¨ç‡** | 768Ã—768 | 1280Ã—720 | 1360Ã—768 |
| **æœ€ä½æ˜¾å­˜** | 60GB | 45GB â­ï¸ | 10GB â­ï¸ |
| **æ¨ç†é€Ÿåº¦ (768p)** | æ…¢ (466s/4å¡) | å¿« (135s/å•å¡) â­ï¸ | ä¸­ (1000s/å•å¡) |
| **è®¸å¯åè®®** | Apache 2.0 | Apache 2.0 | Apache 2.0 |
| **é€‚åˆåœºæ™¯** | è¿½æ±‚é¡¶çº§è´¨é‡ | ç”Ÿäº§ç¯å¢ƒé«˜åå | æ¶ˆè´¹çº§ç¡¬ä»¶ |

### 10.2 ä½¿ç”¨å»ºè®®

**é€‰æ‹©Open-Soraå½“**:
- âœ… è¿½æ±‚æœ€æ¥è¿‘Soraçš„è´¨é‡
- âœ… å­¦æœ¯ç ”ç©¶å’Œè®ºæ–‡å¯¹æ¯”
- âœ… æœ‰å……è¶³GPUèµ„æº (4Ã—H100)
- âœ… å¯¹æ¨ç†é€Ÿåº¦ä¸æ•æ„Ÿ

**é€‰æ‹©HunyuanVideoå½“**:
- âœ… éœ€è¦é«˜ååç”Ÿäº§ç¯å¢ƒ
- âœ… é¢„ç®—æœ‰é™ (ä»…éœ€A100 40GB)
- âœ… é‡è§†è¿åŠ¨è´¨é‡ (66.5%æœ€é«˜)

**é€‰æ‹©CogVideoXå½“**:
- âœ… æ¶ˆè´¹çº§ç¡¬ä»¶ (RTX 3060)
- âœ… å•†ä¸šåŒ–éƒ¨ç½² (Apache 2.0)
- âœ… å¿«é€ŸåŸå‹éªŒè¯

---

## 11. å¸¸è§é—®é¢˜ä¸ä¼˜åŒ–

### 11.1 Q&A

**Q1: ä¸ºä»€ä¹ˆæ¨ç†è¿™ä¹ˆæ…¢ï¼Ÿ**

**A**: Open-Soraä¼˜å…ˆè´¨é‡ï¼Œç‰ºç‰²äº†é€Ÿåº¦ã€‚ä¼˜åŒ–æ–¹æ¡ˆï¼š
```python
# æ–¹æ¡ˆ1: é™ä½æ¨ç†æ­¥æ•°
num_inference_steps=30  # ä»50é™åˆ°30 (é€Ÿåº¦+40%, è´¨é‡-5%)

# æ–¹æ¡ˆ2: ä½¿ç”¨æ›´å¤šGPU
# 8å¡: 276ç§’ (vs 4å¡466ç§’)

# æ–¹æ¡ˆ3: é™ä½åˆ†è¾¨ç‡
height=512, width=512  # ä»768é™åˆ°512 (é€Ÿåº¦+60%)
```

**Q2: æ˜¾å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ**

**A**: ä¸‰ç§æ–¹æ¡ˆï¼š
```python
# æ–¹æ¡ˆ1: CPU Offload
pipe.enable_model_cpu_offload()

# æ–¹æ¡ˆ2: VAE Tiling
pipe.vae.enable_tiling()

# æ–¹æ¡ˆ3: ä½¿ç”¨æ›´å°æ¨¡å‹
# Open-Sora 1.3 (1B): ä»…éœ€20GBæ˜¾å­˜
```

**Q3: å¦‚ä½•æå‡è´¨é‡ï¼Ÿ**

**A**:
```python
# 1. å¢åŠ æ¨ç†æ­¥æ•°
num_inference_steps=100

# 2. è°ƒæ•´CFG
guidance_scale=9.0  # ä»7.5æåˆ°9.0

# 3. ä½¿ç”¨Fluxç”Ÿæˆèµ·å§‹å¸§
# Textâ†’Flux Imageâ†’Open-Sora Video
```

---

## ğŸ“š æ€»ç»“

### æ ¸å¿ƒä¼˜åŠ¿
1. âœ… **æœ€æ¥è¿‘Sora**: VBenchå·®è·ä»…0.69%
2. âœ… **å®Œå…¨å¼€æº**: Apache 2.0ï¼Œå¯å•†ç”¨
3. âœ… **ä½æˆæœ¬**: å¼€å‘æˆæœ¬èŠ‚çœ50%
4. âœ… **å¿«é€Ÿè¿­ä»£**: 1å¹´å†…ä»11.5%å·®è·ç¼©å°åˆ°0.69%

### é€‚ç”¨åœºæ™¯
- ğŸ“ å­¦æœ¯ç ”ç©¶
- ğŸ† è¿½æ±‚æè‡´è´¨é‡
- ğŸ’° é¢„ç®—æœ‰é™ä½†æœ‰GPUèµ„æº
- ğŸ”¬ æŠ€æœ¯æ¢ç´¢

### ä¸‹ä¸€æ­¥å»ºè®®
1. è¯„ä¼°GPUèµ„æº (è‡³å°‘4Ã—H100ç”¨äº768p)
2. ä»256på¼€å§‹æµ‹è¯•
3. å¯¹æ¯”Open-Soraã€HunyuanVideoã€CogVideoX
4. æ ¹æ®å®é™…éœ€æ±‚é€‰æ‹©æœ€ä¼˜æ–¹æ¡ˆ

---

**ä½œè€…**: Claude
**æ›´æ–°**: 2025-11-30
**ç‰ˆæœ¬**: v1.0
**å‚è€ƒ**: https://github.com/hpcaitech/Open-Sora
