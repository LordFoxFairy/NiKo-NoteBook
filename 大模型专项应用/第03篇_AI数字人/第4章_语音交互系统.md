# 第4章 语音交互系统

## 4.1 Whisper实时STT

```python
from faster_whisper import WhisperModel

class RealtimeSTT:
    def __init__(self):
        self.model = WhisperModel("large-v3", device="cuda", compute_type="float16")
    
    async def transcribe_stream(self, audio_chunk):
        segments, _ = self.model.transcribe(audio_chunk, language="zh")
        return "".join([seg.text for seg in segments])
```

## 4.2 ElevenLabs TTS

```python
from elevenlabs import generate

class RealtimeTTS:
    async def synthesize_stream(self, text: str):
        audio_stream = generate(text=text, voice="21m00Tcm4TlvDq8ikWAM",
                               model="eleven_turbo_v2", stream=True)
        for chunk in audio_stream:
            yield chunk
```

## 4.3 VAD语音端点检测

```python
import webrtcvad

class VADDetector:
    def __init__(self):
        self.vad = webrtcvad.Vad(3)  # 激进模式
    
    def is_speech(self, audio_chunk, sample_rate=16000):
        return self.vad.is_speech(audio_chunk, sample_rate)
```

## 4.4 本章小结
- Whisper Large-v3提供95%+准确率,延迟<100ms
- ElevenLabs Turbo模型首字节延迟~300ms
- VAD可减少30%+无效识别
