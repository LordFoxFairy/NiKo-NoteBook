# ç¬¬å…«ç¯‡ Middleware å·¥ç¨‹åŒ–

> **ç›®æ ‡**: æŒæ¡ LangChain Middleware æœºåˆ¶,å®ç°å¯¹ Agent è¡Œä¸ºçš„ç²¾å‡†æ§åˆ¶

åœ¨å‰é¢çš„ç¯‡ç« ä¸­,æˆ‘ä»¬å­¦ä¼šäº†å¦‚ä½•åˆ›å»ºAgent(`create_agent`)ã€æ„å»ºå¤æ‚å·¥ä½œæµ(`LangGraph`)ã€å¤„ç†å¤æ‚ä»»åŠ¡(`Deep Agents`)ã€‚ä½†è¿™äº›éƒ½æ˜¯"åŠŸèƒ½å®ç°"å±‚é¢,æœ¬ç¯‡è¿›å…¥**å·¥ç¨‹åŒ–é˜¶æ®µ**:å¦‚ä½•è®©Agentåœ¨ç”Ÿäº§ç¯å¢ƒä¸­**å®‰å…¨ã€å¯é ã€å¯æ§**åœ°è¿è¡Œã€‚

**æ ¸å¿ƒé—®é¢˜**:
- å¦‚ä½•é˜²æ­¢Agentæ³„éœ²æ•æ„Ÿä¿¡æ¯?
- å¦‚ä½•é™åˆ¶Agentçš„è°ƒç”¨æˆæœ¬?
- å¦‚ä½•åœ¨å…³é”®æ“ä½œå‰è¦æ±‚äººå·¥å®¡æ‰¹?
- å¦‚ä½•åœ¨å¯¹è¯è¿‡é•¿æ—¶è‡ªåŠ¨æ‘˜è¦?

**è§£å†³æ–¹æ¡ˆ**: **Middleware** - LangChain 1.0çš„æ ¸å¿ƒæœºåˆ¶,å…è®¸ä½ åœ¨Agentæ‰§è¡Œçš„å„ä¸ªé˜¶æ®µç²¾å‡†å¹²é¢„ã€‚

---

## ç¬¬1ç« ï¼šMiddleware æ ¸å¿ƒæœºåˆ¶

> **æœ¬ç« ç›®æ ‡**: ç†è§£Middlewareçš„æœ¬è´¨ã€è¿è¡ŒåŸç†å’ŒåŸºæœ¬ç”¨æ³•

### 1.1 ä»€ä¹ˆæ˜¯ Middleware

#### 1.1.1 Agentæ‰§è¡Œæµç¨‹å›é¡¾

é¦–å…ˆå›é¡¾`create_agent`åˆ›å»ºçš„Agentæ˜¯å¦‚ä½•å·¥ä½œçš„:

```python
from langchain.agents import create_agent
from langchain_openai import ChatOpenAI

agent = create_agent(
    model=ChatOpenAI(model="gpt-4o"),
    tools=[search_tool, calculator_tool]
)

result = agent.invoke({"messages": [("user", "æœç´¢æœ€æ–°æ–°é—»")]})
```

**å†…éƒ¨æ‰§è¡Œæµç¨‹**:

```mermaid
graph LR
    A[ç”¨æˆ·è¾“å…¥] --> B[æ¨¡å‹æ¨ç†]
    B --> C{éœ€è¦å·¥å…·?}
    C -->|æ˜¯| D[è°ƒç”¨å·¥å…·]
    D --> B
    C -->|å¦| E[è¿”å›ç»“æœ]
```

**é—®é¢˜**: è¿™ä¸ªæµç¨‹æ˜¯"é»‘ç›’",æˆ‘ä»¬æ— æ³•å¹²é¢„ä¸­é—´æ­¥éª¤ã€‚

#### 1.1.2 Middlewareçš„åˆ‡å…¥ç‚¹

**Middleware**åœ¨Agentæ‰§è¡Œçš„å…³é”®èŠ‚ç‚¹æä¾›**Hook(é’©å­)**,å…è®¸ä½ :

1. **before_agent**: Agentå¼€å§‹å‰ - åšæƒé™æ£€æŸ¥ã€è¾“å…¥éªŒè¯
2. **before_model**: è°ƒç”¨æ¨¡å‹å‰ - ä¿®æ”¹æç¤ºè¯ã€æ£€æŸ¥Token
3. **wrap_model_call**: åŒ…è£…æ¨¡å‹è°ƒç”¨ - ç¼“å­˜ã€é‡è¯•ã€é™çº§
4. **after_model**: æ¨¡å‹å“åº”å - å®¡æ ¸è¾“å‡ºã€è®°å½•æ—¥å¿—
5. **wrap_tool_call**: åŒ…è£…å·¥å…·è°ƒç”¨ - é‡è¯•ã€é™æµã€å®¡æ‰¹
6. **after_agent**: Agentç»“æŸå - ä¿å­˜ç»“æœã€è®¡è´¹

**å®Œæ•´æµç¨‹**:

```mermaid
sequenceDiagram
    participant User
    participant before_agent
    participant before_model
    participant wrap_model_call
    participant Model
    participant after_model
    participant wrap_tool_call
    participant Tool
    participant after_agent

    User->>before_agent: è¾“å…¥
    before_agent->>before_model: state
    before_model->>wrap_model_call: state
    wrap_model_call->>Model: request
    Model-->>wrap_model_call: response
    wrap_model_call->>after_model: state

    alt éœ€è¦å·¥å…·
        after_model->>wrap_tool_call: tool_call
        wrap_tool_call->>Tool: execute
        Tool-->>wrap_tool_call: result
        wrap_tool_call->>before_model: ç»§ç»­å¾ªç¯
    else ä¸éœ€è¦å·¥å…·
        after_model->>after_agent: final state
        after_agent-->>User: ç»“æœ
    end
```

#### 1.1.3 æ ¸å¿ƒä»·å€¼

| ç»´åº¦ | æ²¡æœ‰Middleware | ä½¿ç”¨Middleware |
|------|--------------|---------------|
| **å®‰å…¨** | å¯èƒ½æ³„éœ²PII | PIIMiddlewareè‡ªåŠ¨è„±æ• |
| **æˆæœ¬** | æ— é™åˆ¶è°ƒç”¨ | ModelCallLimitMiddlewareé™åˆ¶æ¬¡æ•° |
| **å¯é æ€§** | å·¥å…·å¤±è´¥ç›´æ¥æŠ¥é”™ | ToolRetryMiddlewareè‡ªåŠ¨é‡è¯• |
| **å¯è§‚æµ‹** | é»‘ç›’æ‰§è¡Œ | LoggingMiddlewareè®°å½•æ‰€æœ‰æ­¥éª¤ |
| **åˆè§„** | æ— äººå·¥å®¡æ‰¹ | HumanInTheLoopMiddlewareå¼ºåˆ¶å®¡æ‰¹ |

---

### 1.2 å…­å¤§Hookä½“ç³»

#### 1.2.1 Hookåˆ†ç±»

LangChain Middlewareæä¾›**6ä¸ªHook**,åˆ†ä¸ºä¸¤ç±»:

**Node-Style Hooks** (èŠ‚ç‚¹å‹):

- é¡ºåºæ‰§è¡Œ
- è¿”å›`dict`ä¿®æ”¹state,è¿”å›`None`æ²¿ç”¨åŸå€¼
- Hooks: `before_agent`, `before_model`, `after_model`, `after_agent`

**Wrap-Style Hooks** (åŒ…è£…å‹):
- åµŒå¥—æ‰§è¡Œ(æ´‹è‘±æ¨¡å‹)
- å®Œå…¨æ§åˆ¶è°ƒç”¨æµç¨‹,å¯çŸ­è·¯è¿”å›
- Hooks: `wrap_model_call`, `wrap_tool_call`

#### 1.2.2 Hookç­¾åè¯¦è§£

**Node-Style Hookç­¾å**:

```python
def before_agent(
    state: AgentState,      # å½“å‰çŠ¶æ€
    runtime: Runtime        # è¿è¡Œæ—¶ä¸Šä¸‹æ–‡
) -> dict[str, Any] | None:
    """
    Agentæ‰§è¡Œå‰çš„Hook

    Returns:
        dict: è¿”å›å­—å…¸ä¼šmergeåˆ°state
        None: æ²¿ç”¨åŸstate
    """
    pass
```

**Wrap-Style Hookç­¾å**:

```python
def wrap_model_call(
    request: ModelRequest,         # æ¨¡å‹è¯·æ±‚
    handler: Callable[[ModelRequest], ModelResponse]  # æ‰§è¡Œå™¨
) -> ModelResponse | AIMessage:
    """
    åŒ…è£…æ¨¡å‹è°ƒç”¨

    Args:
        request: åŒ…å«model, messages, toolsç­‰çš„è¯·æ±‚å¯¹è±¡
        handler: å®é™…æ‰§è¡Œæ¨¡å‹è°ƒç”¨çš„å‡½æ•°

    Returns:
        ModelResponse æˆ– AIMessage
    """
    # å¯ä»¥ä¿®æ”¹request
    request = request.override(model=different_model)

    # è°ƒç”¨å®é™…æ¨¡å‹(å¯å¤šæ¬¡è°ƒç”¨/ä¸è°ƒç”¨)
    response = handler(request)

    # å¯ä»¥ä¿®æ”¹response
    return response
```

#### 1.2.3 æ ¸å¿ƒç±»å‹

**1. AgentState**

```python
from langchain.agents.middleware import AgentState

class AgentState(TypedDict):
    messages: Required[Annotated[list[AnyMessage], add_messages]]
    # å¿…éœ€å­—æ®µ,æ¶ˆæ¯åˆ—è¡¨(ä½¿ç”¨add_messages reducer)

    jump_to: NotRequired[JumpTo | None]
    # å¯é€‰,è·³è½¬ç›®æ ‡: "tools" | "model" | "end"

    structured_response: NotRequired[Any]
    # å¯é€‰,ç»“æ„åŒ–è¾“å‡º
```

**2. Runtime[ContextT]**

```python
# Runtimeæ¥è‡ªlanggraph.runtime
# åŒ…å«è¿è¡Œæ—¶ä¸Šä¸‹æ–‡å’Œå·¥å…·

runtime.context  # ç”¨æˆ·è‡ªå®šä¹‰ä¸Šä¸‹æ–‡(å¦‚user_id, tenantç­‰)
runtime.store    # BaseStoreå®ä¾‹,æŒä¹…åŒ–å­˜å‚¨
```

**3. ModelRequest**

```python
@dataclass
class ModelRequest:
    model: BaseChatModel
    system_prompt: str | None
    messages: list[AnyMessage]
    tool_choice: Any | None
    tools: list[BaseTool | dict]
    response_format: ResponseFormat | None
    state: AgentState              # å½“å‰çŠ¶æ€
    runtime: Runtime[ContextT]     # è¿è¡Œæ—¶ä¸Šä¸‹æ–‡
    model_settings: dict[str, Any]

    def override(self, **overrides) -> ModelRequest:
        """ä¸å¯å˜æ›¿æ¢,è¿”å›æ–°çš„ModelRequest"""
```

**4. ModelResponse**

```python
@dataclass
class ModelResponse:
    result: list[BaseMessage]       # é€šå¸¸åŒ…å«1ä¸ªAIMessage
    structured_response: Any = None # ç»“æ„åŒ–è¾“å‡º(å¦‚æœæŒ‡å®š)
```

---

### 1.3 åˆ›å»ºç¬¬ä¸€ä¸ªMiddleware

#### 1.3.1 æ–¹å¼1: ä½¿ç”¨Decorator

**æœ€ç®€å•çš„æ–¹å¼** - ä½¿ç”¨decoratorå¿«é€Ÿåˆ›å»ºmiddleware:

```python
from langchain.agents.middleware import before_model, after_model

@before_model
def log_before_model(state, runtime):
    """æ¨¡å‹è°ƒç”¨å‰æ‰“å°æ—¥å¿—"""
    print(f"[LOG] å‡†å¤‡è°ƒç”¨æ¨¡å‹,å½“å‰æ¶ˆæ¯æ•°: {len(state['messages'])}")
    return None  # ä¸ä¿®æ”¹state

@after_model
def log_after_model(state, runtime):
    """æ¨¡å‹è°ƒç”¨åæ‰“å°æ—¥å¿—"""
    last_msg = state["messages"][-1]
    print(f"[LOG] æ¨¡å‹è¿”å›: {last_msg.content[:50]}...")
    return None

# ä½¿ç”¨
from langchain.agents import create_agent

agent = create_agent(
    model="gpt-4o",
    tools=[],
    middleware=[log_before_model, log_after_model]
)
```

**æ”¯æŒçš„decorators**:
- `@before_agent`
- `@before_model(can_jump_to=["end"])`  # å¯æŒ‡å®šå…è®¸è·³è½¬çš„ç›®æ ‡
- `@after_model`
- `@after_agent`
- `@wrap_model_call`
- `@wrap_tool_call`
- `@dynamic_prompt`  # åŠ¨æ€ç”Ÿæˆsystem prompt

#### 1.3.2 æ–¹å¼2: ç»§æ‰¿AgentMiddleware

**æ›´çµæ´»çš„æ–¹å¼** - ç»§æ‰¿`AgentMiddleware`ç±»:

```python
from langchain.agents.middleware import AgentMiddleware

class TokenCounterMiddleware(AgentMiddleware):
    """ç»Ÿè®¡Tokenä½¿ç”¨é‡"""

    def before_agent(self, state, runtime):
        """åˆå§‹åŒ–è®¡æ•°å™¨"""
        # æ³¨æ„: ä¸èƒ½åœ¨stateä¸­æ·»åŠ è‡ªå®šä¹‰å­—æ®µ,å› ä¸ºAgentStateæ˜¯å›ºå®šçš„
        # å¯ä»¥ä½¿ç”¨runtime.contextå­˜å‚¨è‡ªå®šä¹‰æ•°æ®
        return None

    def before_model(self, state, runtime):
        """æ¨¡å‹è°ƒç”¨å‰ç»Ÿè®¡"""
        # ç®€å•ä¼°ç®—: æ¯ä¸ªmessageçº¦100 tokens
        approx_tokens = len(state["messages"]) * 100
        print(f"ğŸ“Š é¢„ä¼°è¾“å…¥Token: {approx_tokens}")
        return None

    def after_model(self, state, runtime):
        """æ¨¡å‹è°ƒç”¨åç»Ÿè®¡"""
        # çœŸå®ç¯å¢ƒå¯ä»¥ä»response.usageä¸­è·å–
        print(f"ğŸ“Š æ¨¡å‹è°ƒç”¨å®Œæˆ")
        return None

# ä½¿ç”¨
agent = create_agent(
    model="gpt-4o",
    tools=[],
    middleware=[TokenCounterMiddleware()]
)
```

#### 1.3.3 å®æˆ˜: wrap_model_callå®ç°ç¼“å­˜

```python
from langchain.agents.middleware import wrap_model_call
from langchain_core.messages import AIMessage
import hashlib
import json

# ç®€å•çš„å†…å­˜ç¼“å­˜
_cache = {}

@wrap_model_call
def cache_middleware(request, handler):
    """ç¼“å­˜æ¨¡å‹å“åº”"""

    # 1. è®¡ç®—ç¼“å­˜é”®(åŸºäºmessageså†…å®¹)
    messages_str = json.dumps([
        {"role": m.type, "content": str(m.content)}
        for m in request.messages
    ], sort_keys=True)
    cache_key = hashlib.md5(messages_str.encode()).hexdigest()

    # 2. æ£€æŸ¥ç¼“å­˜
    if cache_key in _cache:
        print("âœ… ç¼“å­˜å‘½ä¸­!")
        return _cache[cache_key]

    # 3. ç¼“å­˜æœªå‘½ä¸­,è°ƒç”¨æ¨¡å‹
    print("âŒ ç¼“å­˜æœªå‘½ä¸­,è°ƒç”¨æ¨¡å‹...")
    response = handler(request)

    # 4. ä¿å­˜åˆ°ç¼“å­˜
    _cache[cache_key] = response

    return response

# æµ‹è¯•
agent = create_agent(
    model="gpt-4o-mini",  # ä½¿ç”¨miniæµ‹è¯•
    tools=[],
    middleware=[cache_middleware]
)

# ç¬¬ä¸€æ¬¡è°ƒç”¨
result1 = agent.invoke({"messages": [("user", "hi")]})
# è¾“å‡º: âŒ ç¼“å­˜æœªå‘½ä¸­,è°ƒç”¨æ¨¡å‹...

# ç¬¬äºŒæ¬¡ç›¸åŒè¾“å…¥
result2 = agent.invoke({"messages": [("user", "hi")]})
# è¾“å‡º: âœ… ç¼“å­˜å‘½ä¸­!
```

#### 1.3.4 å®æˆ˜: wrap_tool_callå®ç°é‡è¯•

```python
from langchain.agents.middleware import wrap_tool_call
from langchain_core.messages import ToolMessage
import time

@wrap_tool_call
def retry_on_error(request, handler):
    """å·¥å…·è°ƒç”¨å¤±è´¥æ—¶é‡è¯•3æ¬¡"""

    max_retries = 3
    for attempt in range(max_retries):
        try:
            result = handler(request)
            print(f"âœ… å·¥å…·è°ƒç”¨æˆåŠŸ (å°è¯• {attempt + 1})")
            return result
        except Exception as e:
            print(f"âŒ å·¥å…·è°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}): {e}")

            if attempt == max_retries - 1:
                # æœ€åä¸€æ¬¡ä»å¤±è´¥,è¿”å›é”™è¯¯æ¶ˆæ¯
                return ToolMessage(
                    content=f"å·¥å…·è°ƒç”¨å¤±è´¥(é‡è¯•{max_retries}æ¬¡): {str(e)}",
                    tool_call_id=request.tool_call["id"]
                )

            # æŒ‡æ•°é€€é¿
            time.sleep(2 ** attempt)
```

---

### 1.4 Hookæ‰§è¡Œé¡ºåº

#### 1.4.1 å¤šä¸ªMiddlewareçš„æ‰§è¡Œé¡ºåº

å½“ä¼ å…¥å¤šä¸ªmiddlewareæ—¶,æ‰§è¡Œé¡ºåºè§„åˆ™:

```python
middleware = [A, B, C]

# before_* hooks: é¡ºåºæ‰§è¡Œ A â†’ B â†’ C
# wrap_* hooks: åµŒå¥—æ‰§è¡Œ AåŒ…è£…BåŒ…è£…C (æ´‹è‘±æ¨¡å‹)
# after_* hooks: é€†åºæ‰§è¡Œ C â†’ B â†’ A
```

**ç¤ºä¾‹**:

```python
@before_model
def middleware_a(state, runtime):
    print("A: before_model")
    return None

@before_model
def middleware_b(state, runtime):
    print("B: before_model")
    return None

@after_model
def middleware_c(state, runtime):
    print("C: after_model")
    return None

agent = create_agent(
    model="gpt-4o-mini",
    tools=[],
    middleware=[middleware_a, middleware_b, middleware_c]
)

agent.invoke({"messages": [("user", "hi")]})

# è¾“å‡ºé¡ºåº:
# A: before_model
# B: before_model
# (æ¨¡å‹è°ƒç”¨)
# C: after_model
```

**wrap_* hooksçš„æ´‹è‘±æ¨¡å‹**:

```python
# å‡è®¾æœ‰3ä¸ªwrap_model_call middleware: [A, B, C]
# å®é™…æ‰§è¡Œ:
def final_call(request):
    return A.wrap_model_call(request, lambda r1:
        B.wrap_model_call(r1, lambda r2:
            C.wrap_model_call(r2, lambda r3:
                actual_model_call(r3)
            )
        )
    )
# Aæœ€å¤–å±‚,Cæœ€å†…å±‚
```

---

### 1.5 jump_to: æ¡ä»¶è·³è½¬

#### 1.5.1 ä»€ä¹ˆæ˜¯jump_to

åœ¨`before_model`æˆ–`after_model` hookä¸­,å¯ä»¥è¿”å›`{"jump_to": "end"}`æ¥æå‰ç»“æŸAgentæ‰§è¡Œ:

**å…è®¸çš„è·³è½¬ç›®æ ‡**:
- `"end"`: ç»“æŸAgentæ‰§è¡Œ
- `"tools"`: è·³åˆ°å·¥å…·æ‰§è¡ŒèŠ‚ç‚¹
- `"model"`: è·³å›æ¨¡å‹èŠ‚ç‚¹(é‡æ–°è°ƒç”¨æ¨¡å‹)

**ä½¿ç”¨åœºæ™¯**:
- æ£€æµ‹åˆ°"å†è§"ç­‰ç»“æŸè¯,ç›´æ¥ç»“æŸå¯¹è¯
- æ£€æµ‹åˆ°ç‰¹å®šæ¡ä»¶,è·³è¿‡æ¨¡å‹è°ƒç”¨
- å®ç°è‡ªå®šä¹‰çš„è·¯ç”±é€»è¾‘

#### 1.5.2 å®æˆ˜: æ—©é€€å‡ºMiddleware

```python
from langchain.agents.middleware import before_model
from langchain_core.messages import AIMessage

@before_model(can_jump_to=["end"])
def early_exit_on_goodbye(state, runtime):
    """æ£€æµ‹åˆ°'å†è§'ç›´æ¥ç»“æŸ"""

    # è·å–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
    messages = state["messages"]
    if not messages:
        return None

    last_msg = messages[-1]
    if hasattr(last_msg, "content") and "å†è§" in last_msg.content:
        print("ğŸšª æ£€æµ‹åˆ°'å†è§',ç›´æ¥ç»“æŸå¯¹è¯")

        # æ·»åŠ ä¸€æ¡AIæ¶ˆæ¯,ç„¶åè·³è½¬åˆ°end
        new_messages = messages + [
            AIMessage(content="å†è§!å¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚")
        ]

        return {
            "messages": new_messages,
            "jump_to": "end"  # è·³è½¬åˆ°ç»“æŸèŠ‚ç‚¹
        }

    return None

# æµ‹è¯•
agent = create_agent(
    model="gpt-4o-mini",
    tools=[],
    middleware=[early_exit_on_goodbye]
)

result = agent.invoke({"messages": [("user", "å†è§")]})
# è¾“å‡º: ğŸšª æ£€æµ‹åˆ°'å†è§',ç›´æ¥ç»“æŸå¯¹è¯
# ä¸ä¼šè°ƒç”¨æ¨¡å‹,ç›´æ¥è¿”å›é¢„è®¾çš„å›å¤
```

**æ³¨æ„**: å¿…é¡»ä½¿ç”¨`@before_model(can_jump_to=["end"])`å£°æ˜å…è®¸çš„è·³è½¬ç›®æ ‡,å¦åˆ™ä¼šæŠ¥é”™ã€‚

---

### æœ¬ç« å°ç»“

1. **Middlewareæ˜¯ä»€ä¹ˆ**: Agentæ‰§è¡Œæµç¨‹ä¸­çš„Hookç‚¹,å…è®¸ç²¾å‡†å¹²é¢„
2. **å…­å¤§Hook**:
   - Node-Style: `before_agent`, `before_model`, `after_model`, `after_agent`
   - Wrap-Style: `wrap_model_call`, `wrap_tool_call`
3. **æ ¸å¿ƒç±»å‹**: `AgentState`, `Runtime`, `ModelRequest`, `ModelResponse`
4. **åˆ›å»ºæ–¹å¼**: Decorator(å¿«é€Ÿ) vs ç»§æ‰¿AgentMiddleware(çµæ´»)
5. **æ‰§è¡Œé¡ºåº**: beforeé¡ºåº, wrapåµŒå¥—(æ´‹è‘±), afteré€†åº
6. **jump_to**: æ¡ä»¶è·³è½¬,æå‰ç»“æŸæˆ–è·¯ç”±

**ä¸‹ä¸€ç« é¢„å‘Š**: å­¦ä¹ LangChainæä¾›çš„æ‰€æœ‰å†…ç½®Middleware,ä»¥åŠå¦‚ä½•è‡ªå®šä¹‰å¼€å‘ã€‚

---

(ç¬¬1ç« å®Œæˆ,å­—æ•°çº¦4500å­—)

<å¾…ç»­...>

## ç¬¬2ç« ï¼šå†…ç½®Middlewareä¸è‡ªå®šä¹‰å¼€å‘

> **æœ¬ç« ç›®æ ‡**: æŒæ¡æ‰€æœ‰å†…ç½®Middlewareçš„ä½¿ç”¨,ä»¥åŠè‡ªå®šä¹‰å¼€å‘æ–¹æ³•

LangChainæä¾›äº†11ä¸ªå†…ç½®Middleware,è¦†ç›–å®‰å…¨ã€å¯é æ€§ã€æ€§èƒ½ç­‰åœºæ™¯ã€‚æœ¬ç« æŒ‰åŠŸèƒ½åˆ†ç±»è®²è§£ã€‚

### 2.1 å®‰å…¨ç±»Middleware

#### 2.1.1 PIIMiddleware - æ•æ„Ÿä¿¡æ¯è„±æ•

**åœºæ™¯**: é˜²æ­¢Agentåœ¨è¾“å…¥/è¾“å‡ºä¸­æ³„éœ²ä¸ªäººä¿¡æ¯(é‚®ç®±ã€ä¿¡ç”¨å¡å·ã€IPåœ°å€ç­‰)

**API**:

```python
from langchain.agents.middleware import PIIMiddleware

PIIMiddleware(
    pii_type: Literal['email', 'credit_card', 'ip', 'mac_address', 'url'],  # PIIç±»å‹
    *,
    strategy: Literal['block', 'redact', 'mask', 'hash'] = 'redact',  # å¤„ç†ç­–ç•¥
    detector: Callable | str | None = None,    # è‡ªå®šä¹‰æ£€æµ‹å™¨
    apply_to_input: bool = True,              # åº”ç”¨åˆ°ç”¨æˆ·è¾“å…¥
    apply_to_output: bool = False,            # åº”ç”¨åˆ°AIè¾“å‡º
    apply_to_tool_results: bool = False       # åº”ç”¨åˆ°å·¥å…·ç»“æœ
)
```

**ç­–ç•¥è¯´æ˜**:
- `block`: ç›´æ¥æ‹’ç»åŒ…å«PIIçš„è¯·æ±‚
- `redact`: æ›¿æ¢ä¸º`[REDACTED_EMAIL]`ç­‰
- `mask`: éƒ¨åˆ†é®è”½ (å¦‚`a***e@example.com`)
- `hash`: SHA-256å“ˆå¸Œ

**ç¤ºä¾‹1: è„±æ•ç”¨æˆ·è¾“å…¥ä¸­çš„é‚®ç®±**

```python
from langchain.agents import create_agent
from langchain.agents.middleware import PIIMiddleware

agent = create_agent(
    model="gpt-4o-mini",
    tools=[],
    middleware=[
        PIIMiddleware(
            pii_type="email",
            strategy="redact",
            apply_to_input=True  # æ£€æµ‹è¾“å…¥
        )
    ]
)

# æµ‹è¯•
result = agent.invoke({
    "messages": [("user", "æˆ‘çš„é‚®ç®±æ˜¯ alice@example.com")]
})

# å®é™…å‘é€ç»™æ¨¡å‹çš„æ¶ˆæ¯:
# "æˆ‘çš„é‚®ç®±æ˜¯ [REDACTED_EMAIL]"
```

**ç¤ºä¾‹2: æ£€æµ‹å¤šç§PIIç±»å‹**

```python
# æ¯ä¸ªPIIMiddlewareåªèƒ½æ£€æµ‹ä¸€ç§ç±»å‹
# éœ€è¦å¤šä¸ªå®ä¾‹æ¥æ£€æµ‹å¤šç§PII

agent = create_agent(
    model="gpt-4o-mini",
    tools=[],
    middleware=[
        PIIMiddleware(pii_type="email", strategy="redact"),
        PIIMiddleware(pii_type="credit_card", strategy="mask"),
        PIIMiddleware(pii_type="ip", strategy="hash")
    ]
)
```

**ç¤ºä¾‹3: blockç­–ç•¥ - ç›´æ¥æ‹’ç»**

```python
agent = create_agent(
    model="gpt-4o-mini",
    tools=[],
    middleware=[
        PIIMiddleware(
            pii_type="credit_card",
            strategy="block"  # æ£€æµ‹åˆ°ä¿¡ç”¨å¡å·ç›´æ¥æ‹’ç»
        )
    ]
)

# è¾“å…¥åŒ…å«ä¿¡ç”¨å¡å·ä¼šç›´æ¥æŠ›å¼‚å¸¸
try:
    agent.invoke({"messages": [("user", "æˆ‘çš„å¡å·æ˜¯ 4532-1234-5678-9010")]})
except Exception as e:
    print(f"è¢«æ‹¦æˆª: {e}")
```

#### 2.1.2 HumanInTheLoopMiddleware - äººå·¥å®¡æ‰¹

**åœºæ™¯**: å…³é”®æ“ä½œ(å¦‚å‘é€é‚®ä»¶ã€åˆ é™¤æ•°æ®)éœ€è¦äººå·¥ç¡®è®¤

**API**:

```python
from langchain.agents.middleware import HumanInTheLoopMiddleware

HumanInTheLoopMiddleware(
    interrupt_on: dict[str, bool | InterruptOnConfig],  # ä¸­æ–­é…ç½®
    *,
    description_prefix: str = 'Tool execution requires approval'
)
```

**interrupt_oné…ç½®**:
- `"tool_start": True` - å·¥å…·è°ƒç”¨å‰ä¸­æ–­
- `"tool_end": True` - å·¥å…·è°ƒç”¨åä¸­æ–­

**ç¤ºä¾‹: å·¥å…·è°ƒç”¨å‰è¦æ±‚å®¡æ‰¹**

```python
from langchain.agents import create_agent
from langchain.agents.middleware import HumanInTheLoopMiddleware
from langgraph.checkpoint.memory import MemorySaver

# æ³¨æ„: HumanInTheLoopMiddlewareéœ€è¦é…åˆCheckpointerä½¿ç”¨
checkpointer = MemorySaver()

agent = create_agent(
    model="gpt-4o-mini",
    tools=[send_email_tool, search_tool],  # å‡è®¾æœ‰è¿™ä¸¤ä¸ªå·¥å…·
    checkpointer=checkpointer,
    middleware=[
        HumanInTheLoopMiddleware(
            interrupt_on={"tool_start": True}
        )
    ]
)

# ç¬¬ä¸€æ¬¡è°ƒç”¨:ä¼šåœ¨å·¥å…·è°ƒç”¨å‰ä¸­æ–­
config = {"configurable": {"thread_id": "thread-001"}}
result = agent.invoke(
    {"messages": [("user", "å‘é€é‚®ä»¶ç»™alice@example.com")]},
    config=config
)

# æ­¤æ—¶Agentä¸­æ–­,ç­‰å¾…å®¡æ‰¹
# éœ€è¦äººå·¥æ£€æŸ¥,ç„¶åæ¢å¤æ‰§è¡Œ:
from langgraph.types import Command

# æ‰¹å‡†æ‰§è¡Œ
agent.invoke(Command(resume=True), config=config)

# æˆ–æ‹’ç»æ‰§è¡Œ
agent.invoke(Command(resume=False), config=config)
```

---

### 2.2 å¯é æ€§ç±»Middleware

#### 2.2.1 ModelCallLimitMiddleware - é˜²æ­¢æ­»å¾ªç¯

**åœºæ™¯**: é™åˆ¶æ¨¡å‹è°ƒç”¨æ¬¡æ•°,é˜²æ­¢æ— é™å¾ªç¯ã€æ§åˆ¶æˆæœ¬

**API**:

```python
from langchain.agents.middleware import ModelCallLimitMiddleware

ModelCallLimitMiddleware(
    *,
    thread_limit: int | None = None,  # å•ä¸ªthreadæ€»é™åˆ¶
    run_limit: int | None = None,     # å•æ¬¡runé™åˆ¶
    exit_behavior: Literal['end', 'error'] = 'end'
)
```

**exit_behavior**:
- `'end'`: ä¼˜é›…ç»“æŸ,è¿”å›å½“å‰çŠ¶æ€
- `'error'`: æŠ›å‡ºå¼‚å¸¸

**ç¤ºä¾‹: é™åˆ¶å•æ¬¡è°ƒç”¨æœ€å¤š10æ¬¡æ¨¡å‹**

```python
from langchain.agents import create_agent
from langchain.agents.middleware import ModelCallLimitMiddleware

agent = create_agent(
    model="gpt-4o-mini",
    tools=[search_tool],
    middleware=[
        ModelCallLimitMiddleware(
            run_limit=10,             # å•æ¬¡æœ€å¤š10æ¬¡
            exit_behavior="end"       # è¶…é™åä¼˜é›…ç»“æŸ
        )
    ]
)

# å¦‚æœAgenté™·å…¥å¾ªç¯,åˆ°ç¬¬10æ¬¡ä¼šè‡ªåŠ¨åœæ­¢
result = agent.invoke({"messages": [("user", "å¸®æˆ‘å¾ªç¯æœç´¢100æ¬¡æ–°é—»")]})
```

#### 2.2.2 ToolCallLimitMiddleware - å·¥å…·è°ƒç”¨é™åˆ¶

**API**:

```python
from langchain.agents.middleware import ToolCallLimitMiddleware

ToolCallLimitMiddleware(
    *,
    tool_name: str | None = None,     # æŒ‡å®šå·¥å…·å(None=æ‰€æœ‰å·¥å…·)
    thread_limit: int | None = None,
    run_limit: int | None = None,
    exit_behavior: Literal['continue', 'error', 'end'] = 'continue'
)
```

**exit_behavior**:
- `'continue'`: ç»§ç»­æ‰§è¡Œä½†ä¸å†è°ƒç”¨å·¥å…·
- `'error'`: æŠ›å‡ºå¼‚å¸¸
- `'end'`: ç»“æŸæ‰§è¡Œ

**ç¤ºä¾‹: é™åˆ¶æ˜‚è´µAPIçš„è°ƒç”¨æ¬¡æ•°**

```python
from langchain.agents.middleware import ToolCallLimitMiddleware

agent = create_agent(
    model="gpt-4o-mini",
    tools=[expensive_api_tool, search_tool],
    middleware=[
        # é™åˆ¶expensive_api_toolå•æ¬¡æœ€å¤šè°ƒç”¨3æ¬¡
        ToolCallLimitMiddleware(
            tool_name="expensive_api",
            run_limit=3,
            exit_behavior="continue"  # è¶…é™åç»§ç»­,ä½†ä¸å†è°ƒç”¨æ­¤å·¥å…·
        )
    ]
)
```

#### 2.2.3 ToolRetryMiddleware - è‡ªåŠ¨é‡è¯•

**åœºæ™¯**: å·¥å…·è°ƒç”¨å¤±è´¥æ—¶è‡ªåŠ¨é‡è¯•(ç½‘ç»œæŠ–åŠ¨ã€ä¸´æ—¶æ•…éšœ)

**API**:

```python
from langchain.agents.middleware import ToolRetryMiddleware

ToolRetryMiddleware(
    *,
    max_retries: int = 2,                    # æœ€å¤šé‡è¯•2æ¬¡
    tools: list[BaseTool | str] | None = None,  # æŒ‡å®šå·¥å…·(None=æ‰€æœ‰)
    retry_on: tuple[type[Exception], ...] = (Exception,),  # é‡è¯•çš„å¼‚å¸¸ç±»å‹
    on_failure: Literal['raise', 'return_message'] = 'return_message',
    backoff_factor: float = 2.0,             # æŒ‡æ•°é€€é¿å› å­
    initial_delay: float = 1.0,              # åˆå§‹å»¶è¿Ÿ(ç§’)
    max_delay: float = 60.0,                 # æœ€å¤§å»¶è¿Ÿ(ç§’)
    jitter: bool = True                      # éšæœºæŠ–åŠ¨
)
```

**é‡è¯•å»¶è¿Ÿè®¡ç®—**: `min(initial_delay * (backoff_factor ^ retry_count), max_delay) + jitter`

**ç¤ºä¾‹: ç½‘ç»œè¯·æ±‚å·¥å…·è‡ªåŠ¨é‡è¯•**

```python
from langchain.agents.middleware import ToolRetryMiddleware

agent = create_agent(
    model="gpt-4o-mini",
    tools=[api_call_tool],
    middleware=[
        ToolRetryMiddleware(
            max_retries=3,          # æœ€å¤šé‡è¯•3æ¬¡
            initial_delay=1.0,      # ç¬¬1æ¬¡é‡è¯•ç­‰1ç§’
            backoff_factor=2.0,     # ç¬¬2æ¬¡ç­‰2ç§’,ç¬¬3æ¬¡ç­‰4ç§’
            jitter=True            # æ·»åŠ éšæœºæŠ–åŠ¨é¿å…é›·é¸£ç¾Šç¾¤
        )
    ]
)

# å¦‚æœapi_call_toolå¤±è´¥,ä¼šè‡ªåŠ¨é‡è¯•3æ¬¡
# å»¶è¿Ÿ: 1s â†’ 2s â†’ 4s (åŠ ä¸ŠéšæœºæŠ–åŠ¨)
```

#### 2.2.4 ModelFallbackMiddleware - æ¨¡å‹é™çº§

**åœºæ™¯**: ä¸»æ¨¡å‹å¤±è´¥æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°å¤‡ç”¨æ¨¡å‹

**API**:

```python
from langchain.agents.middleware import ModelFallbackMiddleware

ModelFallbackMiddleware(
    fallback_models: list[BaseChatModel],  # é™çº§æ¨¡å‹åˆ—è¡¨
    retry_on: tuple[type[Exception], ...] = (Exception,)
)
```

**ç¤ºä¾‹: GPT-4oå¤±è´¥æ—¶é™çº§åˆ°GPT-4o-mini**

```python
from langchain.agents import create_agent
from langchain.agents.middleware import ModelFallbackMiddleware
from langchain_openai import ChatOpenAI

agent = create_agent(
    model=ChatOpenAI(model="gpt-4o"),  # ä¸»æ¨¡å‹
    tools=[],
    middleware=[
        ModelFallbackMiddleware(
            fallback_models=[
                ChatOpenAI(model="gpt-4o-mini"),  # ç¬¬1ä¸ªå¤‡ç”¨
                ChatOpenAI(model="gpt-3.5-turbo")  # ç¬¬2ä¸ªå¤‡ç”¨
            ]
        )
    ]
)

# å¦‚æœgpt-4oè°ƒç”¨å¤±è´¥,ä¼šä¾æ¬¡å°è¯•gpt-4o-miniå’Œgpt-3.5-turbo
```

---

### 2.3 æ€§èƒ½ä¼˜åŒ–ç±»Middleware

#### 2.3.1 SummarizationMiddleware - å¯¹è¯æ‘˜è¦

**åœºæ™¯**: é•¿å¯¹è¯å¯¼è‡´Tokenè¶…é™,è‡ªåŠ¨æ‘˜è¦æ—§æ¶ˆæ¯

**API**:

```python
from langchain.agents.middleware import SummarizationMiddleware

SummarizationMiddleware(
    model: str | BaseChatModel,                    # ç”¨äºæ‘˜è¦çš„æ¨¡å‹
    max_tokens_before_summary: int | None = None,  # Tokené˜ˆå€¼
    messages_to_keep: int = 20,                    # ä¿ç•™æœ€è¿‘Næ¡æ¶ˆæ¯
    token_counter: Callable = count_tokens_approximately,
    summary_prompt: str = "<é»˜è®¤æç¤ºè¯>",
    summary_prefix: str = "## Previous conversation summary:"
)
```

**ç¤ºä¾‹: è¶…è¿‡2000 tokensæ—¶æ‘˜è¦**

```python
from langchain.agents.middleware import SummarizationMiddleware
from langchain_openai import ChatOpenAI

model = ChatOpenAI(model="gpt-4o")

agent = create_agent(
    model=model,
    tools=[],
    middleware=[
        SummarizationMiddleware(
            model=ChatOpenAI(model="gpt-4o-mini"),  # ç”¨ä¾¿å®œçš„æ¨¡å‹æ‘˜è¦
            max_tokens_before_summary=2000,        # è¶…è¿‡2000 tokensè§¦å‘
            messages_to_keep=6,                    # ä¿ç•™æœ€è¿‘6æ¡
            summary_prefix="## å¯¹è¯å†å²æ‘˜è¦:"
        )
    ]
)

# å½“å¯¹è¯è¶…è¿‡2000 tokensæ—¶:
# 1. ä¿ç•™æœ€è¿‘6æ¡æ¶ˆæ¯
# 2. å…¶ä½™æ¶ˆæ¯ç”¨gpt-4o-miniæ‘˜è¦
# 3. æ‘˜è¦ä½œä¸ºSystemMessageæ’å…¥åˆ°å¼€å¤´
```

#### 2.3.2 ContextEditingMiddleware - ä¸Šä¸‹æ–‡è£å‰ª

**åœºæ™¯**: è‡ªåŠ¨æ¸…ç†å·¥å…·è°ƒç”¨å†å²,å‡å°‘Tokenæ¶ˆè€—

**API**:

```python
from langchain.agents.middleware import ContextEditingMiddleware, ClearToolUsesEdit

ContextEditingMiddleware(
    *,
    edits: Iterable[ContextEdit] | None = None,
    token_count_method: Literal['approximate', 'model'] = 'approximate'
)
```

**ç¤ºä¾‹: è¶…è¿‡é˜ˆå€¼æ—¶æ¸…ç†å·¥å…·è°ƒç”¨**

```python
from langchain.agents.middleware import ContextEditingMiddleware, ClearToolUsesEdit

agent = create_agent(
    model="gpt-4o",
    tools=[search_tool, calculator_tool],
    middleware=[
        ContextEditingMiddleware(
            edits=[
                ClearToolUsesEdit(
                    trigger=("tokens", 1000)  # è¶…è¿‡1000 tokensæ—¶è§¦å‘
                )
            ]
        )
    ]
)

# å½“æ¶ˆæ¯ä¸­çš„ToolMessageè¿‡å¤šæ—¶,ä¼šè‡ªåŠ¨æ¸…ç†
# ä¿ç•™ToolCallä½†ç§»é™¤ToolMessageçš„content
```

---

### 2.4 èƒ½åŠ›å¢å¼ºç±»Middleware

#### 2.4.1 TodoListMiddleware - ä»»åŠ¡è§„åˆ’

**åŠŸèƒ½**: ä¸ºAgentæ·»åŠ `write_todos`å·¥å…·,æ”¯æŒä»»åŠ¡åˆ†è§£å’Œè¿›åº¦è¿½è¸ª

**API**:

```python
from langchain.agents.middleware import TodoListMiddleware

TodoListMiddleware(
    *,
    system_prompt: str = "<é»˜è®¤æç¤ºè¯>",
    tool_description: str = "<é»˜è®¤æè¿°>"
)
```

**ç¤ºä¾‹**:

```python
from langchain.agents.middleware import TodoListMiddleware

agent = create_agent(
    model="gpt-4o",
    tools=[search_tool, write_file_tool],
    middleware=[TodoListMiddleware()]
)

# Agentç°åœ¨å¯ä»¥ä½¿ç”¨write_todoså·¥å…·æ¥è§„åˆ’ä»»åŠ¡
result = agent.invoke({
    "messages": [("user", "ç ”ç©¶AIçš„æœ€æ–°è¿›å±•å¹¶å†™æˆæŠ¥å‘Š")]
})

# Agentä¼šè‡ªåŠ¨åˆ›å»ºtodo list:
# 1. æœç´¢AIæœ€æ–°è®ºæ–‡
# 2. æ€»ç»“å…³é”®å‘ç°
# 3. æ’°å†™æŠ¥å‘Š
# 4. ä¿å­˜åˆ°æ–‡ä»¶
```

#### 2.4.2 LLMToolSelectorMiddleware - æ™ºèƒ½å·¥å…·ç­›é€‰

**åœºæ™¯**: å·¥å…·å¤ªå¤š(50+)å¯¼è‡´æ¨¡å‹æ··ä¹±,åŠ¨æ€ç­›é€‰ç›¸å…³å·¥å…·

**API**:

```python
from langchain.agents.middleware import LLMToolSelectorMiddleware

LLMToolSelectorMiddleware(
    *,
    model: str | BaseChatModel | None = None,  # ç­›é€‰æ¨¡å‹(None=ä¸»æ¨¡å‹)
    system_prompt: str = "Your goal is to select the most relevant tools...",
    max_tools: int | None = None,              # æœ€å¤šé€‰Nä¸ªå·¥å…·
    always_include: list[str] | None = None    # å§‹ç»ˆåŒ…å«çš„å·¥å…·
)
```

**ç¤ºä¾‹: ä»50ä¸ªå·¥å…·ä¸­ç­›é€‰5ä¸ª**

```python
from langchain.agents.middleware import LLMToolSelectorMiddleware

# å‡è®¾æœ‰50ä¸ªå·¥å…·
all_tools = [tool1, tool2, ..., tool50]

agent = create_agent(
    model="gpt-4o",
    tools=all_tools,
    middleware=[
        LLMToolSelectorMiddleware(
            model="gpt-4o-mini",    # ç”¨ä¾¿å®œæ¨¡å‹ç­›é€‰
            max_tools=5,            # æœ€å¤šé€‰5ä¸ª
            always_include=["search"]  # searchå·¥å…·å§‹ç»ˆåŒ…å«
        )
    ]
)

# Agentåœ¨è°ƒç”¨å‰ä¼šå…ˆç”¨LLMç­›é€‰å‡ºæœ€ç›¸å…³çš„5ä¸ªå·¥å…·
```

#### 2.4.3 LLMToolEmulator - å·¥å…·æ¨¡æ‹Ÿ

**åœºæ™¯**: æµ‹è¯•æ—¶æ¨¡æ‹Ÿå·¥å…·æ‰§è¡Œ,ä¸å®é™…è°ƒç”¨å¤–éƒ¨API

**API**:

```python
from langchain.agents.middleware import LLMToolEmulator

LLMToolEmulator(
    *,
    tools: list[str | BaseTool] | None = None,  # è¦æ¨¡æ‹Ÿçš„å·¥å…·(None=æ‰€æœ‰)
    model: str | BaseChatModel | None = None
)
```

**ç¤ºä¾‹: æ¨¡æ‹Ÿæ˜‚è´µçš„APIè°ƒç”¨**

```python
from langchain.agents.middleware import LLMToolEmulator

agent = create_agent(
    model="gpt-4o-mini",
    tools=[expensive_api_tool, local_tool],
    middleware=[
        LLMToolEmulator(
            tools=["expensive_api"],  # åªæ¨¡æ‹Ÿè¿™ä¸ªå·¥å…·
            model="gpt-4o-mini"
        )
    ]
)

# expensive_api_toolä¸ä¼šå®é™…è°ƒç”¨,ç”±LLMæ¨¡æ‹Ÿè¿”å›ç»“æœ
# local_toolæ­£å¸¸æ‰§è¡Œ
```

---

### 2.5 è‡ªå®šä¹‰Middlewareå¼€å‘

#### 2.5.1 å¼€å‘è§„èŒƒ

**æœ€ä½³å®è·µ**:

1. **ç»§æ‰¿AgentMiddleware**: è¦†ç›–éœ€è¦çš„Hook
2. **è¿”å›å€¼è§„åˆ™**:
   - Node-Style: è¿”å›`dict`ä¿®æ”¹state,`None`æ²¿ç”¨åŸå€¼
   - Wrap-Style: å¿…é¡»è¿”å›`ModelResponse`æˆ–`ToolMessage`
3. **é¿å…é˜»å¡I/O**: ä¸è¦åœ¨Hookä¸­åšåŒæ­¥æ•°æ®åº“æŸ¥è¯¢
4. **å¹‚ç­‰è®¾è®¡**: é¿å…é‡å¤æ‰§è¡Œäº§ç”Ÿå‰¯ä½œç”¨

#### 2.5.2 å®æˆ˜: æˆæœ¬è¿½è¸ªMiddleware

```python
from langchain.agents.middleware import AgentMiddleware

class CostTrackingMiddleware(AgentMiddleware):
    """è¿½è¸ªæ¨¡å‹è°ƒç”¨æˆæœ¬"""

    # ä»·æ ¼(ç¾å…ƒ/1K tokens)
    PRICING = {
        "gpt-4o": {"input": 0.005, "output": 0.015},
        "gpt-4o-mini": {"input": 0.00015, "output": 0.0006},
    }

    def __init__(self):
        self.total_cost = 0.0
        self.call_count = 0

    def after_model(self, state, runtime):
        """æ¨¡å‹è°ƒç”¨åè®¡ç®—æˆæœ¬"""
        self.call_count += 1

        # ç®€åŒ–: ä¼°ç®—tokenæ•°(å®é™…åº”ä»response.usageè·å–)
        messages = state["messages"]
        input_tokens = sum(len(str(m.content).split()) for m in messages[:-1]) * 1.3
        output_tokens = len(str(messages[-1].content).split()) * 1.3

        # ä»runtime.contextè·å–æ¨¡å‹åç§°
        model_name = "gpt-4o-mini"  # ç®€åŒ–,å®é™…åº”ä»requestè·å–

        # è®¡ç®—æˆæœ¬
        pricing = self.PRICING.get(model_name, self.PRICING["gpt-4o-mini"])
        cost = (
            input_tokens / 1000 * pricing["input"] +
            output_tokens / 1000 * pricing["output"]
        )

        self.total_cost += cost
        print(f"ğŸ’° æœ¬æ¬¡è°ƒç”¨: ${cost:.6f}, ç´¯è®¡: ${self.total_cost:.6f}")

        return None

    def after_agent(self, state, runtime):
        """Agentç»“æŸåè¾“å‡ºæ€»æˆæœ¬"""
        print(f"ğŸ“Š æ€»è®¡: {self.call_count}æ¬¡è°ƒç”¨, æˆæœ¬${self.total_cost:.4f}")
        return None

# ä½¿ç”¨
cost_tracker = CostTrackingMiddleware()
agent = create_agent(
    model="gpt-4o-mini",
    tools=[],
    middleware=[cost_tracker]
)

result = agent.invoke({"messages": [("user", "è®²ä¸ªç¬‘è¯")]})
# è¾“å‡º:
# ğŸ’° æœ¬æ¬¡è°ƒç”¨: $0.000123, ç´¯è®¡: $0.000123
# ğŸ“Š æ€»è®¡: 1æ¬¡è°ƒç”¨, æˆæœ¬$0.0001
```

#### 2.5.3 å®æˆ˜: åŠ¨æ€æ¨¡å‹è·¯ç”±Middleware

```python
from langchain.agents.middleware import AgentMiddleware
from langchain_openai import ChatOpenAI

class DynamicModelRouter(AgentMiddleware):
    """æ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ‹©æ¨¡å‹"""

    def __init__(self):
        self.fast_model = ChatOpenAI(model="gpt-4o-mini")
        self.smart_model = ChatOpenAI(model="gpt-4o")

    def wrap_model_call(self, request, handler):
        """æ¨¡å‹è°ƒç”¨å‰è·¯ç”±"""

        # åˆ†æä»»åŠ¡å¤æ‚åº¦
        last_msg = request.messages[-1].content if request.messages else ""

        # ç®€å•è§„åˆ™: é•¿æ–‡æœ¬æˆ–åŒ…å«"å¤æ‚"å…³é”®è¯ç”¨é«˜çº§æ¨¡å‹
        is_complex = (
            len(last_msg) > 500 or
            any(kw in last_msg for kw in ["å¤æ‚", "è¯¦ç»†", "æ·±å…¥", "åˆ†æ"])
        )

        # è·¯ç”±åˆ°ä¸åŒæ¨¡å‹
        if is_complex:
            print("ğŸ§  ä½¿ç”¨é«˜çº§æ¨¡å‹(gpt-4o)")
            request = request.override(model=self.smart_model)
        else:
            print("âš¡ ä½¿ç”¨å¿«é€Ÿæ¨¡å‹(gpt-4o-mini)")
            request = request.override(model=self.fast_model)

        return handler(request)

# ä½¿ç”¨
agent = create_agent(
    model="gpt-4o",  # é»˜è®¤æ¨¡å‹(ä¼šè¢«middlewareè¦†ç›–)
    tools=[],
    middleware=[DynamicModelRouter()]
)

# ç®€å•é—®é¢˜ â†’ gpt-4o-mini
result1 = agent.invoke({"messages": [("user", "hi")]})
# è¾“å‡º: âš¡ ä½¿ç”¨å¿«é€Ÿæ¨¡å‹(gpt-4o-mini)

# å¤æ‚é—®é¢˜ â†’ gpt-4o
result2 = agent.invoke({"messages": [("user", "è¯·è¯¦ç»†åˆ†æé‡å­è®¡ç®—çš„åŸç†")]})
# è¾“å‡º: ğŸ§  ä½¿ç”¨é«˜çº§æ¨¡å‹(gpt-4o)
```

---

### æœ¬ç« å°ç»“

**å†…ç½®Middlewareåˆ†ç±»**:

| ç±»åˆ« | Middleware | æ ¸å¿ƒåŠŸèƒ½ |
|------|-----------|---------|
| **å®‰å…¨** | PIIMiddleware | PIIæ£€æµ‹ä¸è„±æ• |
| | HumanInTheLoopMiddleware | äººå·¥å®¡æ‰¹ |
| **å¯é æ€§** | ModelCallLimitMiddleware | é™åˆ¶æ¨¡å‹è°ƒç”¨ |
| | ToolCallLimitMiddleware | é™åˆ¶å·¥å…·è°ƒç”¨ |
| | ToolRetryMiddleware | è‡ªåŠ¨é‡è¯• |
| | ModelFallbackMiddleware | æ¨¡å‹é™çº§ |
| **æ€§èƒ½** | SummarizationMiddleware | å¯¹è¯æ‘˜è¦ |
| | ContextEditingMiddleware | ä¸Šä¸‹æ–‡è£å‰ª |
| **èƒ½åŠ›å¢å¼º** | TodoListMiddleware | ä»»åŠ¡è§„åˆ’ |
| | LLMToolSelectorMiddleware | å·¥å…·ç­›é€‰ |
| | LLMToolEmulator | å·¥å…·æ¨¡æ‹Ÿ |

**è‡ªå®šä¹‰å¼€å‘**:
1. ç»§æ‰¿`AgentMiddleware`
2. è¦†ç›–éœ€è¦çš„Hook
3. éµå¾ªæœ€ä½³å®è·µ(é¿å…é˜»å¡I/Oã€å¹‚ç­‰è®¾è®¡)

**ä¸‹ä¸€ç« é¢„å‘Š**: å­¦ä¹ å¦‚ä½•ç»„åˆå¤šä¸ªMiddlewareã€æµ‹è¯•ç­–ç•¥å’Œç”Ÿäº§çº§é…ç½®ã€‚

---

(ç¬¬2ç« å®Œæˆ,ç´¯è®¡çº¦12000å­—)

<å¾…ç»­...>

## ç¬¬3ç« ï¼šç»„åˆç­–ç•¥ä¸ç”Ÿäº§å®è·µ

> **æœ¬ç« ç›®æ ‡**: å°†Multiple Middlewareç»„åˆä½¿ç”¨,æŒæ¡æµ‹è¯•æ–¹æ³•å’Œç”Ÿäº§çº§é…ç½®

### 3.1 Middlewareç»„åˆç­–ç•¥

#### 3.1.1 æ‰§è¡Œé¡ºåºè§„åˆ™(é‡è¦!)

å½“ä¼ å…¥å¤šä¸ªmiddlewareæ—¶,æ‰§è¡Œé¡ºåºè§„åˆ™:

```python
middleware = [A, B, C]
```

**è§„åˆ™**:
1. **before_* hooks**: é¡ºåºæ‰§è¡Œ A â†’ B â†’ C
2. **wrap_* hooks**: åµŒå¥—æ‰§è¡Œ(æ´‹è‘±æ¨¡å‹) AåŒ…è£…BåŒ…è£…C
3. **after_* hooks**: é€†åºæ‰§è¡Œ C â†’ B â†’ A

**ç¤ºä¾‹éªŒè¯**:

```python
from langchain.agents.middleware import before_model, after_model

@before_model
def mw_a(state, runtime):
    print("A: before_model")
    return None

@before_model
def mw_b(state, runtime):
    print("B: before_model")
    return None

@after_model
def mw_c(state, runtime):
    print("C: after_model")
    return None

@after_model
def mw_d(state, runtime):
    print("D: after_model")
    return None

agent = create_agent(
    model="gpt-4o-mini",
    tools=[],
    middleware=[mw_a, mw_b, mw_c, mw_d]
)

result = agent.invoke({"messages": [("user", "hi")]})

# è¾“å‡ºé¡ºåº:
# A: before_model
# B: before_model
# (æ¨¡å‹è°ƒç”¨)
# D: after_model  â† æ³¨æ„:after hooksæ˜¯é€†åº!
# C: after_model
```

**wrap_* hooksçš„æ´‹è‘±æ¨¡å‹**:

```python
@wrap_model_call
def outer(request, handler):
    print("Outer: before")
    response = handler(request)
    print("Outer: after")
    return response

@wrap_model_call
def inner(request, handler):
    print("Inner: before")
    response = handler(request)
    print("Inner: after")
    return response

agent = create_agent(
    model="gpt-4o-mini",
    tools=[],
    middleware=[outer, inner]
)

result = agent.invoke({"messages": [("user", "hi")]})

# è¾“å‡º:
# Outer: before
# Inner: before
# (æ¨¡å‹è°ƒç”¨)
# Inner: after
# Outer: after
```

#### 3.1.2 åˆ†å±‚ç»„åˆç­–ç•¥

**æœ€ä½³å®è·µ**: æŒ‰åŠŸèƒ½åˆ†å±‚ç»„åˆ,ç¡®ä¿ä¼˜å…ˆçº§

```python
# ç¬¬1å±‚: å®‰å…¨ä¸åˆè§„(æœ€å…ˆæ‰§è¡Œ)
security_layer = [
    PIIMiddleware(pii_type="email", strategy="redact"),
    PIIMiddleware(pii_type="credit_card", strategy="block"),
]

# ç¬¬2å±‚: å¯é æ€§ä¿éšœ
reliability_layer = [
    ModelCallLimitMiddleware(run_limit=20),
    ToolRetryMiddleware(max_retries=3),
]

# ç¬¬3å±‚: æ€§èƒ½ä¼˜åŒ–
performance_layer = [
    SummarizationMiddleware(
        model="gpt-4o-mini",
        max_tokens_before_summary=2000,
        messages_to_keep=6
    ),
]

# ç¬¬4å±‚: è§‚æµ‹ä¸ç›‘æ§
observability_layer = [
    cost_tracker,  # è‡ªå®šä¹‰æˆæœ¬è¿½è¸ª
]

# ç»„åˆ(é¡ºåºå¾ˆé‡è¦!)
middleware = (
    security_layer +
    reliability_layer +
    performance_layer +
    observability_layer
)

agent = create_agent(
    model="gpt-4o",
    tools=[search_tool, database_tool],
    middleware=middleware
)
```

**ä¸ºä»€ä¹ˆè¿™ä¸ªé¡ºåº?**
1. **å®‰å…¨å±‚åœ¨æœ€å‰**: ç¡®ä¿æ‰€æœ‰è¯·æ±‚/å“åº”éƒ½ç»è¿‡PIIæ£€æŸ¥
2. **å¯é æ€§å±‚åœ¨ä¸­é—´**: é™åˆ¶è°ƒç”¨æ¬¡æ•°,é˜²æ­¢èµ„æºæµªè´¹
3. **æ€§èƒ½å±‚åœ¨å**: åœ¨å®‰å…¨å’Œå¯é æ€§ä¿éšœåå†åšä¼˜åŒ–
4. **è§‚æµ‹å±‚åœ¨æœ€å**: è®°å½•æœ€ç»ˆçŠ¶æ€

#### 3.1.3 å†²çªå¤„ç†

**é—®é¢˜**: å¤šä¸ªmiddlewareåŒæ—¶ä¿®æ”¹state

**ç¤ºä¾‹å†²çªåœºæ™¯**:

```python
@before_model
def add_context_a(state, runtime):
    messages = state["messages"]
    return {
        "messages": [SystemMessage("æ¥è‡ªAçš„ä¸Šä¸‹æ–‡")] + messages
    }

@before_model
def add_context_b(state, runtime):
    messages = state["messages"]
    return {
        "messages": [SystemMessage("æ¥è‡ªBçš„ä¸Šä¸‹æ–‡")] + messages
    }

# é—®é¢˜: Bä¼šè¦†ç›–Aæ·»åŠ çš„SystemMessageå—?
```

**ç­”æ¡ˆ**: ä¸ä¼š!state updatesæ˜¯**merge**çš„,ä¸æ˜¯replaceã€‚ä½†éœ€è¦æ³¨æ„:
- å¯¹äº`messages`å­—æ®µ,ä½¿ç”¨`add_messages` reducer,ä¼šè¿½åŠ è€Œä¸æ˜¯æ›¿æ¢
- å…¶ä»–å­—æ®µé»˜è®¤æ˜¯æ›¿æ¢

**è§£å†³æ–¹æ¡ˆ1: å¹‚ç­‰è®¾è®¡**

```python
@before_model
def idempotent_system_prompt(state, runtime):
    """å¹‚ç­‰çš„system promptæ³¨å…¥"""
    messages = state["messages"]

    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨system message
    has_system = any(isinstance(m, SystemMessage) for m in messages)

    if not has_system:
        return {
            "messages": [SystemMessage("ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹")] + messages
        }

    return None  # å·²å­˜åœ¨,è·³è¿‡
```

**è§£å†³æ–¹æ¡ˆ2: åˆå¹¶è€Œéæ›¿æ¢**

```python
@before_model
def merge_system_prompts(state, runtime):
    """åˆå¹¶å¤šä¸ªsystem prompts"""
    messages = state["messages"]

    # æå–æ‰€æœ‰system messages
    system_msgs = [m for m in messages if isinstance(m, SystemMessage)]
    other_msgs = [m for m in messages if not isinstance(m, SystemMessage)]

    # åˆå¹¶system messages
    if system_msgs:
        combined_content = "\n\n".join(m.content for m in system_msgs)
        new_messages = [SystemMessage(combined_content)] + other_msgs
        return {"messages": new_messages}

    return None
```

---

### 3.2 æµ‹è¯•ç­–ç•¥

#### 3.2.1 å•å…ƒæµ‹è¯•: æµ‹è¯•å•ä¸ªMiddleware

**ç­–ç•¥**: Mock stateå’Œruntime,éªŒè¯middlewareè¡Œä¸º

**ç¤ºä¾‹: æµ‹è¯•TokenCounterMiddleware**

```python
import pytest
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

def test_token_counter_before_model():
    """æµ‹è¯•before_model hook"""

    # åˆ›å»ºmiddlewareå®ä¾‹
    middleware = TokenCounterMiddleware()

    # Mock state
    state = {
        "messages": [
            HumanMessage(content="æµ‹è¯•æ¶ˆæ¯1"),
            AIMessage(content="æµ‹è¯•å›å¤1"),
            HumanMessage(content="æµ‹è¯•æ¶ˆæ¯2"),
        ]
    }

    # Mock runtime
    class MockRuntime:
        context = {}

    runtime = MockRuntime()

    # è°ƒç”¨hook
    result = middleware.before_model(state, runtime)

    # éªŒè¯: åº”è¯¥è¿”å›None(ä¸ä¿®æ”¹state)
    assert result is None

# è¿è¡Œæµ‹è¯•
test_token_counter_before_model()
print("âœ… æµ‹è¯•é€šè¿‡")
```

**ç¤ºä¾‹: æµ‹è¯•wrap_model_call**

```python
def test_cache_middleware():
    """æµ‹è¯•ç¼“å­˜middleware"""

    # åˆ›å»ºmiddleware
    @wrap_model_call
    def cache_mw(request, handler):
        # ç®€åŒ–ç‰ˆç¼“å­˜é€»è¾‘
        cache_key = str(request.messages)
        if cache_key in cache_mw._cache:
            return cache_mw._cache[cache_key]

        response = handler(request)
        cache_mw._cache[cache_key] = response
        return response

    cache_mw._cache = {}

    # Mock handler
    call_count = 0
    def mock_handler(request):
        nonlocal call_count
        call_count += 1
        return ModelResponse(result=[AIMessage(content="æµ‹è¯•å“åº”")])

    # Mock request
    from langchain.agents.middleware import ModelRequest
    request = ModelRequest(
        model=ChatOpenAI(model="gpt-4o-mini"),
        system_prompt=None,
        messages=[HumanMessage(content="æµ‹è¯•")],
        tool_choice=None,
        tools=[],
        response_format=None,
        state={"messages": []},
        runtime=MockRuntime()
    )

    # ç¬¬ä¸€æ¬¡è°ƒç”¨ - ç¼“å­˜miss
    response1 = cache_mw(request, mock_handler)
    assert call_count == 1

    # ç¬¬äºŒæ¬¡è°ƒç”¨ - ç¼“å­˜hit
    response2 = cache_mw(request, mock_handler)
    assert call_count == 1  # handleræ²¡æœ‰è¢«å†æ¬¡è°ƒç”¨
    assert response1 == response2

    print("âœ… ç¼“å­˜middlewareæµ‹è¯•é€šè¿‡")

test_cache_middleware()
```

#### 3.2.2 é›†æˆæµ‹è¯•: æµ‹è¯•å®Œæ•´Agent

**ç­–ç•¥**: ä½¿ç”¨çœŸå®æ¨¡å‹(gpt-4o-mini)æµ‹è¯•,éªŒè¯middlewareç»„åˆ

```python
def test_middleware_integration():
    """é›†æˆæµ‹è¯•: å¤šä¸ªmiddlewareç»„åˆ"""

    # åˆ›å»ºagent
    agent = create_agent(
        model="gpt-4o-mini",
        tools=[],
        middleware=[
            ModelCallLimitMiddleware(run_limit=5),
            cost_tracker,
        ]
    )

    # æµ‹è¯•æ­£å¸¸æµç¨‹
    result = agent.invoke({"messages": [("user", "hi")]})
    assert result["messages"][-1].content  # åº”è¯¥æœ‰å“åº”

    # æµ‹è¯•é™åˆ¶ç”Ÿæ•ˆ
    # (è¿™é‡Œçœç•¥,å®é™…éœ€è¦è§¦å‘å¾ªç¯åœºæ™¯)

    print("âœ… é›†æˆæµ‹è¯•é€šè¿‡")

test_middleware_integration()
```

---

### 3.3 ç”Ÿäº§çº§Middleware Stack

#### 3.3.1 ä¼ä¸šçº§é…ç½®ç¤ºä¾‹

```python
from langchain.agents import create_agent
from langchain.agents.middleware import (
    PIIMiddleware,
    ModelCallLimitMiddleware,
    ToolRetryMiddleware,
    SummarizationMiddleware,
    HumanInTheLoopMiddleware,
)
from langchain_openai import ChatOpenAI
from langgraph.checkpoint.postgres import PostgresSaver

# è‡ªå®šä¹‰middleware
class ProductionMonitoringMiddleware(AgentMiddleware):
    """ç”Ÿäº§ç¯å¢ƒç›‘æ§"""

    def __init__(self, metrics_client):
        self.metrics = metrics_client

    def before_agent(self, state, runtime):
        self.metrics.increment("agent.requests")
        return None

    def after_agent(self, state, runtime):
        self.metrics.increment("agent.success")
        return None

    def after_model(self, state, runtime):
        self.metrics.increment("model.calls")
        return None

# é…ç½®
def create_production_agent(
    model_name="gpt-4o",
    checkpointer=None,
    metrics_client=None
):
    """åˆ›å»ºç”Ÿäº§ç¯å¢ƒagent"""

    middleware = [
        # 1. å®‰å…¨å±‚
        PIIMiddleware(pii_type="email", strategy="redact", apply_to_input=True),
        PIIMiddleware(pii_type="credit_card", strategy="block", apply_to_input=True),

        # 2. ç›‘æ§å±‚
        ProductionMonitoringMiddleware(metrics_client),

        # 3. å¯é æ€§å±‚
        ModelCallLimitMiddleware(run_limit=30, thread_limit=100, exit_behavior="end"),
        ToolRetryMiddleware(max_retries=3, backoff_factor=2.0),

        # 4. æ€§èƒ½å±‚
        SummarizationMiddleware(
            model=ChatOpenAI(model="gpt-4o-mini"),
            max_tokens_before_summary=3000,
            messages_to_keep=8
        ),

        # 5. å®¡æ‰¹å±‚(å±é™©å·¥å…·)
        HumanInTheLoopMiddleware(
            interrupt_on={"tool_start": True}  # æ‰€æœ‰å·¥å…·éƒ½éœ€è¦å®¡æ‰¹
        ) if checkpointer else None,
    ]

    # è¿‡æ»¤None
    middleware = [m for m in middleware if m is not None]

    return create_agent(
        model=ChatOpenAI(model=model_name),
        tools=[search_tool, database_tool],
        checkpointer=checkpointer,
        middleware=middleware,
        system_prompt="ä½ æ˜¯ä¼ä¸šçº§AIåŠ©æ‰‹,è¯·è°¨æ…å¤„ç†æ•æ„Ÿä¿¡æ¯ã€‚"
    )

# ä½¿ç”¨
checkpointer = PostgresSaver.from_conn_string("postgresql://...")
metrics = MyMetricsClient()

agent = create_production_agent(
    model_name="gpt-4o",
    checkpointer=checkpointer,
    metrics_client=metrics
)
```

#### 3.3.2 ç¯å¢ƒåŒºåˆ†é…ç½®

```python
import os

# åŸºç¡€é…ç½®
BASE_MIDDLEWARE = [
    ModelCallLimitMiddleware(run_limit=30),
]

# å¼€å‘ç¯å¢ƒ
DEV_MIDDLEWARE = BASE_MIDDLEWARE + [
    # å¼€å‘ç¯å¢ƒä¸é™åˆ¶,æ–¹ä¾¿è°ƒè¯•
]

# æµ‹è¯•ç¯å¢ƒ
TEST_MIDDLEWARE = BASE_MIDDLEWARE + [
    # ä½¿ç”¨å·¥å…·æ¨¡æ‹Ÿ,ä¸å®é™…è°ƒç”¨å¤–éƒ¨API
    LLMToolEmulator(tools=["expensive_api"]),
]

# ç”Ÿäº§ç¯å¢ƒ
PROD_MIDDLEWARE = BASE_MIDDLEWARE + [
    PIIMiddleware(pii_type="email", strategy="redact"),
    PIIMiddleware(pii_type="credit_card", strategy="block"),
    ToolRetryMiddleware(max_retries=3),
    ProductionMonitoringMiddleware(metrics_client),
]

# æ ¹æ®ç¯å¢ƒé€‰æ‹©
env = os.getenv("ENV", "dev")
middleware = {
    "dev": DEV_MIDDLEWARE,
    "test": TEST_MIDDLEWARE,
    "prod": PROD_MIDDLEWARE,
}[env]

agent = create_agent(
    model="gpt-4o",
    tools=all_tools,
    middleware=middleware
)
```

#### 3.3.3 Feature Flagsé…ç½®

```python
class FeatureFlagMiddleware(AgentMiddleware):
    """æ ¹æ®feature flagsæ§åˆ¶åŠŸèƒ½"""

    def __init__(self, flags):
        self.flags = flags

    def before_model(self, state, runtime):
        # ä»runtime.contextè¯»å–ç”¨æˆ·ä¿¡æ¯
        user_id = runtime.context.get("user_id") if runtime.context else None

        # æ£€æŸ¥æ˜¯å¦å¯ç”¨å®éªŒæ€§åŠŸèƒ½
        if self.flags.is_enabled("experimental_prompt", user_id):
            messages = state["messages"]
            experimental_prompt = SystemMessage(
                "ä½¿ç”¨å®éªŒæ€§æ¨ç†æ¨¡å¼(CoT)è¿›è¡Œå›ç­”"
            )
            return {"messages": [experimental_prompt] + messages}

        return None

# ä½¿ç”¨
flags = FeatureFlagClient()

agent = create_agent(
    model="gpt-4o",
    tools=[],
    middleware=[FeatureFlagMiddleware(flags)]
)

# è°ƒç”¨æ—¶ä¼ å…¥user_id
from langgraph.runtime import Runtime

result = agent.invoke(
    {"messages": [("user", "æµ‹è¯•")]},
    config={
        "configurable": {
            "context": {"user_id": "user-123"}
        }
    }
)
```

---

### 3.4 æ€§èƒ½è€ƒé‡ä¸æœ€ä½³å®è·µ

#### 3.4.1 é¿å…é˜»å¡I/O

**âŒ ä¸å¥½çš„åšæ³•**:

```python
class BadMiddleware(AgentMiddleware):
    def before_model(self, state, runtime):
        # åŒæ­¥æ•°æ®åº“æŸ¥è¯¢ä¼šé˜»å¡!
        user = db.query("SELECT * FROM users WHERE id = ?", user_id)
        return {"user_info": user}
```

**âœ… å¥½çš„åšæ³•**:

```python
class GoodMiddleware(AgentMiddleware):
    def __init__(self):
        self.cache = {}

    def before_model(self, state, runtime):
        user_id = runtime.context.get("user_id") if runtime.context else None

        # ä»ç¼“å­˜è¯»å–
        if user_id in self.cache:
            return {"user_info": self.cache[user_id]}

        # ç¼“å­˜æœªå‘½ä¸­: ä½¿ç”¨å¼‚æ­¥æŸ¥è¯¢æˆ–è·³è¿‡
        # æˆ–è€…åœ¨agentåˆ›å»ºæ—¶é¢„åŠ è½½æ•°æ®
        return None
```

#### 3.4.2 æ§åˆ¶é™„åŠ æ¨¡å‹è°ƒç”¨

```python
# âŒ æ¯æ¬¡éƒ½è°ƒç”¨LLMåšå®‰å…¨æ£€æµ‹ - æˆæœ¬é«˜
class ExpensiveSafetyMiddleware(AgentMiddleware):
    def after_model(self, state, runtime):
        content = state["messages"][-1].content
        # è°ƒç”¨å¦ä¸€ä¸ªLLMåšå®‰å…¨æ£€æµ‹
        is_safe = safety_llm.check(content)  # é¢å¤–æˆæœ¬!
        return None

# âœ… ä½¿ç”¨è§„åˆ™æˆ–ä¾¿å®œæ¨¡å‹
class CheapSafetyMiddleware(AgentMiddleware):
    def after_model(self, state, runtime):
        content = state["messages"][-1].content

        # å…ˆç”¨æ­£åˆ™å¿«é€Ÿæ£€æµ‹
        if self.regex_check(content):
            return None

        # åªæœ‰å¯ç–‘æ—¶æ‰ç”¨ä¾¿å®œçš„LLM
        is_safe = ChatOpenAI(model="gpt-4o-mini").check(content)
        return None
```

#### 3.4.3 æŒ‡æ ‡æ”¶é›†

```python
import time

class MetricsMiddleware(AgentMiddleware):
    """æ”¶é›†æ€§èƒ½æŒ‡æ ‡"""

    def __init__(self, metrics_client):
        self.metrics = metrics_client

    def wrap_model_call(self, request, handler):
        """æµ‹é‡æ¨¡å‹è°ƒç”¨è€—æ—¶"""
        start = time.time()

        try:
            response = handler(request)
            elapsed = time.time() - start

            # è®°å½•æˆåŠŸè°ƒç”¨çš„è€—æ—¶
            self.metrics.histogram("model.call.duration", elapsed)
            self.metrics.increment("model.call.success")

            return response

        except Exception as e:
            elapsed = time.time() - start

            # è®°å½•å¤±è´¥
            self.metrics.increment("model.call.error")
            self.metrics.histogram("model.call.duration", elapsed)

            raise

    def wrap_tool_call(self, request, handler):
        """æµ‹é‡å·¥å…·è°ƒç”¨è€—æ—¶"""
        tool_name = request.tool_call["name"]
        start = time.time()

        try:
            result = handler(request)
            elapsed = time.time() - start

            self.metrics.histogram(f"tool.{tool_name}.duration", elapsed)
            self.metrics.increment(f"tool.{tool_name}.success")

            return result

        except Exception as e:
            elapsed = time.time() - start
            self.metrics.increment(f"tool.{tool_name}.error")
            raise
```

---

### æœ¬ç« å°ç»“

1. **æ‰§è¡Œé¡ºåº**:
   - before_* hooks: é¡ºåºæ‰§è¡Œ
   - wrap_* hooks: æ´‹è‘±æ¨¡å‹(åµŒå¥—)
   - after_* hooks: é€†åºæ‰§è¡Œ

2. **ç»„åˆç­–ç•¥**:
   - åˆ†å±‚ç»„åˆ: å®‰å…¨ â†’ å¯é æ€§ â†’ æ€§èƒ½ â†’ è§‚æµ‹
   - ç¯å¢ƒåŒºåˆ†: dev / test / prod
   - Feature flags: çµæ´»æ§åˆ¶åŠŸèƒ½å¼€å…³

3. **æµ‹è¯•**:
   - å•å…ƒæµ‹è¯•: mock stateå’Œruntime
   - é›†æˆæµ‹è¯•: çœŸå®æ¨¡å‹æµ‹è¯•

4. **æ€§èƒ½æœ€ä½³å®è·µ**:
   - é¿å…é˜»å¡I/O
   - æ§åˆ¶é™„åŠ æ¨¡å‹è°ƒç”¨
   - æ”¶é›†æ€§èƒ½æŒ‡æ ‡

---

### ç¬¬äº”ç¯‡æ€»ç»“

**æ ¸å¿ƒè¦ç‚¹**:

1. **Middlewareæ˜¯ä»€ä¹ˆ**: Agentæ‰§è¡Œæµç¨‹ä¸­çš„Hook,å®ç°ç²¾å‡†æ§åˆ¶
2. **å…­å¤§Hook**: before_agent, before_model, after_model, after_agent, wrap_model_call, wrap_tool_call
3. **å†…ç½®ç»„ä»¶**: 11ä¸ªmiddlewareè¦†ç›–å®‰å…¨/å¯é æ€§/æ€§èƒ½/èƒ½åŠ›å¢å¼º
4. **è‡ªå®šä¹‰å¼€å‘**: ç»§æ‰¿AgentMiddleware,è¦†ç›–éœ€è¦çš„Hook
5. **ç”Ÿäº§å®è·µ**: åˆ†å±‚ç»„åˆã€ç¯å¢ƒåŒºåˆ†ã€æµ‹è¯•ç­–ç•¥

**ä¸å…¶ä»–ç¯‡ç« çš„è”ç³»**:

- **ç¬¬ä¸‰ç¯‡(LangGraph)**: Middlewareè¿è¡Œåœ¨LangGraphä¹‹ä¸Š
- **ç¬¬å››ç¯‡(Deep Agents)**: deepagentså†…ç½®äº†TodoListç­‰middleware
- **ç¬¬å…­ç¯‡(ç›‘æ§è¯„ä¼°)**: Middlewareå¯è¾“å‡ºæŒ‡æ ‡ç»™LangSmith

**ä¸‹ä¸€æ­¥**: å­¦ä¹ å¦‚ä½•ä½¿ç”¨LangSmithè¿½è¸ªå’Œè¯„ä¼°Agentè´¨é‡ã€‚

---

### æ€è€ƒä¸ç»ƒä¹ 

1. **æ€è€ƒ**: å¦‚æœè¦å®ç°"é«˜ä»·å€¼ç”¨æˆ·è‡ªåŠ¨å‡çº§åˆ°GPT-4o"çš„åŠŸèƒ½,åº”è¯¥ç”¨å“ªä¸ªHook?

   <details>
   <summary>ç­”æ¡ˆ</summary>

   ä½¿ç”¨`wrap_model_call`,æ ¹æ®runtime.contextä¸­çš„user_idåˆ¤æ–­:

   ```python
   @wrap_model_call
   def premium_user_upgrade(request, handler):
       user_id = request.runtime.context.get("user_id")
       if user_id in premium_users:
           request = request.override(model=ChatOpenAI(model="gpt-4o"))
       return handler(request)
   ```
   </details>

2. **ç»ƒä¹ **: å®ç°ä¸€ä¸ª`RateLimitMiddleware`,é™åˆ¶å•ä¸ªç”¨æˆ·æ¯åˆ†é’Ÿæœ€å¤šè°ƒç”¨10æ¬¡Agentã€‚

   <details>
   <summary>å‚è€ƒç­”æ¡ˆ</summary>

   ```python
   import time
   from collections import defaultdict

   class RateLimitMiddleware(AgentMiddleware):
       def __init__(self, max_calls=10, window=60):
           self.max_calls = max_calls
           self.window = window
           self.calls = defaultdict(list)  # user_id -> [timestamps]

       def before_agent(self, state, runtime):
           user_id = runtime.context.get("user_id", "anonymous") if runtime.context else "anonymous"
           now = time.time()

           # æ¸…ç†è¿‡æœŸè®°å½•
           self.calls[user_id] = [
               t for t in self.calls[user_id]
               if now - t < self.window
           ]

           # æ£€æŸ¥é€Ÿç‡é™åˆ¶
           if len(self.calls[user_id]) >= self.max_calls:
               raise ValueError(
                   f"é€Ÿç‡é™åˆ¶: æ¯{self.window}ç§’æœ€å¤š{self.max_calls}æ¬¡è¯·æ±‚"
               )

           # è®°å½•æœ¬æ¬¡è°ƒç”¨
           self.calls[user_id].append(now)
           return None
   ```
   </details>

3. **æ€è€ƒ**: ä¸ºä»€ä¹ˆPIIMiddlewareè¦åˆ†å¤šä¸ªå®ä¾‹(æ¯ä¸ªæ£€æµ‹ä¸€ç§ç±»å‹),è€Œä¸æ˜¯ä¸€ä¸ªå®ä¾‹æ£€æµ‹æ‰€æœ‰ç±»å‹?

   <details>
   <summary>ç­”æ¡ˆ</summary>

   è®¾è®¡è€ƒé‡:
   - **å•ä¸€èŒè´£**: æ¯ä¸ªå®ä¾‹åªåšä¸€ä»¶äº‹,ä»£ç æ›´æ¸…æ™°
   - **çµæ´»é…ç½®**: ä¸åŒPIIç±»å‹å¯ä»¥ç”¨ä¸åŒç­–ç•¥(emailç”¨redact, credit_cardç”¨block)
   - **æ€§èƒ½**: å¯ä»¥å¹¶è¡Œæ£€æµ‹å¤šç§ç±»å‹
   - **æ‰©å±•æ€§**: æ–¹ä¾¿æ·»åŠ è‡ªå®šä¹‰æ£€æµ‹å™¨

   å¦‚æœéœ€è¦æ£€æµ‹å¤šç§ç±»å‹,ç»„åˆå¤šä¸ªå®ä¾‹å³å¯:
   ```python
   middleware=[
       PIIMiddleware("email", strategy="redact"),
       PIIMiddleware("credit_card", strategy="block"),
   ]
   ```
   </details>

4. **ç»ƒä¹ **: è®¾è®¡ä¸€ä¸ª"å¯¹è¯è´¨é‡è¯„åˆ†"çš„Middleware,åœ¨æ¯æ¬¡å¯¹è¯ç»“æŸåç»™å‡º1-5åˆ†çš„è¯„åˆ†ã€‚

---

**å‚è€ƒèµ„æº**:

- [LangChain Agentså®˜æ–¹æ–‡æ¡£](https://docs.langchain.com/oss/python/langchain/agents)
- [Middleware API Reference](https://reference.langchain.com/python/langchain/middleware/)
- [LangGraph Runtime](https://langchain-ai.github.io/langgraph/reference/runtime/)

---

(å…¨æ–‡å®Œæˆ,çº¦18000å­—)
