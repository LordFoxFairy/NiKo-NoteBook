# 4. Agentæœ€ä½³è®¾è®¡æ¨¡å¼ä¸ç”Ÿäº§å®è·µ

> **ç‰ˆæœ¬**: LangChain 1.0.7+ | LangGraph 1.0.3+
> **å®šä½**: Agentç³»ç»Ÿä»è®¾è®¡åˆ°ç”Ÿäº§çš„å®Œæ•´å®è·µæŒ‡å—
> **æ›´æ–°**: 2025-11-20

---

## æ¦‚è¿°

æœ¬ç¬”è®°ç³»ç»Ÿæ€»ç»“äº†å¤§æ¨¡å‹Agentå¼€å‘ä¸éƒ¨ç½²çš„æ ¸å¿ƒå®è·µ,æ¶µç›–æ¶æ„è®¾è®¡ã€æ€§èƒ½ä¼˜åŒ–ã€å¯é æ€§ä¿éšœã€ç›‘æ§è¿ç»´ç­‰ç”Ÿäº§ç¯èŠ‚ã€‚æ‰€æœ‰å†…å®¹åŸºäºçœŸå®é¡¹ç›®ç»éªŒ,æä¾›å¯è¿è¡Œçš„å®Œæ•´ä»£ç ç¤ºä¾‹ã€‚

### ä¸ã€ŠLangChainç¬”è®°ã€‹çš„å…³ç³»

å»ºè®®å­¦ä¹ è·¯å¾„:
```
ã€ŠLangChainç¬”è®°ã€‹ç¬¬ä¸€~ä¸‰ç¯‡ (åŸºç¡€) â†’ æœ¬å®è·µç¬”è®° (ç”Ÿäº§)
```

æœ¬ç¬”è®°æ·±åŒ–ã€ŠLangChainç¬”è®°ã€‹ç¬¬ä¸ƒç¯‡(é«˜çº§åº”ç”¨)å’Œç¬¬å…«ç¯‡(ç”Ÿäº§å®è·µ)çš„å†…å®¹,è¡¥å……å®æˆ˜ç»†èŠ‚ã€‚

### å­¦ä¹ ç›®æ ‡

**æŒæ¡æ ¸å¿ƒæŠ€èƒ½**:
- è®¾è®¡å¯æ‰©å±•çš„Agentæ¶æ„
- ä¼˜åŒ–å“åº”é€Ÿåº¦å’Œæˆæœ¬
- æ„å»ºå¯é çš„é”™è¯¯å¤„ç†æœºåˆ¶
- å»ºç«‹å®Œå–„çš„ç›‘æ§ä½“ç³»

**è¾¾æˆç”Ÿäº§æ ‡å‡†**:
- å“åº”æ—¶é—´ < 1s (P95)
- ç³»ç»Ÿå¯ç”¨æ€§ > 99.9%
- é”™è¯¯æ¢å¤è‡ªåŠ¨åŒ–
- å…¨é“¾è·¯å¯è§‚æµ‹

---

## ç›®å½•

### [ç¬¬ä¸€éƒ¨åˆ†: æ¶æ„è®¾è®¡æ¨¡å¼](#ç¬¬ä¸€éƒ¨åˆ†æ¶æ„è®¾è®¡æ¨¡å¼)
- [1.1 å•Agentæ¶æ„è®¾è®¡](#11-å•agentæ¶æ„è®¾è®¡)
- [1.2 çŠ¶æ€ç®¡ç†æœ€ä½³å®è·µ](#12-çŠ¶æ€ç®¡ç†æœ€ä½³å®è·µ)
- [1.3 å·¥å…·ç³»ç»Ÿè®¾è®¡](#13-å·¥å…·ç³»ç»Ÿè®¾è®¡)

### [ç¬¬äºŒéƒ¨åˆ†: æ€§èƒ½ä¼˜åŒ–å®æˆ˜](#ç¬¬äºŒéƒ¨åˆ†æ€§èƒ½ä¼˜åŒ–å®æˆ˜)
- [2.1 å“åº”é€Ÿåº¦ä¼˜åŒ–](#21-å“åº”é€Ÿåº¦ä¼˜åŒ–)
- [2.2 æˆæœ¬ä¼˜åŒ–ç­–ç•¥](#22-æˆæœ¬ä¼˜åŒ–ç­–ç•¥)
- [2.3 å¹¶å‘ä¸å¼‚æ­¥å¤„ç†](#23-å¹¶å‘ä¸å¼‚æ­¥å¤„ç†)

### [ç¬¬ä¸‰éƒ¨åˆ†: å¯é æ€§ä¿éšœ](#ç¬¬ä¸‰éƒ¨åˆ†å¯é æ€§ä¿éšœ)
- [3.1 é”™è¯¯å¤„ç†ä¸é‡è¯•](#31-é”™è¯¯å¤„ç†ä¸é‡è¯•)
- [3.2 é™çº§ä¸ç†”æ–­](#32-é™çº§ä¸ç†”æ–­)
- [3.3 æµ‹è¯•ç­–ç•¥](#33-æµ‹è¯•ç­–ç•¥)

### [ç¬¬å››éƒ¨åˆ†: ç›‘æ§è¿ç»´](#ç¬¬å››éƒ¨åˆ†ç›‘æ§è¿ç»´)
- [4.1 å¯è§‚æµ‹æ€§å»ºè®¾](#41-å¯è§‚æµ‹æ€§å»ºè®¾)
- [4.2 å…³é”®æŒ‡æ ‡ç›‘æ§](#42-å…³é”®æŒ‡æ ‡ç›‘æ§)

### [ç¬¬äº”éƒ¨åˆ†: æ¡ˆä¾‹ç ”ç©¶](#ç¬¬äº”éƒ¨åˆ†æ¡ˆä¾‹ç ”ç©¶)
- [5.1 æ™ºèƒ½å®¢æœAgentä¼˜åŒ–å®æˆ˜](#51-æ™ºèƒ½å®¢æœagentä¼˜åŒ–å®æˆ˜)

---

# ç¬¬ä¸€éƒ¨åˆ†:æ¶æ„è®¾è®¡æ¨¡å¼

## 1.1 å•Agentæ¶æ„è®¾è®¡

### æ ¸å¿ƒåŸåˆ™

å•Agentæ¶æ„éµå¾ªä»¥ä¸‹è®¾è®¡åŸåˆ™:

1. **å•ä¸€èŒè´£** - ä¸€ä¸ªAgentä¸“æ³¨è§£å†³ä¸€ç±»é—®é¢˜
2. **å·¥å…·é½å…¨** - é€šè¿‡å·¥å…·æ‰©å±•èƒ½åŠ›,è€Œéå¤æ‚é€»è¾‘
3. **çŠ¶æ€æ¸…æ™°** - æœ€å°åŒ–çŠ¶æ€ç®¡ç†å¤æ‚åº¦
4. **æ˜“äºæµ‹è¯•** - è¾“å…¥è¾“å‡ºæ˜ç¡®,å¯æµ‹è¯•æ€§å¼º

### ä¸‰ç§æ ¸å¿ƒæ¨¡å¼

#### æ¨¡å¼1: ReAct Agent (æ¨è â­â­â­â­â­)

**é€‚ç”¨åœºæ™¯**: 90%çš„Agentåº”ç”¨åœºæ™¯

**æ¶æ„å›¾**:
```
ç”¨æˆ·è¾“å…¥
   â†“
[Agent State]
   â†“
LLMæ¨ç† â†’ å†³ç­– â†’ å·¥å…·è°ƒç”¨ â†’ å·¥å…·æ‰§è¡Œ â†’ æ›´æ–°çŠ¶æ€
   â†‘                                        â†“
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å¾ªç¯ (ç›´åˆ°ä»»åŠ¡å®Œæˆ) â”€â”€â”€â”€â”€â”€â”˜
   â†“
æœ€ç»ˆå“åº”
```

**å®Œæ•´å®ç°**:

```python
"""
ReAct Agent å®Œæ•´å®ç°ç¤ºä¾‹
æ¼”ç¤ºä¸‰ç§çŠ¶æ€ç®¡ç†æ¨¡å¼: æ— çŠ¶æ€ã€å†…å­˜ã€æŒä¹…åŒ–
"""
from __future__ import annotations

import asyncio
import os
from collections import defaultdict
from typing import Dict, List

from langchain_openai import ChatOpenAI
from langchain_core.tools import tool
from langgraph.prebuilt import create_react_agent

# ============================================================================
# å·¥å…·å®šä¹‰
# ============================================================================

@tool
async def search_web(query: str) -> str:
    """æœç´¢ç½‘ç»œä¿¡æ¯

    Args:
        query: æœç´¢å…³é”®è¯

    Returns:
        æœç´¢ç»“æœæ‘˜è¦
    """
    # å®é™…åº”ç”¨ä¸­,è¿™é‡Œä¼šè°ƒç”¨çœŸå®çš„æœç´¢API (å¦‚Tavilyã€SerpAPI)
    await asyncio.sleep(0.5)  # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
    return f"æœç´¢ç»“æœ: å…³äº'{query}'çš„æœ€æ–°ä¿¡æ¯åŒ…æ‹¬..."


@tool
async def calculate(expression: str) -> str:
    """è®¡ç®—æ•°å­¦è¡¨è¾¾å¼

    Args:
        expression: æ•°å­¦è¡¨è¾¾å¼,å¦‚ "2 + 2" æˆ– "10 * 5"

    Returns:
        è®¡ç®—ç»“æœ
    """
    try:
        result = eval(expression)
        return f"è®¡ç®—ç»“æœ: {expression} = {result}"
    except Exception as e:
        return f"è®¡ç®—é”™è¯¯: {str(e)}"


@tool
async def get_weather(city: str) -> str:
    """è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯

    Args:
        city: åŸå¸‚åç§°,å¦‚ "åŒ—äº¬" æˆ– "ä¸Šæµ·"

    Returns:
        å¤©æ°”ä¿¡æ¯
    """
    # å®é™…åº”ç”¨ä¸­,è¿™é‡Œä¼šè°ƒç”¨å¤©æ°”API
    await asyncio.sleep(0.3)
    return f"{city}çš„å¤©æ°”: æ™´å¤©, æ¸©åº¦25Â°C, æ¹¿åº¦60%"


def get_tools():
    """è·å–å·¥å…·åˆ—è¡¨"""
    return [search_web, calculate, get_weather]


def get_model() -> ChatOpenAI:
    """è·å–LLMæ¨¡å‹"""
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")

    return ChatOpenAI(
        model="gpt-4o-mini",  # ä½¿ç”¨miniç‰ˆæœ¬èŠ‚çœæˆæœ¬
        temperature=0
    )


# ============================================================================
# æ¨¡å¼1: æ— çŠ¶æ€Agent
# ============================================================================

class StatelessAgent:
    """æ— çŠ¶æ€Agent - æ¯æ¬¡è°ƒç”¨ç‹¬ç«‹

    ä¼˜ç‚¹:
    - ç®€å•ã€å¯é 
    - æ˜“äºæ‰©å±•
    - æ— çŠ¶æ€æ³„æ¼é£é™©

    ç¼ºç‚¹:
    - ä¸æ”¯æŒå¤šè½®å¯¹è¯
    - æ¯æ¬¡éƒ½é‡æ–°åˆå§‹åŒ–
    """

    def __init__(self):
        self.model = get_model()
        self.tools = get_tools()
        self.agent = create_react_agent(
            model=self.model,
            tools=self.tools,
            state_modifier="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹,å¯ä»¥æœç´¢ä¿¡æ¯ã€è®¡ç®—å’ŒæŸ¥è¯¢å¤©æ°”ã€‚"
        )

    async def chat(self, user_input: str) -> str:
        """å¤„ç†ç”¨æˆ·è¾“å…¥"""
        result = await self.agent.ainvoke({
            "messages": [("user", user_input)]
        })
        return result["messages"][-1].content


# ============================================================================
# æ¨¡å¼2: å†…å­˜çŠ¶æ€Agent
# ============================================================================

class InMemoryAgent:
    """å†…å­˜çŠ¶æ€Agent - æ”¯æŒå¤šè½®å¯¹è¯

    ä¼˜ç‚¹:
    - å®ç°ç®€å•
    - æ”¯æŒå¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡

    ç¼ºç‚¹:
    - è¿›ç¨‹é‡å¯ä¸¢å¤±çŠ¶æ€
    - æ— æ³•æ°´å¹³æ‰©å±•
    - å†…å­˜å ç”¨æŒç»­å¢é•¿
    """

    def __init__(self):
        self.model = get_model()
        self.tools = get_tools()
        self.agent = create_react_agent(
            model=self.model,
            tools=self.tools,
            state_modifier="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹,å¯ä»¥æœç´¢ä¿¡æ¯ã€è®¡ç®—å’ŒæŸ¥è¯¢å¤©æ°”ã€‚"
        )
        # æ¯ä¸ªç”¨æˆ·çš„å¯¹è¯å†å² (å­˜å‚¨åœ¨å†…å­˜ä¸­)
        self.conversations: Dict[str, List] = defaultdict(list)

    async def chat(self, user_id: str, user_input: str) -> str:
        """å¤„ç†ç”¨æˆ·è¾“å…¥ (æ”¯æŒå¤šè½®å¯¹è¯)"""
        # è·å–è¯¥ç”¨æˆ·çš„å†å²æ¶ˆæ¯
        messages = self.conversations[user_id]
        messages.append(("user", user_input))

        # è°ƒç”¨Agent
        result = await self.agent.ainvoke({"messages": messages})

        # æ›´æ–°å†å²æ¶ˆæ¯
        self.conversations[user_id] = result["messages"]

        return result["messages"][-1].content

    def clear_history(self, user_id: str):
        """æ¸…ç©ºç”¨æˆ·çš„å¯¹è¯å†å²"""
        self.conversations[user_id] = []


# ============================================================================
# æ¨¡å¼3: æŒä¹…åŒ–Agent (ç”Ÿäº§æ¨è â­â­â­â­â­)
# ============================================================================

class PersistentAgent:
    """æŒä¹…åŒ–Agent - ç”Ÿäº§çº§æ–¹æ¡ˆ

    ä¼˜ç‚¹:
    - è¿›ç¨‹é‡å¯ä¸ä¸¢å¤±çŠ¶æ€
    - æ”¯æŒæ°´å¹³æ‰©å±•
    - å¯æŸ¥è¯¢å†å²è®°å½•

    ç¼ºç‚¹:
    - éœ€è¦æ•°æ®åº“ä¾èµ–
    - å¢åŠ å»¶è¿Ÿ (é€šå¸¸ < 10ms)
    """

    def __init__(self, checkpoint_uri: str = None):
        self.model = get_model()
        self.tools = get_tools()

        # æŒä¹…åŒ–å­˜å‚¨
        checkpointer = None
        if checkpoint_uri:
            try:
                from langgraph.checkpoint.postgres import PostgresSaver
                checkpointer = PostgresSaver.from_conn_string(checkpoint_uri)
                print(f"âœ“ ä½¿ç”¨PostgreSQLæŒä¹…åŒ–: {checkpoint_uri}")
            except ImportError:
                print("âš  PostgreSQLä¾èµ–æœªå®‰è£…,é™çº§åˆ°å†…å­˜æ¨¡å¼")
            except Exception as e:
                print(f"âš  PostgreSQLè¿æ¥å¤±è´¥: {e},é™çº§åˆ°å†…å­˜æ¨¡å¼")

        if checkpointer is None:
            # é™çº§åˆ°SQLite(ä»…ç”¨äºæ¼”ç¤º)
            try:
                from langgraph.checkpoint.sqlite import SqliteSaver
                checkpointer = SqliteSaver.from_conn_string(":memory:")
                print(f"âœ“ ä½¿ç”¨SQLiteå†…å­˜æ¨¡å¼ (ä»…æ¼”ç¤º)")
            except ImportError:
                print("âš  æ— å¯ç”¨checkpointer,ä½¿ç”¨æ— çŠ¶æ€æ¨¡å¼")

        self.agent = create_react_agent(
            model=self.model,
            tools=self.tools,
            checkpointer=checkpointer,
            state_modifier="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹,å¯ä»¥æœç´¢ä¿¡æ¯ã€è®¡ç®—å’ŒæŸ¥è¯¢å¤©æ°”ã€‚"
        )

    async def chat(self, thread_id: str, user_input: str) -> str:
        """å¤„ç†ç”¨æˆ·è¾“å…¥ (è‡ªåŠ¨æŒä¹…åŒ–)

        Args:
            thread_id: ä¼šè¯ID,ç”¨äºåŒºåˆ†ä¸åŒä¼šè¯
            user_input: ç”¨æˆ·è¾“å…¥
        """
        config = {"configurable": {"thread_id": thread_id}}

        # è°ƒç”¨Agent - è‡ªåŠ¨åŠ è½½å†å²çŠ¶æ€
        result = await self.agent.ainvoke(
            {"messages": [("user", user_input)]},
            config=config
        )

        # çŠ¶æ€è‡ªåŠ¨æŒä¹…åŒ–
        return result["messages"][-1].content
```

**ä½¿ç”¨ç¤ºä¾‹**:

```python
async def demo_stateless():
    """æ¼”ç¤ºæ— çŠ¶æ€æ¨¡å¼"""
    agent = StatelessAgent()

    # ç¬¬ä¸€æ¬¡è°ƒç”¨
    response1 = await agent.chat("åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·?")
    print(f"åŠ©æ‰‹: {response1}")

    # ç¬¬äºŒæ¬¡è°ƒç”¨ - æ— æ³•è®°ä½ä¸Šä¸€è½®å¯¹è¯
    response2 = await agent.chat("é‚£ä¸Šæµ·å‘¢?")  # Agentæ— æ³•ç†è§£"é‚£ä¸Šæµ·å‘¢"
    print(f"åŠ©æ‰‹: {response2}")


async def demo_in_memory():
    """æ¼”ç¤ºå†…å­˜çŠ¶æ€æ¨¡å¼"""
    agent = InMemoryAgent()
    user_id = "user_123"

    # ç¬¬ä¸€è½®å¯¹è¯
    response1 = await agent.chat(user_id, "åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·?")
    print(f"åŠ©æ‰‹: {response1}")

    # ç¬¬äºŒè½®å¯¹è¯ - å¯ä»¥ç†è§£ä¸Šä¸‹æ–‡
    response2 = await agent.chat(user_id, "é‚£ä¸Šæµ·å‘¢?")  # âœ“ èƒ½å¤Ÿç†è§£
    print(f"åŠ©æ‰‹: {response2}")


async def demo_persistent():
    """æ¼”ç¤ºæŒä¹…åŒ–æ¨¡å¼"""
    # å°è¯•ä½¿ç”¨PostgreSQL,å¤±è´¥åˆ™é™çº§
    postgres_uri = os.getenv("POSTGRES_URI")
    agent = PersistentAgent(checkpoint_uri=postgres_uri)

    thread_id = "conversation_456"

    # ç¬¬ä¸€è½®å¯¹è¯
    response1 = await agent.chat(thread_id, "æœç´¢LangChainæœ€æ–°ç‰ˆæœ¬")
    print(f"åŠ©æ‰‹: {response1}")

    # ç¬¬äºŒè½®å¯¹è¯ (å³ä½¿è¿›ç¨‹é‡å¯,é€šè¿‡ç›¸åŒthread_idä¹Ÿèƒ½æ¢å¤)
    response2 = await agent.chat(thread_id, "å®ƒæœ‰å“ªäº›æ–°ç‰¹æ€§?")
    print(f"åŠ©æ‰‹: {response2}")
```

**æ€§èƒ½å¯¹æ¯”**:

| æ¨¡å¼ | é¦–æ¬¡è°ƒç”¨ | åç»­è°ƒç”¨ | çŠ¶æ€æŒä¹…åŒ– | æ°´å¹³æ‰©å±• | æ¨èåœºæ™¯ |
|------|---------|---------|-----------|---------|---------|
| æ— çŠ¶æ€ | ~500ms | ~500ms | âŒ | âœ… | å•æ¬¡æŸ¥è¯¢ |
| å†…å­˜ | ~500ms | ~520ms | âŒ | âŒ | å¼€å‘æµ‹è¯• |
| æŒä¹…åŒ– | ~510ms | ~530ms | âœ… | âœ… | **ç”Ÿäº§ç¯å¢ƒ** |

---

## 1.2 çŠ¶æ€ç®¡ç†æœ€ä½³å®è·µ

### çŠ¶æ€è®¾è®¡åŸåˆ™

**1. æœ€å°åŒ–åŸåˆ™** - åªä¿å­˜å¿…è¦çš„çŠ¶æ€
```python
# âŒ ä¸å¥½ - ä¿å­˜è¿‡å¤šå†—ä½™ä¿¡æ¯
state = {
    "all_messages": [...],  # å®Œæ•´å†å²
    "user_profile": {...},  # ç”¨æˆ·ä¿¡æ¯
    "search_cache": {...},  # æœç´¢ç¼“å­˜
    "debug_info": {...}     # è°ƒè¯•ä¿¡æ¯
}

# âœ… å¥½ - åªä¿å­˜æ ¸å¿ƒçŠ¶æ€
state = {
    "messages": messages[-10:],  # åªä¿ç•™æœ€è¿‘10è½®
}
```

**2. çŠ¶æ€éš”ç¦»** - ä¸åŒç”¨æˆ·/ä¼šè¯çš„çŠ¶æ€å®Œå…¨éš”ç¦»
```python
# ä½¿ç”¨thread_idéš”ç¦»
config = {"configurable": {"thread_id": f"user_{user_id}"}}
```

**3. çŠ¶æ€æ¸…ç†** - å®šæœŸæ¸…ç†è¿‡æœŸçŠ¶æ€
```python
from datetime import datetime, timedelta

async def cleanup_old_sessions(checkpointer, days=30):
    """æ¸…ç†30å¤©å‰çš„ä¼šè¯"""
    cutoff = datetime.now() - timedelta(days=days)
    # å®ç°æ¸…ç†é€»è¾‘
    pass
```

### æŒä¹…åŒ–æ–¹æ¡ˆå¯¹æ¯”

| æ–¹æ¡ˆ | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|------|------|---------|
| **SQLite** | ç®€å•,æ— é¢å¤–ä¾èµ– | ä¸æ”¯æŒå¹¶å‘å†™ | å•æœºå¼€å‘ |
| **PostgreSQL** | æˆç†Ÿ,æ”¯æŒé«˜å¹¶å‘ | éœ€è¦è¿ç»´ | **ç”Ÿäº§æ¨è** |
| **Redis** | å¿«é€Ÿ,æ”¯æŒTTL | å†…å­˜å¼€é”€å¤§ | çŸ­æœŸä¼šè¯ |

**PostgreSQLæŒä¹…åŒ–å®Œæ•´ç¤ºä¾‹**:

```python
from langgraph.checkpoint.postgres import PostgresSaver

# åˆå§‹åŒ–
checkpointer = PostgresSaver.from_conn_string(
    "postgresql://user:password@localhost:5432/langchain"
)

# åˆ›å»ºAgent
agent = create_react_agent(
    model=model,
    tools=tools,
    checkpointer=checkpointer
)

# ä½¿ç”¨
config = {"configurable": {"thread_id": "user_123"}}
result = await agent.ainvoke(input_data, config=config)

# æŸ¥è¯¢å†å²
state = await checkpointer.aget(config)
```

---

## 1.3 å·¥å…·ç³»ç»Ÿè®¾è®¡

### å·¥å…·è®¾è®¡åŸåˆ™

**1. å•ä¸€èŒè´£**
```python
# âŒ ä¸å¥½ - ä¸€ä¸ªå·¥å…·åšå¤ªå¤šäº‹
@tool
def universal_tool(action: str, data: dict) -> str:
    if action == "search":
        return search(data)
    elif action == "calculate":
        return calculate(data)
    ...

# âœ… å¥½ - æ¯ä¸ªå·¥å…·èŒè´£æ˜ç¡®
@tool
def search(query: str) -> str:
    """æœç´¢ç½‘ç»œä¿¡æ¯"""
    pass

@tool
def calculate(expression: str) -> str:
    """è®¡ç®—æ•°å­¦è¡¨è¾¾å¼"""
    pass
```

**2. æ¸…æ™°çš„æ–‡æ¡£å­—ç¬¦ä¸²**
```python
@tool
def query_database(sql: str, limit: int = 100) -> str:
    """æŸ¥è¯¢æ•°æ®åº“

    Args:
        sql: SQLæŸ¥è¯¢è¯­å¥ (åªæ”¯æŒSELECT)
        limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶,é»˜è®¤100æ¡

    Returns:
        JSONæ ¼å¼çš„æŸ¥è¯¢ç»“æœ

    ç¤ºä¾‹:
        query_database("SELECT * FROM users WHERE age > 18", limit=10)
    """
    pass
```

**3. é”™è¯¯å¤„ç†**
```python
@tool
async def api_call(endpoint: str) -> str:
    """è°ƒç”¨å¤–éƒ¨API"""
    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            response = await client.get(endpoint)
            response.raise_for_status()
            return response.text
    except httpx.TimeoutException:
        return "é”™è¯¯: APIè°ƒç”¨è¶…æ—¶"
    except httpx.HTTPError as e:
        return f"é”™è¯¯: APIè°ƒç”¨å¤±è´¥ - {str(e)}"
```

### å·¥å…·æ•°é‡æ§åˆ¶

**æ¨èæ–¹æ¡ˆ**: æ ¹æ®åœºæ™¯åŠ¨æ€åŠ è½½å·¥å…·

```python
def select_tools_by_context(user_input: str) -> list:
    """æ ¹æ®ç”¨æˆ·è¾“å…¥é€‰æ‹©ç›¸å…³å·¥å…·"""

    # å…³é”®è¯æ£€æµ‹
    if any(kw in user_input for kw in ["å¤©æ°”", "æ¸©åº¦", "ä¸‹é›¨"]):
        return [get_weather]
    elif any(kw in user_input for kw in ["è®¡ç®—", "åŠ ", "å‡", "ä¹˜", "é™¤"]):
        return [calculate]
    elif any(kw in user_input for kw in ["æœç´¢", "æŸ¥æ‰¾", "äº†è§£"]):
        return [search_web]
    else:
        # é»˜è®¤æä¾›åŸºç¡€å·¥å…·
        return [search_web, calculate]

# åŠ¨æ€åˆ›å»ºAgent
relevant_tools = select_tools_by_context(user_input)
agent = create_react_agent(model, tools=relevant_tools)
```

**å·¥å…·æ•°é‡å»ºè®®**:
- âœ… æ¨è: 3-7ä¸ªå·¥å…· (æœ€ä¼˜)
- âš ï¸ å¯æ¥å—: 8-15ä¸ªå·¥å…·
- âŒ é¿å…: >20ä¸ªå·¥å…· (LLMå®¹æ˜“é€‰é”™)

---

# ç¬¬äºŒéƒ¨åˆ†:æ€§èƒ½ä¼˜åŒ–å®æˆ˜

## 2.1 å“åº”é€Ÿåº¦ä¼˜åŒ–

### æ€§èƒ½åŸºå‡†

**å“åº”æ—¶é—´åˆ†çº§**:
```
å“åº”æ—¶é—´      ç”¨æˆ·æ„ŸçŸ¥        è¯„çº§
< 100ms      å³æ—¶å“åº”        â­â­â­â­â­ å“è¶Š
< 500ms      æµç•…ä½“éªŒ        â­â­â­â­   ä¼˜ç§€
< 1s         å¯æ¥å—          â­â­â­     è‰¯å¥½
1-3s         å¼€å§‹æ„Ÿè§‰æ…¢      â­â­       éœ€ä¼˜åŒ–
3-5s         æ˜æ˜¾å»¶è¿Ÿ        â­         å·®
> 5s         ç”¨æˆ·æµå¤±é£é™©    âŒ         ç´§æ€¥
```

**Agentå“åº”æ—¶é—´ç»„æˆ** (ä»¥GPT-4oä¸ºä¾‹):
```
æ€»å“åº”æ—¶é—´ = LLMé¦–Token (40%) + LLMç”Ÿæˆ (15%) + å·¥å…·æ‰§è¡Œ (35%) + ç½‘ç»œ+ç³»ç»Ÿ (10%)
```

### ä¼˜åŒ–ç­–ç•¥1: æµå¼è¾“å‡º (å¿…åš â­â­â­â­â­)

**æ”¶ç›Š**: é¦–å­—å»¶è¿Ÿä»5sé™è‡³0.2s,é™ä½96%

**å®Œæ•´å®ç°**:

```python
"""
æµå¼è¾“å‡ºå®Œæ•´ç¤ºä¾‹
å¯¹æ¯”æµå¼ vs éæµå¼çš„æ€§èƒ½å·®å¼‚
"""
import time
import asyncio
from langchain_openai import ChatOpenAI
from langchain_core.tools import tool
from langgraph.prebuilt import create_react_agent

@tool
async def search(query: str) -> str:
    """æœç´¢ä¿¡æ¯"""
    await asyncio.sleep(1)  # æ¨¡æ‹Ÿæœç´¢å»¶è¿Ÿ
    return f"æœç´¢ç»“æœ: {query}"

model = ChatOpenAI(model="gpt-4o-mini", temperature=0)
agent = create_react_agent(model=model, tools=[search])

# ============================================================================
# éæµå¼è°ƒç”¨ - ç”¨æˆ·ç­‰å¾…æ‰€æœ‰å†…å®¹ç”Ÿæˆå®Œæˆ
# ============================================================================

async def non_streaming_example(query: str):
    """éæµå¼è°ƒç”¨"""
    print("ã€éæµå¼è°ƒç”¨ã€‘")
    start = time.time()

    result = await agent.ainvoke({"messages": [("user", query)]})

    total_time = time.time() - start
    print(f"æ€»è€—æ—¶: {total_time:.2f}s")
    print(f"æœ€ç»ˆå“åº”: {result['messages'][-1].content}\n")


# ============================================================================
# æµå¼è°ƒç”¨ - ç”¨æˆ·ç«‹å³å¼€å§‹çœ‹åˆ°å†…å®¹
# ============================================================================

async def streaming_example(query: str):
    """æµå¼è°ƒç”¨"""
    print("ã€æµå¼è°ƒç”¨ã€‘")
    start = time.time()
    first_chunk_time = None

    async for event in agent.astream_events(
        {"messages": [("user", query)]},
        version="v2"
    ):
        kind = event["event"]

        # æµå¼è¿”å›LLMç”Ÿæˆçš„å†…å®¹
        if kind == "on_chat_model_stream":
            content = event["data"]["chunk"].content
            if content:
                if first_chunk_time is None:
                    first_chunk_time = time.time()
                    print(f"é¦–å­—å»¶è¿Ÿ: {first_chunk_time - start:.2f}s\n")
                print(content, end="", flush=True)

        # æ˜¾ç¤ºå·¥å…·è°ƒç”¨
        elif kind == "on_tool_start":
            print(f"\n[ğŸ”§ è°ƒç”¨å·¥å…·: {event['name']}]", flush=True)
        elif kind == "on_tool_end":
            print(f"[âœ“ å·¥å…·å®Œæˆ]", flush=True)

    total_time = time.time() - start
    print(f"\n\næ€»è€—æ—¶: {total_time:.2f}s\n")


# ============================================================================
# FastAPIé›†æˆç¤ºä¾‹
# ============================================================================

from fastapi import FastAPI
from fastapi.responses import StreamingResponse

app = FastAPI()

@app.post("/chat/stream")
async def chat_stream(query: str):
    """æµå¼èŠå¤©ç«¯ç‚¹"""
    async def generate():
        async for event in agent.astream_events(
            {"messages": [("user", query)]},
            version="v2"
        ):
            if event["event"] == "on_chat_model_stream":
                content = event["data"]["chunk"].content
                if content:
                    yield f"data: {content}\n\n"

    return StreamingResponse(
        generate(),
        media_type="text/event-stream"
    )
```

**æ€§èƒ½å¯¹æ¯”**:
```python
query = "æœç´¢2024å¹´GDPæ•°æ®å¹¶åˆ†æ"

# éæµå¼: ç”¨æˆ·ç­‰å¾…5ç§’åä¸€æ¬¡æ€§çœ‹åˆ°ç»“æœ
await non_streaming_example(query)
# è¾“å‡º: æ€»è€—æ—¶: 5.23s

# æµå¼: ç”¨æˆ·200msåå°±å¼€å§‹çœ‹åˆ°å†…å®¹
await streaming_example(query)
# è¾“å‡º: é¦–å­—å»¶è¿Ÿ: 0.21s, æ€»è€—æ—¶: 5.18s
```

---

### ä¼˜åŒ–ç­–ç•¥2: å¹¶è¡Œå·¥å…·è°ƒç”¨ (æ”¶ç›Š â­â­â­â­)

**æ”¶ç›Š**: ç­‰å¾…æ—¶é—´é™ä½50-70%

**åŸç†**: ç°ä»£LLM (GPT-4o, Claude 3.5) ä¼šè‡ªåŠ¨è¯†åˆ«å¯å¹¶è¡Œçš„å·¥å…·è°ƒç”¨

```python
@tool
async def search_web(query: str) -> str:
    """æœç´¢ç½‘ç»œ (è€—æ—¶: 1s)"""
    await asyncio.sleep(1)
    return f"æœç´¢ç»“æœ: {query}"

@tool
async def query_database(sql: str) -> str:
    """æŸ¥è¯¢æ•°æ®åº“ (è€—æ—¶: 1s)"""
    await asyncio.sleep(1)
    return f"æŸ¥è¯¢ç»“æœ: {sql}"

@tool
async def call_api(endpoint: str) -> str:
    """è°ƒç”¨API (è€—æ—¶: 1s)"""
    await asyncio.sleep(1)
    return f"APIå“åº”: {endpoint}"

# Agentä¼šè‡ªåŠ¨å¹¶è¡Œè°ƒç”¨
agent = create_react_agent(
    model=ChatOpenAI(model="gpt-4o"),
    tools=[search_web, query_database, call_api]
)

# å•ä¸ªè¯·æ±‚è§¦å‘3ä¸ªå·¥å…·è°ƒç”¨
result = await agent.ainvoke({
    "messages": [("user", "æœç´¢å¤©æ°”,æŸ¥è¯¢ç”¨æˆ·æ•°,è°ƒç”¨æ”¯ä»˜API")]
})

# âŒ ä¸²è¡Œæ‰§è¡Œ: 3s (1s + 1s + 1s)
# âœ… å¹¶è¡Œæ‰§è¡Œ: ~1s (max(1s, 1s, 1s))
```

**æ§åˆ¶å¹¶å‘æ•°**:
```python
from langchain_core.runnables import RunnableConfig

# é™åˆ¶æœ€å¤§å¹¶å‘æ•° (é¿å…è¿‡è½½)
config = RunnableConfig(max_concurrency=5)
result = await agent.ainvoke(input_data, config=config)
```

---

### ä¼˜åŒ–ç­–ç•¥3: æ¨¡å‹è·¯ç”± (æ”¶ç›Š â­â­â­â­)

**æ”¶ç›Š**: æˆæœ¬é™ä½50-70%,é€Ÿåº¦æå‡40-60%

**åŸç†**: ç®€å•ä»»åŠ¡ç”¨å¿«é€Ÿæ¨¡å‹,å¤æ‚ä»»åŠ¡ç”¨å¼ºå¤§æ¨¡å‹

```python
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic

# æ¨¡å‹æ€§èƒ½å¯¹æ¯” (å®æµ‹æ•°æ®)
MODELS = {
    "fast": ChatOpenAI(model="gpt-4o-mini"),      # ~200ms, $0.15/1M tokens
    "balanced": ChatOpenAI(model="gpt-4o"),       # ~500ms, $2.5/1M tokens
    "powerful": ChatAnthropic(model="claude-sonnet-4"),  # ~800ms, $3/1M tokens
}

def select_model(user_input: str) -> ChatOpenAI:
    """æ ¹æ®æŸ¥è¯¢å¤æ‚åº¦é€‰æ‹©æ¨¡å‹"""

    # ç®€å•è§„åˆ™
    if len(user_input) < 50 and "?" in user_input:
        return MODELS["fast"]  # ç®€å•é—®ç­”

    # å…³é”®è¯æ£€æµ‹
    complex_keywords = ["åˆ†æ", "æ€»ç»“", "è¯„ä¼°", "å¯¹æ¯”", "æ¨ç†"]
    if any(kw in user_input for kw in complex_keywords):
        return MODELS["powerful"]  # å¤æ‚åˆ†æ

    return MODELS["balanced"]  # é»˜è®¤


# ä½¿ç”¨åŠ¨æ€æ¨¡å‹
async def smart_agent(user_input: str):
    model = select_model(user_input)
    agent = create_react_agent(model, tools)
    return await agent.ainvoke({"messages": [("user", user_input)]})
```

**åŸºäºLLMçš„è·¯ç”±** (é«˜çº§):
```python
from pydantic import BaseModel

class RouteDecision(BaseModel):
    """è·¯ç”±å†³ç­–"""
    model: str  # "fast" | "balanced" | "powerful"
    reason: str

# ç”¨å¿«é€Ÿæ¨¡å‹åšè·¯ç”±å†³ç­–
router_model = ChatOpenAI(model="gpt-4o-mini")
router = router_model.with_structured_output(RouteDecision)

async def llm_based_routing(user_input: str):
    # ç”¨å¿«é€Ÿæ¨¡å‹åˆ†æä»»åŠ¡å¤æ‚åº¦
    decision = await router.ainvoke(
        f"åˆ†æä»¥ä¸‹ä»»åŠ¡çš„å¤æ‚åº¦,é€‰æ‹©åˆé€‚çš„æ¨¡å‹:\n{user_input}"
    )

    # ç”¨é€‰å®šçš„æ¨¡å‹æ‰§è¡Œä»»åŠ¡
    model = MODELS[decision.model]
    agent = create_react_agent(model, tools)
    return await agent.ainvoke({"messages": [("user", user_input)]})
```

---

### ä¼˜åŒ–ç­–ç•¥4: æ™ºèƒ½ç¼“å­˜ (æ”¶ç›Š â­â­â­)

**æ”¶ç›Š**: ç›¸åŒæŸ¥è¯¢å“åº”æ—¶é—´ < 10ms

#### ç²¾ç¡®ç¼“å­˜

```python
from langchain_community.cache import RedisCache
import redis

# Redisç¼“å­˜
redis_client = redis.Redis(
    host='localhost',
    port=6379,
    decode_responses=True
)
cache = RedisCache(redis_client)

model = ChatOpenAI(model="gpt-4o", cache=cache)

# é¦–æ¬¡æŸ¥è¯¢: 500ms
result1 = await model.ainvoke("ä»€ä¹ˆæ˜¯LangChain?")

# ç¬¬äºŒæ¬¡ç›¸åŒæŸ¥è¯¢: <10ms (ç¼“å­˜å‘½ä¸­)
result2 = await model.ainvoke("ä»€ä¹ˆæ˜¯LangChain?")
```

#### è¯­ä¹‰ç¼“å­˜

```python
from langchain_community.cache import RedisSemanticCache
from langchain_openai import OpenAIEmbeddings

# è¯­ä¹‰ç¼“å­˜ - ç›¸ä¼¼é—®é¢˜ä¹Ÿå‘½ä¸­
embeddings = OpenAIEmbeddings()
semantic_cache = RedisSemanticCache(
    redis_url="redis://localhost:6379",
    embedding=embeddings,
    similarity_threshold=0.9  # ç›¸ä¼¼åº¦é˜ˆå€¼
)

model = ChatOpenAI(model="gpt-4o", cache=semantic_cache)

# é¦–æ¬¡æŸ¥è¯¢
await model.ainvoke("ä»€ä¹ˆæ˜¯LangChain?")

# è¯­ä¹‰ç›¸ä¼¼çš„æŸ¥è¯¢ä¹Ÿå‘½ä¸­ç¼“å­˜
await model.ainvoke("LangChainæ˜¯ä»€ä¹ˆ?")      # âœ“ ç¼“å­˜å‘½ä¸­
await model.ainvoke("ä»‹ç»ä¸€ä¸‹LangChain")     # âœ“ ç¼“å­˜å‘½ä¸­
await model.ainvoke("LangChainçš„ä½œç”¨")       # âœ“ ç¼“å­˜å‘½ä¸­
```

---

## 2.2 æˆæœ¬ä¼˜åŒ–ç­–ç•¥

### Tokenä½¿ç”¨ä¼˜åŒ–

**ç­–ç•¥1: Promptå‹ç¼©**
```python
# âŒ ä¸å¥½ - Promptå†—é•¿
prompt = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ã€‚
ä½ éœ€è¦å¸®åŠ©ç”¨æˆ·è§£å†³å„ç§é—®é¢˜ã€‚
ä½ åº”è¯¥æä¾›å‡†ç¡®ã€è¯¦ç»†çš„å›ç­”ã€‚
ä½ éœ€è¦ä¿æŒç¤¼è²Œå’Œä¸“ä¸šã€‚
...  (æ›´å¤šå†—ä½™æè¿°)

ç”¨æˆ·é—®é¢˜: {question}
"""

# âœ… å¥½ - Promptç®€æ´
prompt = """ä¸“ä¸šAIåŠ©æ‰‹,æä¾›å‡†ç¡®å›ç­”ã€‚

é—®é¢˜: {question}"""
```

**ç­–ç•¥2: ä¸Šä¸‹æ–‡çª—å£æ§åˆ¶**
```python
# åªä¿ç•™æœ€è¿‘Nè½®å¯¹è¯
MAX_HISTORY = 10

messages = conversation_history[-MAX_HISTORY:]
result = await agent.ainvoke({"messages": messages})
```

**ç­–ç•¥3: ä½¿ç”¨ä¾¿å®œçš„Embeddingæ¨¡å‹**
```python
# å¯¹æ¯”
expensive_embed = OpenAIEmbeddings(model="text-embedding-3-large")  # $0.13/1M tokens
cheap_embed = OpenAIEmbeddings(model="text-embedding-3-small")      # $0.02/1M tokens

# å¯¹äºå¤§å¤šæ•°åœºæ™¯,smallæ¨¡å‹è¶³å¤Ÿ
vectorstore = Chroma(embedding_function=cheap_embed)
```

---

## 2.3 å¹¶å‘ä¸å¼‚æ­¥å¤„ç†

### å¼‚æ­¥è°ƒç”¨ (å¿…åš)

```python
# âŒ ä¸å¥½ - åŒæ­¥è°ƒç”¨
def process_requests(queries):
    results = []
    for query in queries:
        result = agent.invoke({"messages": [("user", query)]})
        results.append(result)
    return results  # ä¸²è¡Œå¤„ç†,100ä¸ªæŸ¥è¯¢éœ€è¦100s

# âœ… å¥½ - å¼‚æ­¥æ‰¹å¤„ç†
async def process_requests_async(queries):
    tasks = [
        agent.ainvoke({"messages": [("user", query)]})
        for query in queries
    ]
    results = await asyncio.gather(*tasks)
    return results  # å¹¶å‘å¤„ç†,100ä¸ªæŸ¥è¯¢çº¦10s (å–å†³äºmax_concurrency)
```

### æ‰¹å¤„ç†ä¼˜åŒ–

```python
from langchain_core.runnables import RunnableConfig

# æ‰¹é‡å¤„ç†
inputs = [{"messages": [("user", f"é—®é¢˜{i}")]} for i in range(100)]

# æ§åˆ¶å¹¶å‘
config = RunnableConfig(max_concurrency=10)
results = await model.abatch(inputs, config=config)

# æ€§èƒ½å¯¹æ¯”:
# ä¸²è¡Œ: 100æ¬¡ Ã— 1s = 100s
# å¹¶å‘(10): 100æ¬¡ Ã· 10 = 10s
```

---

# ç¬¬ä¸‰éƒ¨åˆ†:å¯é æ€§ä¿éšœ

## 3.1 é”™è¯¯å¤„ç†ä¸é‡è¯•

### é”™è¯¯åˆ†ç±»

```python
# å¯æ¢å¤é”™è¯¯ - é‡è¯•æœ‰æ„ä¹‰
class RecoverableError(Exception):
    """å¯æ¢å¤é”™è¯¯"""
    pass

# ç½‘ç»œè¶…æ—¶
class NetworkTimeoutError(RecoverableError):
    pass

# é€Ÿç‡é™åˆ¶
class RateLimitError(RecoverableError):
    pass

# ä¸å¯æ¢å¤é”™è¯¯ - ç«‹å³å¤±è´¥
class UnrecoverableError(Exception):
    """ä¸å¯æ¢å¤é”™è¯¯"""
    pass

# è®¤è¯å¤±è´¥
class AuthError(UnrecoverableError):
    pass

# é…é¢è€—å°½
class QuotaExceededError(UnrecoverableError):
    pass
```

### é‡è¯•ç­–ç•¥

#### ç­–ç•¥1: ç®€å•é‡è¯•

```python
from tenacity import retry, stop_after_attempt, wait_fixed

@retry(
    stop=stop_after_attempt(3),  # æœ€å¤š3æ¬¡
    wait=wait_fixed(2)            # æ¯æ¬¡ç­‰å¾…2ç§’
)
async def simple_retry_call(user_input: str):
    """ç®€å•é‡è¯•ç­–ç•¥"""
    return await agent.ainvoke({"messages": [("user", user_input)]})
```

#### ç­–ç•¥2: æŒ‡æ•°é€€é¿ (æ¨è â­â­â­â­â­)

```python
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(
    stop=stop_after_attempt(5),
    wait=wait_exponential(multiplier=1, min=2, max=60)
    # é‡è¯•é—´éš”: 2s, 4s, 8s, 16s, 32s
)
async def exponential_backoff_call(user_input: str):
    """æŒ‡æ•°é€€é¿é‡è¯•"""
    return await agent.ainvoke({"messages": [("user", user_input)]})
```

#### ç­–ç•¥3: æ™ºèƒ½é‡è¯• (ç”Ÿäº§æ¨è â­â­â­â­â­)

```python
from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type
)
import httpx
from openai import RateLimitError, APITimeoutError

@retry(
    # åªå¯¹ç‰¹å®šé”™è¯¯é‡è¯•
    retry=retry_if_exception_type((APITimeoutError, httpx.TimeoutException)),
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=1, max=10)
)
async def smart_retry_call(user_input: str):
    """æ™ºèƒ½é‡è¯• - åªé‡è¯•å¯æ¢å¤é”™è¯¯"""
    try:
        return await agent.ainvoke({"messages": [("user", user_input)]})
    except RateLimitError as e:
        # é€Ÿç‡é™åˆ¶ - ç­‰å¾…æ›´é•¿æ—¶é—´
        wait_time = parse_retry_after_header(e)
        await asyncio.sleep(wait_time)
        raise  # ç»§ç»­é‡è¯•
    except ValueError as e:
        # è¾“å…¥é”™è¯¯ - ä¸é‡è¯•
        raise ValueError(f"è¾“å…¥éªŒè¯å¤±è´¥: {e}") from None
```

#### ç­–ç•¥4: æ–­è·¯å™¨æ¨¡å¼ (é˜²é›ªå´© â­â­â­â­)

```python
from enum import Enum
import time

class CircuitState(Enum):
    CLOSED = "closed"      # æ­£å¸¸
    OPEN = "open"          # æ–­è·¯
    HALF_OPEN = "half_open"  # åŠå¼€(æµ‹è¯•)

class CircuitBreaker:
    """æ–­è·¯å™¨ - é˜²æ­¢æŒç»­è°ƒç”¨å¤±è´¥æœåŠ¡"""

    def __init__(
        self,
        failure_threshold: int = 5,
        timeout: int = 60,
        expected_exception: type = Exception
    ):
        self.failure_threshold = failure_threshold
        self.timeout = timeout
        self.expected_exception = expected_exception

        self.failure_count = 0
        self.last_failure_time = None
        self.state = CircuitState.CLOSED

    async def call(self, func, *args, **kwargs):
        """æ‰§è¡Œè°ƒç”¨,å¸¦æ–­è·¯å™¨ä¿æŠ¤"""
        if self.state == CircuitState.OPEN:
            # æ£€æŸ¥æ˜¯å¦å¯ä»¥å°è¯•æ¢å¤
            if time.time() - self.last_failure_time > self.timeout:
                self.state = CircuitState.HALF_OPEN
                print("[æ–­è·¯å™¨] è¿›å…¥åŠå¼€çŠ¶æ€,å°è¯•æ¢å¤")
            else:
                raise Exception("æ–­è·¯å™¨å¼€å¯,æœåŠ¡ä¸å¯ç”¨")

        try:
            result = await func(*args, **kwargs)

            # æˆåŠŸ - é‡ç½®è®¡æ•°
            if self.state == CircuitState.HALF_OPEN:
                self.state = CircuitState.CLOSED
                print("[æ–­è·¯å™¨] æ¢å¤æ­£å¸¸")

            self.failure_count = 0
            return result

        except self.expected_exception as e:
            self.failure_count += 1
            self.last_failure_time = time.time()

            if self.failure_count >= self.failure_threshold:
                self.state = CircuitState.OPEN
                print(f"[æ–­è·¯å™¨] è§¦å‘æ–­è·¯ (å¤±è´¥{self.failure_count}æ¬¡)")

            raise


# ä½¿ç”¨
breaker = CircuitBreaker(failure_threshold=3, timeout=30)

async def protected_agent_call(user_input: str):
    return await breaker.call(
        agent.ainvoke,
        {"messages": [("user", user_input)]}
    )
```

---

## 3.2 é™çº§ä¸ç†”æ–­

### é™çº§ç­–ç•¥

#### é™çº§1: å·¥å…·é™çº§

```python
@tool
async def search_with_fallback(query: str) -> str:
    """æœç´¢(å¸¦é™çº§)"""
    try:
        # ä¸»å·¥å…·: é«˜è´¨é‡API
        return await premium_search_api(query)
    except Exception as e:
        print(f"[é™çº§] ä¸»æœç´¢å¤±è´¥: {e}")
        try:
            # é™çº§1: å…è´¹API
            return await free_search_api(query)
        except Exception as e2:
            print(f"[é™çº§] å¤‡ç”¨æœç´¢å¤±è´¥: {e2}")
            # é™çº§2: è¿”å›ç¼“å­˜
            return get_cached_result(query)
```

#### é™çº§2: æ¨¡å‹é™çº§

```python
class ModelFallback:
    """æ¨¡å‹é™çº§"""
    def __init__(self):
        self.models = [
            ChatOpenAI(model="gpt-4o"),              # ä¸»æ¨¡å‹
            ChatOpenAI(model="gpt-4o-mini"),         # é™çº§1
            ChatAnthropic(model="claude-sonnet-4"),  # é™çº§2
        ]

    async def invoke_with_fallback(self, messages):
        """å¸¦é™çº§çš„æ¨¡å‹è°ƒç”¨"""
        for i, model in enumerate(self.models):
            try:
                return await model.ainvoke(messages)
            except Exception as e:
                print(f"[é™çº§] æ¨¡å‹{i}å¤±è´¥: {e}")
                if i == len(self.models) - 1:
                    raise  # æ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥

        raise Exception("æ‰€æœ‰æ¨¡å‹å‡ä¸å¯ç”¨")
```

#### é™çº§3: åŠŸèƒ½é™çº§

```python
async def agent_with_degradation(user_input: str):
    """å¸¦åŠŸèƒ½é™çº§çš„Agent"""
    try:
        # å®Œæ•´åŠŸèƒ½: å¤šå·¥å…·ReAct Agent
        agent = create_react_agent(model, tools=all_tools)
        return await agent.ainvoke({"messages": [("user", user_input)]})

    except Exception as e:
        print(f"[é™çº§] å®Œæ•´Agentå¤±è´¥: {e}")
        try:
            # é™çº§1: åªç”¨æ ¸å¿ƒå·¥å…·
            agent = create_react_agent(model, tools=core_tools)
            return await agent.ainvoke({"messages": [("user", user_input)]})

        except Exception as e2:
            print(f"[é™çº§] ç®€åŒ–Agentå¤±è´¥: {e2}")
            # é™çº§2: çº¯LLM,æ— å·¥å…·
            return await model.ainvoke(user_input)
```

---

## 3.3 æµ‹è¯•ç­–ç•¥

### å•å…ƒæµ‹è¯•

```python
import pytest
from unittest.mock import AsyncMock

@pytest.mark.asyncio
async def test_agent_with_search():
    """æµ‹è¯•Agentèƒ½æ­£ç¡®è°ƒç”¨æœç´¢å·¥å…·"""
    # Mockå·¥å…·
    mock_search = AsyncMock(return_value="Mockæœç´¢ç»“æœ")

    # åˆ›å»ºAgent
    agent = create_react_agent(model, tools=[mock_search])

    # æ‰§è¡Œ
    result = await agent.ainvoke({
        "messages": [("user", "æœç´¢Pythonæ•™ç¨‹")]
    })

    # éªŒè¯
    assert mock_search.called
    assert "Mockæœç´¢ç»“æœ" in str(result)


@pytest.mark.asyncio
async def test_retry_on_timeout():
    """æµ‹è¯•è¶…æ—¶é‡è¯•"""
    mock_agent = AsyncMock()
    mock_agent.ainvoke.side_effect = [
        asyncio.TimeoutError(),  # ç¬¬1æ¬¡å¤±è´¥
        asyncio.TimeoutError(),  # ç¬¬2æ¬¡å¤±è´¥
        {"result": "success"}    # ç¬¬3æ¬¡æˆåŠŸ
    ]

    @retry(stop=stop_after_attempt(3))
    async def call_with_retry():
        return await mock_agent.ainvoke({})

    result = await call_with_retry()

    assert result == {"result": "success"}
    assert mock_agent.ainvoke.call_count == 3
```

---

# ç¬¬å››éƒ¨åˆ†:ç›‘æ§è¿ç»´

## 4.1 å¯è§‚æµ‹æ€§å»ºè®¾

### ä¸‰å¤§æ”¯æŸ±

1. **Metrics (æŒ‡æ ‡)** - å®šé‡ç›‘æ§
2. **Logs (æ—¥å¿—)** - äº‹ä»¶è®°å½•
3. **Traces (è¿½è¸ª)** - é“¾è·¯è¿˜åŸ

### ç»“æ„åŒ–æ—¥å¿—

```python
import logging
import json
from datetime import datetime

class StructuredLogger:
    """ç»“æ„åŒ–æ—¥å¿—"""
    def __init__(self):
        self.logger = logging.getLogger("agent")

    def log_request(
        self,
        user_input: str,
        response: str,
        latency: float,
        success: bool,
        context: dict = None
    ):
        log_entry = {
            "timestamp": datetime.utcnow().isoformat(),
            "event": "agent_request",
            "input": user_input,
            "output": response,
            "latency_ms": latency * 1000,
            "success": success,
            "context": context or {}
        }
        self.logger.info(json.dumps(log_entry))


# ä½¿ç”¨
logger = StructuredLogger()

start = time.time()
try:
    result = await agent.ainvoke({"messages": [("user", query)]})
    latency = time.time() - start

    logger.log_request(
        user_input=query,
        response=result["messages"][-1].content,
        latency=latency,
        success=True,
        context={"model": "gpt-4o", "tools_used": ["search"]}
    )
except Exception as e:
    latency = time.time() - start
    logger.log_request(
        user_input=query,
        response=str(e),
        latency=latency,
        success=False,
        context={"error_type": type(e).__name__}
    )
```

### LangSmithé›†æˆ

```python
from langsmith import traceable

@traceable(name="agent_call")
async def traced_agent_call(user_input: str):
    """è‡ªåŠ¨è¿½è¸ªåˆ°LangSmith"""
    return await agent.ainvoke({"messages": [("user", user_input)]})

# LangSmithä¼šè‡ªåŠ¨è®°å½•:
# - æ€»å»¶è¿Ÿ
# - LLMè°ƒç”¨æ¬¡æ•°å’Œæ—¶é—´
# - å·¥å…·è°ƒç”¨æ¬¡æ•°å’Œæ—¶é—´
# - Tokenæ¶ˆè€—
# - å®Œæ•´çš„è°ƒç”¨é“¾è·¯
```

---

## 4.2 å…³é”®æŒ‡æ ‡ç›‘æ§

### æ ¸å¿ƒæŒ‡æ ‡

```python
from prometheus_client import Counter, Histogram, Gauge

# è¯·æ±‚è®¡æ•°
request_count = Counter(
    'agent_requests_total',
    'Total agent requests',
    ['status', 'model']
)

# å»¶è¿Ÿåˆ†å¸ƒ
request_latency = Histogram(
    'agent_request_latency_seconds',
    'Agent request latency',
    ['model']
)

# Tokenæ¶ˆè€—
token_usage = Counter(
    'agent_tokens_total',
    'Total tokens used',
    ['model', 'type']  # type: prompt/completion
)

# å½“å‰å¹¶å‘
concurrent_requests = Gauge(
    'agent_concurrent_requests',
    'Current concurrent requests'
)


# ä½¿ç”¨
@request_latency.labels(model="gpt-4o").time()
async def monitored_agent_call(user_input: str):
    concurrent_requests.inc()

    try:
        result = await agent.ainvoke({"messages": [("user", user_input)]})
        request_count.labels(status="success", model="gpt-4o").inc()

        # è®°å½•Tokenä½¿ç”¨
        token_usage.labels(model="gpt-4o", type="prompt").inc(result['usage']['prompt_tokens'])
        token_usage.labels(model="gpt-4o", type="completion").inc(result['usage']['completion_tokens'])

        return result
    except Exception as e:
        request_count.labels(status="error", model="gpt-4o").inc()
        raise
    finally:
        concurrent_requests.dec()
```

---

# ç¬¬äº”éƒ¨åˆ†:æ¡ˆä¾‹ç ”ç©¶

## 5.1 æ™ºèƒ½å®¢æœAgentä¼˜åŒ–å®æˆ˜

### åœºæ™¯æè¿°

æŸç”µå•†å¹³å°æ™ºèƒ½å®¢æœç³»ç»Ÿ,æ—¥å‡10ä¸‡æ¬¡å¯¹è¯ã€‚

### ä¼˜åŒ–å‰çŠ¶æ€

```
æ€§èƒ½æŒ‡æ ‡:
- å¹³å‡å“åº”æ—¶é—´: 5.2s
- P95å»¶è¿Ÿ: 8.5s
- P99å»¶è¿Ÿ: 12.3s

ç”¨æˆ·ä½“éªŒ:
- ç”¨æˆ·æ»¡æ„åº¦: 62%
- è¶…æ—¶ç‡: 15%
- è½¬äººå·¥ç‡: 35%

æˆæœ¬:
- æœˆåº¦LLMæˆæœ¬: $5,000
- æœåŠ¡å™¨æˆæœ¬: $1,200
```

### ä¼˜åŒ–ç­–ç•¥

#### ä¼˜åŒ–1: å¯ç”¨æµå¼è¾“å‡º
```python
# å‰: éæµå¼,ç”¨æˆ·ç­‰å¾…5s
# å: æµå¼,é¦–å­—å»¶è¿Ÿ0.3s

async def stream_chat():
    async for event in agent.astream_events(input, version="v2"):
        if event["event"] == "on_chat_model_stream":
            yield event["data"]["chunk"].content
```

**æ•ˆæœ**: é¦–å­—å»¶è¿Ÿ â†“94% (5.2s â†’ 0.3s)

#### ä¼˜åŒ–2: Redisç¼“å­˜å¸¸è§é—®é¢˜
```python
cache = RedisCache(redis.Redis(...))
model = ChatOpenAI(model="gpt-4o", cache=cache)

# å‘½ä¸­ç‡: 35%
# ç¼“å­˜å“åº”æ—¶é—´: <50ms
```

**æ•ˆæœ**: 35%è¯·æ±‚å“åº”æ—¶é—´ â†“99%

#### ä¼˜åŒ–3: ç®€å•é—®é¢˜è·¯ç”±åˆ°gpt-4o-mini
```python
def route_model(query):
    if is_simple_qa(query):  # FAQç±»é—®é¢˜
        return "gpt-4o-mini"  # $0.15/1M vs $2.5/1M
    return "gpt-4o"
```

**æ•ˆæœ**: æˆæœ¬ â†“55%

#### ä¼˜åŒ–4: å¹¶è¡Œè°ƒç”¨çŸ¥è¯†åº“å’Œè®¢å•ç³»ç»Ÿ
```python
# å‰: ä¸²è¡Œ - çŸ¥è¯†åº“1s + è®¢å•ç³»ç»Ÿ1s = 2s
# å: å¹¶è¡Œ - max(1s, 1s) = 1s
```

**æ•ˆæœ**: å·¥å…·è°ƒç”¨æ—¶é—´ â†“50%

### ä¼˜åŒ–åçŠ¶æ€

```
æ€§èƒ½æŒ‡æ ‡:
- é¦–å­—å»¶è¿Ÿ: 0.3s (â†“94%)
- å¹³å‡å®Œæ•´å“åº”: 1.8s (â†“65%)
- P95å»¶è¿Ÿ: 3.2s (â†“62%)
- P99å»¶è¿Ÿ: 5.1s (â†“59%)

ç”¨æˆ·ä½“éªŒ:
- ç”¨æˆ·æ»¡æ„åº¦: 89% (â†‘27%)
- è¶…æ—¶ç‡: 2% (â†“13%)
- è½¬äººå·¥ç‡: 18% (â†“17%)

æˆæœ¬:
- æœˆåº¦LLMæˆæœ¬: $2,250 (â†“55%)
- æœåŠ¡å™¨æˆæœ¬: $980 (â†“18%)
```

### æŠ•å…¥äº§å‡ºæ¯”

```
ä¼˜åŒ–æŠ•å…¥:
- å¼€å‘æ—¶é—´: 2å‘¨
- åŸºç¡€è®¾æ–½: Redis ($100/æœˆ)

æ”¶ç›Š:
- æˆæœ¬èŠ‚çœ: $2,870/æœˆ
- ç”¨æˆ·æ»¡æ„åº¦æå‡: 27%
- ROI: ~28å€/å¹´
```

---

## æœ€ä½³å®è·µé€ŸæŸ¥è¡¨

### âœ… å¿…åšæ¸…å• (é«˜ä¼˜å…ˆçº§)

**æ¶æ„è®¾è®¡**:
- [ ] ä½¿ç”¨`create_react_agent`è€Œéæ‰‹åŠ¨å¾ªç¯
- [ ] ç”Ÿäº§ç¯å¢ƒç”¨PostgreSQLæŒä¹…åŒ–checkpointer
- [ ] å·¥å…·å‡½æ•°æœ‰æ¸…æ™°çš„docstringå’Œå‚æ•°è¯´æ˜
- [ ] æ§åˆ¶å·¥å…·æ•°é‡ (3-7ä¸ªæœ€ä¼˜)

**æ€§èƒ½ä¼˜åŒ–**:
- [ ] å¯ç”¨æµå¼è¾“å‡º (æ”¶ç›Šâ­â­â­â­â­, æˆæœ¬ä½)
- [ ] é…ç½®Redisç¼“å­˜ (æ”¶ç›Šâ­â­â­â­, æˆæœ¬ä½)
- [ ] ä½¿ç”¨å¼‚æ­¥è°ƒç”¨ainvoke/astream (æ”¶ç›Šâ­â­â­â­, æˆæœ¬ä½)
- [ ] æ·»åŠ æ€§èƒ½ç›‘æ§

**å¯é æ€§**:
- [ ] æ‰€æœ‰å¤–éƒ¨è°ƒç”¨æ·»åŠ è¶…æ—¶æ§åˆ¶ (30s)
- [ ] å®ç°æŒ‡æ•°é€€é¿é‡è¯• (è‡³å°‘3æ¬¡)
- [ ] åŒºåˆ†å¯æ¢å¤/ä¸å¯æ¢å¤é”™è¯¯
- [ ] å…³é”®è·¯å¾„æ·»åŠ é™çº§æ–¹æ¡ˆ

**ç›‘æ§**:
- [ ] é›†æˆLangSmithè¿½è¸ª
- [ ] è®°å½•å…³é”®æŒ‡æ ‡ (å»¶è¿Ÿã€æˆæœ¬ã€é”™è¯¯ç‡)
- [ ] è®¾ç½®é”™è¯¯ç‡å‘Šè­¦ (>5%)
- [ ] å®šæœŸå®¡æŸ¥é”™è¯¯æ—¥å¿—

### â­ æ¨èæ¸…å• (ä¸­ä¼˜å…ˆçº§)

- [ ] å®ç°æ¨¡å‹è·¯ç”±é™ä½æˆæœ¬
- [ ] æ–­è·¯å™¨ä¿æŠ¤ä¸‹æ¸¸æœåŠ¡
- [ ] è¯­ä¹‰ç¼“å­˜æå‡å‘½ä¸­ç‡
- [ ] ç¼–å†™æ ¸å¿ƒåœºæ™¯æµ‹è¯•ç”¨ä¾‹
- [ ] é›†æˆSentryé”™è¯¯è¿½è¸ª

### ğŸš€ é«˜çº§æ¸…å• (å¯é€‰)

- [ ] è¾¹ç¼˜éƒ¨ç½²é™ä½å…¨çƒå»¶è¿Ÿ
- [ ] é¢„æµ‹æ€§é¢„åŠ è½½
- [ ] è‡ªåŠ¨åŒ–é”™è¯¯åˆ†ç±»ä¸æ¢å¤
- [ ] æ„å»ºè¯„ä¼°åŸºå‡†
- [ ] A/Bæµ‹è¯•ç³»ç»Ÿ

---

## å­¦ä¹ è·¯å¾„å»ºè®®

### è·¯å¾„1: å¿«é€Ÿæå‡ (1-2å‘¨)
é€‚åˆ: å·²æœ‰Agenté¡¹ç›®,éœ€è¦å¿«é€Ÿä¼˜åŒ–

```
ç¬¬äºŒéƒ¨åˆ† (æ€§èƒ½ä¼˜åŒ–) â†’ ç¬¬ä¸‰éƒ¨åˆ† (å¯é æ€§) â†’ ç¬¬å››éƒ¨åˆ† (ç›‘æ§)
```

### è·¯å¾„2: ç³»ç»Ÿå­¦ä¹  (4-6å‘¨)
é€‚åˆ: ä»é›¶æ„å»ºç”Ÿäº§çº§Agent

```
ç¬¬ä¸€éƒ¨åˆ† (æ¶æ„) â†’ ç¬¬äºŒéƒ¨åˆ† (æ€§èƒ½) â†’ ç¬¬ä¸‰éƒ¨åˆ† (å¯é æ€§)
  â†’ ç¬¬å››éƒ¨åˆ† (ç›‘æ§) â†’ ç¬¬äº”éƒ¨åˆ† (æ¡ˆä¾‹)
```

### è·¯å¾„3: ä¸“é¡¹æ·±å…¥ (æŒ‰éœ€)
é€‚åˆ: é’ˆå¯¹ç‰¹å®šé—®é¢˜

```
æ ¹æ®å®é™…é—®é¢˜é€‰æ‹©å¯¹åº”ç« èŠ‚æ·±å…¥ç ”ç©¶
```

---

## ç¯å¢ƒå‡†å¤‡

### ä¾èµ–å®‰è£…

```bash
# æ ¸å¿ƒä¾èµ–
pip install langchain>=1.0.7
pip install langgraph>=1.0.3
pip install langsmith>=0.2.0

# LLM Providers
pip install langchain-openai>=1.0.3
pip install langchain-anthropic

# æ•°æ®å­˜å‚¨
pip install langchain-chroma
pip install redis
pip install psycopg2-binary

# ç›‘æ§ä¸æµ‹è¯•
pip install prometheus-client
pip install pytest pytest-asyncio
pip install tenacity  # é‡è¯•åº“
pip install sentry-sdk  # é”™è¯¯è¿½è¸ª
```

### ç¯å¢ƒå˜é‡

```bash
# .envæ–‡ä»¶
OPENAI_API_KEY=sk-...
LANGCHAIN_API_KEY=ls__...
LANGCHAIN_TRACING_V2=true
LANGCHAIN_PROJECT=agent-production

# PostgreSQL (å¯é€‰)
POSTGRES_URI=postgresql://user:pass@localhost:5432/langchain

# Redis (å¯é€‰)
REDIS_HOST=localhost
REDIS_PORT=6379
```

---

## å‚è€ƒèµ„æº

### å®˜æ–¹æ–‡æ¡£
- [LangChain Docs](https://docs.langchain.com)
- [LangGraph Docs](https://docs.langchain.com/oss/python/langgraph/)
- [LangSmith Docs](https://docs.smith.langchain.com/)

### ç›¸å…³ç¬”è®°
- [LangChainç¬”è®°](../../chapter27/LangChainç¬”è®°.md) - åŸºç¡€æ•™ç¨‹
- [å¤§æ¨¡å‹è®¾è®¡æ€æƒ³](./3.%20å¤§æ¨¡å‹è®¾è®¡æ€æƒ³.md) - è®¾è®¡ç†å¿µ

### ç¤¾åŒºèµ„æº
- [LangChain GitHub](https://github.com/langchain-ai/langchain)
- [LangChain Discord](https://discord.gg/langchain)
- [LangChain Blog](https://blog.langchain.com)

---

**ç»´æŠ¤**: LangChainç¬”è®°é¡¹ç›®ç»„
**ç‰ˆæœ¬**: v1.0.0
**æœ€åæ›´æ–°**: 2025-11-20
