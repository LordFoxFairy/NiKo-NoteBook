# 第6章：数据工程基础

> Data-Centric AI 宣言：与其死磕模型结构，不如好好洗洗数据。
>
> 好的数据工程能让 7B 模型吊打 13B 模型（如 Llama-3, Phi-3 的成功），而坏的数据会让 100B 模型变成人工智障。

---

## 目录
- [一、数据工程全景图](#一数据工程全景图)
  - [1. 预训练数据 pipeline](#1-预训练数据-pipeline)
  - [2. SFT/RLHF 数据 pipeline](#2-sftrlhf-数据-pipeline)
- [二、数据清洗与质量过滤](#二数据清洗与质量过滤)
  - [1. 启发式过滤 (Heuristic Filtering)](#1-启发式过滤-heuristic-filtering)
  - [2. 基于模型的质量评分 (Quality Classifier)](#2-基于模型的质量评分-quality-classifier)
- [三、核心技术：大规模去重](#三核心技术大规模去重)
  - [1. 精确去重 (Exact Deduplication)](#1-精确去重-exact-deduplication)
  - [2. 模糊去重 (Fuzzy Deduplication)：MinHash + LSH](#2-模糊去重-fuzzy-deduplicationminhash--lsh)
  - [3. 代码实战：手写 MinHash](#3-代码实战手写-minhash)
- [四、隐私保护与去毒](#四隐私保护与去毒)
  - [1. PII 识别与脱敏](#1-pii-识别与脱敏)
  - [2. 毒性检测](#2-毒性检测)
- [五、合成数据：无需人工的数据工厂](#五合成数据无需人工的数据工厂)
  - [1. Self-Instruct：模型教模型](#1-self-instruct模型教模型)
  - [2. Evol-Instruct：让指令进化](#2-evol-instruct让指令进化)
  - [3. Code实战：使用 LLM 生成 SFT 数据](#3-code实战使用-llm-生成-sft-数据)
- [六、本章小结](#六本章小结)

---

## 一、数据工程全景图

### 1. 预训练数据 pipeline

预训练数据量级通常在 **Trillion (万亿)** 级别（如 Llama-3 用了 15T tokens）。

$$
\text{Raw Crawl} \xrightarrow{\text{URL过滤}} \text{Text Extraction} \xrightarrow{\text{语言识别}} \text{Quality Filter} \xrightarrow{\text{去重}} \text{PII Removal} \xrightarrow{\text{Tokenization}} \text{Training Data}
$$

**FineWeb (HuggingFace)** 是目前的黄金标准数据集，它的清洗流程被证明非常有效。

### 2. SFT/RLHF 数据 pipeline

指令微调数据量级通常在 **10k - 100k** 级别。重点不是数量，而是**多样性 (Diversity)** 和 **复杂度 (Complexity)**。

---

## 二、数据清洗与质量过滤

### 1. 启发式过滤 (Heuristic Filtering)

这是最快、成本最低的过滤手段。Gopher 和 Falcon 论文中列出了经典规则：

- **长度过滤**：去除过短（< 50 tokens）或过长（> 100k tokens）的文档。
- **平均词长**：如果平均每个词超过 10 个字符，大概率是乱码或日志。
- **符号比例**：如果 `#`, `{`, `}` 等符号占比过高，可能是代码或数据Dump（除非你有意训练代码模型）。
- **停止词比例**：一篇文章如果不包含 `the`, `and`, `of` 等高频停止词，可能不是自然语言。

```python
def heuristic_filter(text):
    """简单的启发式过滤规则"""
    if len(text) < 100: return False # 太短

    # 计算符号占比
    symbol_ratio = len([c for c in text if c in "#{}[]<>"]) / len(text)
    if symbol_ratio > 0.1: return False # 可能是代码片段

    # 计算平均词长
    words = text.split()
    mean_word_len = sum(len(w) for w in words) / len(words)
    if mean_word_len > 10: return False # 可能是乱码

    return True
```

### 2. 基于模型的质量评分 (Quality Classifier)

仅仅靠规则是不够的。我们需要训练一个二分类器（High Quality vs Low Quality）。

**正样本**：Wikipedia, arXiv 论文, 书籍。
**负样本**：CommonCrawl 中随机抽取的未清洗网页。

**工具**：通常使用轻量级模型（如 fastText 或 BERT-Tiny），因为要处理 TB 级数据。

---

## 三、核心技术：大规模去重

重复数据会导致：
1.  **性能下降**：模型死记硬背，泛化能力变差。
2.  **隐私泄露**：重复出现的 PII 更容易被模型生成。
3.  **计算浪费**：Llama-3 论文指出，去重后训练效率提升明显。

### 1. 精确去重 (Exact Deduplication)

使用 SHA-256 算法计算文档的 Hash 值，相同的直接删除。
更细粒度的：按行去重（Line-level deduplication），删除导航栏、Footer 等重复模版。

### 2. 模糊去重 (Fuzzy Deduplication)：MinHash + LSH

如何发现这两句话是重复的？
> A: "The quick brown fox jumps over the lazy dog."
> B: "The quick brown fox jumped over the lazy dog!"

它们 Hash 值完全不同，但语义高度相似（Jaccard 相似度高）。
在海量数据中两两计算相似度是 $O(N^2)$，这是不可接受的。
**MinHash + LSH (Locality Sensitive Hashing)** 可以在 $O(N)$ 时间内解决问题。

**原理**：
1.  **Shingling**: 将文本切分为 n-grams 集合。
2.  **MinHash签名**: 使用 $K$ 个随机哈希函数，保留最小哈希值。这 $K$ 个值组成了文档的“指纹”。
    - 定理：两个集合的 MinHash 值相等的概率 **等于** 它们的 Jaccard 相似度。
3.  **LSH (局部敏感哈希)**: 将签名切分为 $b$ 个 Band。只要有两个文档在任意一个 Band 上 Hash 碰撞，就认为它们是“候选相似对”。

### 3. 代码实战：手写 MinHash

```python
import re
import random
import hashlib
import numpy as np

class MinHashLSH:
    def __init__(self, num_perm=128, threshold=0.8):
        self.num_perm = num_perm # 生成 K 个签名
        self.threshold = threshold
        # 初始化 K 个随机哈希参数 (a*x + b) % p
        self.perms = [
            (random.randint(1, 2**32), random.randint(0, 2**32))
            for _ in range(num_perm)
        ]
        self.prime = 4294967311 # 一个大于 2^32 的质数

    def get_minhash(self, text):
        """计算文本的 MinHash 签名"""
        # 1. Shingling (3-grams)
        words = re.findall(r'\w+', text.lower())
        shingles = set(
            " ".join(words[i:i+3]) for i in range(len(words)-2)
        )

        if not shingles:
            return np.zeros(self.num_perm)

        # 2. 计算签名
        signature = np.full(self.num_perm, np.inf)

        # 把每个 shingle hash 成整数
        shingle_hashes = [
            int(hashlib.md5(s.encode('utf-8')).hexdigest(), 16) % self.prime
            for s in shingles
        ]

        # 对每个 shingle，更新 K 个哈希函数的最小值
        for sh_hash in shingle_hashes:
            for i, (a, b) in enumerate(self.perms):
                h = (a * sh_hash + b) % self.prime
                if h < signature[i]:
                    signature[i] = h

        return signature

    def compute_jaccard(self, sig1, sig2):
        """估算 Jaccard 相似度"""
        return np.mean(sig1 == sig2)

# 测试
lsh = MinHashLSH(num_perm=128)

text1 = "The quick brown fox jumps over the lazy dog"
text2 = "The quick brown fox jumped over the lazy dog" # 相似
text3 = "Machine learning is fascinating and powerful" # 不相似

sig1 = lsh.get_minhash(text1)
sig2 = lsh.get_minhash(text2)
sig3 = lsh.get_minhash(text3)

print(f"Sim(1, 2): {lsh.compute_jaccard(sig1, sig2):.2f}") # 应该接近 1.0
print(f"Sim(1, 3): {lsh.compute_jaccard(sig1, sig3):.2f}") # 应该接近 0.0
```

---

## 四、隐私保护与去毒

### 1. PII 识别与脱敏

**PII (Personally Identifiable Information)** 包含：邮箱、电话、IP、住址、SSN等。

**StarCoder 做法**：
使用正则 + NER (命名实体识别) 模型，将 PII 替换为特殊 Token。
`john.doe@gmail.com` -> `<NAME>@<EMAIL_DOMAIN>`

**工具**：微软的 `Presidio` 是工业界标准。

### 2. 毒性检测

使用 Jigsaw 维护的 `Perspectives API` 或者 BERT-Toxic 模型，过滤掉仇恨言论、色情暴力内容。

---

## 五、合成数据：无需人工的数据工厂

在 SFT 阶段，高质量人工标注数据（如 ShareGPT）已经用光了。现在流行用**强模型生产数据**来训练**弱模型**。

### 1. Self-Instruct：模型教模型

**流程 (Wang et al., 2022)**：
1.  **种子库**：人工写 175 个高质量指令。
2.  **生成指令**：让 LLM (如 GPT-4) 参考种子，生成新的类似指令。
    > Prompt: "Here are some instructions. Please generate 5 more diverse instructions."
3.  **生成输出**：让 LLM 针对生成指令写出回复。
4.  **过滤**：去除低质量或重复的。
5.  **循环**：把新生成的加入种子库，迭代生成。

Alpaca 就是这么搞出来的，只花了 $500 的 OpenAI API 费用。

### 2. Evol-Instruct：让指令进化

WizardLM 提出的 **Evol-Instruct** 能够显著提升复杂指令的推理能力。

它通过 Prompt 让模型修改现有指令，使其变得更难：
1.  **深度进化 (Deepening)**：增加限制条件、要求多步推理。
    - 原指令：写一个 Python 贪吃蛇。
    - 进化后：写一个 Python 贪吃蛇，**必须使用 OOP 设计，且要有 AI 对手**。
2.  **广度进化 (Broadening)**：改变领域或话题。

### 3. Code实战：使用 LLM 生成 SFT 数据

```python
from openai import OpenAI
import json

client = OpenAI()

def evol_instruction(instruction):
    prompt = f"""
    I want you to act as an Instruction Rewriter.
    Please rewrite the following instruction to make it more complex and difficult.
    You can add constraints, require multiple steps, or ask for specific formats.

    Original Instruction: {instruction}

    Rewritten Instruction:
    """

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content

# 原始简单指令
base_instructions = [
    "Explain quantum computing.",
    "Write a quicksort in Python."
]

# 进化！
evolved_data = []
for inst in base_instructions:
    new_inst = evol_instruction(inst)
    # 再让模型生成答案
    answer = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": new_inst}]
    ).choices[0].message.content

    evolved_data.append({
        "instruction": new_inst,
        "output": answer
    })

# 保存为 SFT 格式
with open("evol_dataset.json", "w") as f:
    json.dump(evolved_data, f, indent=2)
```

通过这种方式，我们可以把简单的 Wiki 百科条目，变成复杂的问答推理题，极大提升数据含金量。

---

## 六、本章小结

1.  **数据质量 > 数据数量**。宁可要 10B 的高质量 tokens，也不要 100B 的垃圾 tokens。
2.  **去重是必选项**。MinHash 是大规模去重的瑞士军刀。
3.  **合成数据是未来**。随着模型越来越强，人类能产生的高质量数据越来越少，AI 必须学会自我博弈和自我进化 (Self-Play)。

掌握了数据工程，你就掌握了大模型一半的命脉。

---

**下一章预告：** 第7章 - 模型评估与榜单

在下一章中，我们将学习如何科学地评估 LLM 的能力，不再被各种刷榜分数忽悠。
