# ç¬¬1ç« ï¼šå¾®è°ƒä½ çš„ä¸“å±æ¨¡å‹

> è®©é€šç”¨æ¨¡å‹å˜æˆä½ çš„ä¸“å±åŠ©æ‰‹

ç»è¿‡é¢„è®­ç»ƒï¼Œå¤§è¯­è¨€æ¨¡å‹å·²ç»æŒæ¡äº†è¯­è¨€çš„åŸºç¡€èƒ½åŠ›ã€‚ä½†é¢„è®­ç»ƒæ¨¡å‹å°±åƒä¸€ä¸ªåšå­¦çš„é€šæ‰â€”â€”ä»€ä¹ˆéƒ½æ‡‚ä¸€ç‚¹ï¼Œä½†åœ¨ç‰¹å®šä»»åŠ¡ä¸Šå¯èƒ½ä¸å¤Ÿä¸“ä¸šã€‚

**å¾®è°ƒï¼ˆFine-tuningï¼‰** å°±æ˜¯å°†è¿™ä¸ªé€šæ‰æ”¹é€ æˆä¸“å®¶çš„è¿‡ç¨‹ã€‚

æœ¬ç« å°†å¸¦ä½ æ·±å…¥ç†è§£å¾®è°ƒçš„åŸç†ä¸å®è·µï¼Œä»å…¨å‚æ•°å¾®è°ƒåˆ°å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰ï¼Œä»LoRAåˆ°æ¨¡å‹åˆå¹¶ï¼ŒæŒæ¡å®šåˆ¶ä¸“å±æ¨¡å‹çš„å…¨å¥—æŠ€æœ¯ã€‚

---

## ä¸€ã€ä»€ä¹ˆæ˜¯å¾®è°ƒï¼Ÿ

### 1. å¾®è°ƒçš„æœ¬è´¨

ä»ä¼˜åŒ–çš„è§’åº¦çœ‹ï¼Œå¾®è°ƒæ˜¯ï¼š

$$
\theta^* = \arg\min_{\theta} \mathcal{L}_{\text{task}}(\mathcal{D}_{\text{task}}; \theta_{\text{pretrain}} + \Delta\theta)
$$

å…¶ä¸­ï¼š
- $\theta_{\text{pretrain}}$ï¼šé¢„è®­ç»ƒæ¨¡å‹çš„å‚æ•°
- $\Delta\theta$ï¼šå¾®è°ƒæ—¶æ›´æ–°çš„å‚æ•°
- $\mathcal{L}_{\text{task}}$ï¼šç‰¹å®šä»»åŠ¡çš„æŸå¤±å‡½æ•°
- $\mathcal{D}_{\text{task}}$ï¼šä»»åŠ¡æ•°æ®é›†

**å…³é”®ç†è§£**ï¼š

```python
from dataclasses import dataclass
from typing import Literal

@dataclass
class TrainingParadigm:
    """è®­ç»ƒèŒƒå¼å¯¹æ¯”"""
    name: str
    objective: str
    data_scale: str
    data_source: str
    compute_cost: str
    goal: str

paradigms = [
    TrainingParadigm(
        "é¢„è®­ç»ƒ",
        "è¯­è¨€å»ºæ¨¡ï¼ˆé¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼‰",
        "TBçº§ï¼ˆæ•°ä¸‡äº¿Tokenï¼‰",
        "äº’è”ç½‘ã€ä¹¦ç±ã€ä»£ç ",
        "æ•°åƒä¸‡ç¾å…ƒ",
        "å­¦ä¹ è¯­è¨€çš„é€šç”¨è§„å¾‹"
    ),
    TrainingParadigm(
        "å¾®è°ƒ",
        "ä»»åŠ¡ç‰¹å®šæŸå¤±",
        "MB-GBçº§ï¼ˆæ•°åƒåˆ°æ•°ç™¾ä¸‡æ ·æœ¬ï¼‰",
        "äººå·¥æ ‡æ³¨ã€åˆæˆæ•°æ®",
        "æ•°ç™¾åˆ°æ•°åƒç¾å…ƒ",
        "é€‚é…ç‰¹å®šä»»åŠ¡æˆ–é¢†åŸŸ"
    ),
]

print("é¢„è®­ç»ƒ vs å¾®è°ƒå¯¹æ¯”:")
print("=" * 90)
for p in paradigms:
    print(f"\n{p.name}:")
    print(f"  ç›®æ ‡: {p.objective}")
    print(f"  æ•°æ®è§„æ¨¡: {p.data_scale}")
    print(f"  æ•°æ®æ¥æº: {p.data_source}")
    print(f"  è®¡ç®—æˆæœ¬: {p.compute_cost}")
    print(f"  æœ€ç»ˆç›®æ ‡: {p.goal}")
```

**è¾“å‡º**:
```
é¢„è®­ç»ƒ vs å¾®è°ƒå¯¹æ¯”:
==========================================================================================

é¢„è®­ç»ƒ:
  ç›®æ ‡: è¯­è¨€å»ºæ¨¡ï¼ˆé¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼‰
  æ•°æ®è§„æ¨¡: TBçº§ï¼ˆæ•°ä¸‡äº¿Tokenï¼‰
  æ•°æ®æ¥æº: äº’è”ç½‘ã€ä¹¦ç±ã€ä»£ç 
  è®¡ç®—æˆæœ¬: æ•°åƒä¸‡ç¾å…ƒ
  æœ€ç»ˆç›®æ ‡: å­¦ä¹ è¯­è¨€çš„é€šç”¨è§„å¾‹

å¾®è°ƒ:
  ç›®æ ‡: ä»»åŠ¡ç‰¹å®šæŸå¤±
  æ•°æ®è§„æ¨¡: MB-GBçº§ï¼ˆæ•°åƒåˆ°æ•°ç™¾ä¸‡æ ·æœ¬ï¼‰
  æ•°æ®æ¥æº: äººå·¥æ ‡æ³¨ã€åˆæˆæ•°æ®
  è®¡ç®—æˆæœ¬: æ•°ç™¾åˆ°æ•°åƒç¾å…ƒ
  æœ€ç»ˆç›®æ ‡: é€‚é…ç‰¹å®šä»»åŠ¡æˆ–é¢†åŸŸ
```

### 2. ç›‘ç£å¼å¾®è°ƒï¼ˆSupervised Fine-Tuning, SFTï¼‰

ç›‘ç£å¼å¾®è°ƒæ˜¯æœ€å¸¸è§çš„å¾®è°ƒæ–¹å¼ï¼Œä½¿ç”¨æ ‡æ³¨æ•°æ®è®­ç»ƒæ¨¡å‹ã€‚

**æŸå¤±å‡½æ•°**ï¼š

å¯¹äºç”Ÿæˆä»»åŠ¡ï¼ˆå¦‚å¯¹è¯ã€æ‘˜è¦ï¼‰ï¼ŒSFTä½¿ç”¨äº¤å‰ç†µæŸå¤±ï¼š

$$
\mathcal{L}_{\text{SFT}} = -\frac{1}{N}\sum_{i=1}^{N}\sum_{t=1}^{T_i} \log P(y_t^{(i)} | y_{<t}^{(i)}, x^{(i)}; \theta)
$$

å…¶ä¸­ï¼š
- $x^{(i)}$ï¼šç¬¬ i ä¸ªè¾“å…¥ï¼ˆå¦‚ç”¨æˆ·é—®é¢˜ï¼‰
- $y^{(i)}$ï¼šç¬¬ i ä¸ªè¾“å‡ºï¼ˆå¦‚æ¨¡å‹å›ç­”ï¼‰
- $T_i$ï¼šè¾“å‡ºåºåˆ—é•¿åº¦

**å…³é”®ç‰¹ç‚¹**ï¼š

```python
import torch
import torch.nn.functional as F
from typing import Tuple

def compute_sft_loss(
    logits: torch.Tensor,      # [batch, seq_len, vocab_size]
    labels: torch.Tensor,      # [batch, seq_len]
    ignore_index: int = -100   # ä¸å‚ä¸æŸå¤±è®¡ç®—çš„Token
) -> Tuple[torch.Tensor, dict]:
    """è®¡ç®—SFTæŸå¤±"""

    # åªè®¡ç®—æ ‡ç­¾éƒ¨åˆ†çš„æŸå¤±ï¼ˆé€šå¸¸æ˜¯å›ç­”éƒ¨åˆ†ï¼‰
    shift_logits = logits[..., :-1, :].contiguous()
    shift_labels = labels[..., 1:].contiguous()

    # å±•å¹³ä¸º2D
    shift_logits = shift_logits.view(-1, shift_logits.size(-1))
    shift_labels = shift_labels.view(-1)

    # è®¡ç®—äº¤å‰ç†µæŸå¤±
    loss = F.cross_entropy(
        shift_logits,
        shift_labels,
        ignore_index=ignore_index,
        reduction='mean'
    )

    # ç»Ÿè®¡ä¿¡æ¯
    valid_tokens = (shift_labels != ignore_index).sum().item()
    perplexity = torch.exp(loss).item()

    return loss, {
        "loss": loss.item(),
        "perplexity": perplexity,
        "valid_tokens": valid_tokens
    }

# ç¤ºä¾‹ï¼šå¯¹è¯æ•°æ®çš„æ ‡ç­¾æ©ç 
def create_dialogue_labels(input_ids: torch.Tensor, response_start: int) -> torch.Tensor:
    """åˆ›å»ºå¯¹è¯æ•°æ®çš„æ ‡ç­¾ï¼ˆåªè®¡ç®—å›ç­”éƒ¨åˆ†çš„æŸå¤±ï¼‰"""
    labels = input_ids.clone()

    # å°†é—®é¢˜éƒ¨åˆ†çš„Tokenæ ‡è®°ä¸º-100ï¼ˆä¸å‚ä¸æŸå¤±è®¡ç®—ï¼‰
    labels[:, :response_start] = -100

    return labels

# æ¨¡æ‹Ÿç¤ºä¾‹
batch_size, seq_len, vocab_size = 2, 10, 50000
logits = torch.randn(batch_size, seq_len, vocab_size)
input_ids = torch.randint(0, vocab_size, (batch_size, seq_len))

# å‡è®¾å‰5ä¸ªTokenæ˜¯é—®é¢˜ï¼Œå5ä¸ªæ˜¯å›ç­”
labels = create_dialogue_labels(input_ids, response_start=5)

loss, stats = compute_sft_loss(logits, labels)

print("SFTæŸå¤±è®¡ç®—:")
print(f"  æŸå¤±å€¼: {stats['loss']:.4f}")
print(f"  å›°æƒ‘åº¦: {stats['perplexity']:.2f}")
print(f"  æœ‰æ•ˆTokenæ•°: {stats['valid_tokens']}")
print(f"\nå…³é”®è®¾è®¡: åªè®¡ç®—å›ç­”éƒ¨åˆ†çš„æŸå¤±ï¼Œé¿å…æ¨¡å‹å­¦ä¹ é‡å¤ç”¨æˆ·è¾“å…¥")
```

### 3. å¾®è°ƒä¸é¢„è®­ç»ƒçš„å…³ç³»

å¾®è°ƒä¸æ˜¯ä»å¤´è®­ç»ƒï¼Œè€Œæ˜¯**è¿ç§»å­¦ä¹ **ï¼š

```mermaid
graph LR
    A[é¢„è®­ç»ƒæ¨¡å‹<br/>é€šç”¨è¯­è¨€èƒ½åŠ›] -->|åˆå§‹åŒ–| B[å¾®è°ƒé˜¶æ®µ]
    B -->|ä»»åŠ¡æ•°æ®| C[ä¸“ç”¨æ¨¡å‹<br/>ç‰¹å®šä»»åŠ¡èƒ½åŠ›]

    style A fill:#e1f5ff
    style C fill:#fff4e1
```

**ä¸ºä»€ä¹ˆå¾®è°ƒæœ‰æ•ˆï¼Ÿ**

1. **ç‰¹å¾å¤ç”¨**ï¼šé¢„è®­ç»ƒå­¦åˆ°çš„è¯­è¨€è¡¨ç¤ºå¯è¿ç§»
   - ä½å±‚ï¼šè¯æ³•ã€å¥æ³•ç‰¹å¾ï¼ˆå¦‚åˆ†è¯ã€è¯­æ³•ï¼‰
   - é«˜å±‚ï¼šè¯­ä¹‰ç‰¹å¾ï¼ˆå¦‚å®ä½“è¯†åˆ«ã€æƒ…æ„Ÿç†è§£ï¼‰

2. **å‚æ•°åˆå§‹åŒ–**ï¼šé¢„è®­ç»ƒæä¾›äº†å¥½çš„èµ·ç‚¹
   - æŸå¤±æ™¯è§‚æ›´å¹³æ»‘
   - æ”¶æ•›é€Ÿåº¦æ›´å¿«
   - æ³›åŒ–èƒ½åŠ›æ›´å¼º

3. **æ•°æ®æ•ˆç‡**ï¼šå°‘é‡æ•°æ®å³å¯è¾¾åˆ°å¥½æ•ˆæœ

**å®éªŒéªŒè¯**ï¼š

```python
import numpy as np
from dataclasses import dataclass
from typing import List

@dataclass
class FineTuningExperiment:
    """å¾®è°ƒå®éªŒç»“æœ"""
    model_size: str
    pretrain_data_tb: float
    finetune_samples: int
    task_accuracy: float
    scratch_accuracy: float  # ä»å¤´è®­ç»ƒçš„å‡†ç¡®ç‡

experiments = [
    # æƒ…æ„Ÿåˆ†ç±»ä»»åŠ¡ï¼ˆIMDbï¼‰
    FineTuningExperiment("BERT-Base", 0.016, 1000, 89.5, 62.3),
    FineTuningExperiment("BERT-Base", 0.016, 5000, 92.8, 78.1),
    FineTuningExperiment("BERT-Base", 0.016, 20000, 94.2, 87.5),

    # å‘½åå®ä½“è¯†åˆ«ï¼ˆCoNLL-2003ï¼‰
    FineTuningExperiment("RoBERTa-Large", 0.160, 500, 88.3, 45.2),
    FineTuningExperiment("RoBERTa-Large", 0.160, 2000, 91.7, 72.8),
]

print("å¾®è°ƒ vs ä»å¤´è®­ç»ƒå¯¹æ¯”:")
print("=" * 100)
print(f"{'æ¨¡å‹':^15} | {'é¢„è®­ç»ƒæ•°æ®':^12} | {'å¾®è°ƒæ ·æœ¬æ•°':^10} | "
      f"{'å¾®è°ƒå‡†ç¡®ç‡':^10} | {'ä»å¤´è®­ç»ƒ':^10} | {'æå‡':^8}")
print("-" * 100)

for exp in experiments:
    improvement = exp.task_accuracy - exp.scratch_accuracy
    print(f"{exp.model_size:^15} | {exp.pretrain_data_tb:^10.3f}TB | "
          f"{exp.finetune_samples:^10,} | {exp.task_accuracy:^10.1f}% | "
          f"{exp.scratch_accuracy:^10.1f}% | {improvement:^7.1f}%")

print("\nå…³é”®å‘ç°:")
print("  1. å³ä½¿åªæœ‰1000ä¸ªæ ·æœ¬ï¼Œå¾®è°ƒä¹Ÿèƒ½è¾¾åˆ°89.5%çš„å‡†ç¡®ç‡")
print("  2. ä»å¤´è®­ç»ƒéœ€è¦æ›´å¤šæ•°æ®æ‰èƒ½è¾¾åˆ°ç›¸åŒæ•ˆæœ")
print("  3. é¢„è®­ç»ƒæä¾›çš„åˆå§‹åŒ–å¸¦æ¥äº†20-40%çš„æ€§èƒ½æå‡")
```

**è¾“å‡º**:
```
å¾®è°ƒ vs ä»å¤´è®­ç»ƒå¯¹æ¯”:
====================================================================================================
     æ¨¡å‹      |   é¢„è®­ç»ƒæ•°æ®   |  å¾®è°ƒæ ·æœ¬æ•°  |  å¾®è°ƒå‡†ç¡®ç‡  |   ä»å¤´è®­ç»ƒ   |  æå‡
----------------------------------------------------------------------------------------------------
  BERT-Base   |   0.016TB   |      1,000 |    89.5%   |    62.3%   |  27.2%
  BERT-Base   |   0.016TB   |      5,000 |    92.8%   |    78.1%   |  14.7%
  BERT-Base   |   0.016TB   |     20,000 |    94.2%   |    87.5%   |   6.7%
RoBERTa-Large |   0.160TB   |        500 |    88.3%   |    45.2%   |  43.1%
RoBERTa-Large |   0.160TB   |      2,000 |    91.7%   |    72.8%   |  18.9%

å…³é”®å‘ç°:
  1. å³ä½¿åªæœ‰1000ä¸ªæ ·æœ¬ï¼Œå¾®è°ƒä¹Ÿèƒ½è¾¾åˆ°89.5%çš„å‡†ç¡®ç‡
  2. ä»å¤´è®­ç»ƒéœ€è¦æ›´å¤šæ•°æ®æ‰èƒ½è¾¾åˆ°ç›¸åŒæ•ˆæœ
  3. é¢„è®­ç»ƒæä¾›çš„åˆå§‹åŒ–å¸¦æ¥äº†20-40%çš„æ€§èƒ½æå‡
```

---

## äºŒã€å…¨é‡å¾®è°ƒ vs. å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰

### 1. å…¨é‡å¾®è°ƒçš„æŒ‘æˆ˜

å…¨é‡å¾®è°ƒï¼ˆFull Fine-Tuningï¼‰æ˜¯æŒ‡æ›´æ–°æ¨¡å‹çš„æ‰€æœ‰å‚æ•°ã€‚

**æ˜¾å­˜å ç”¨åˆ†æ**ï¼š

è®­ç»ƒä¸€ä¸ªæ¨¡å‹éœ€è¦çš„æ˜¾å­˜åŒ…æ‹¬ï¼š

$$
\text{Total Memory} = \text{Model} + \text{Optimizer} + \text{Gradients} + \text{Activations}
$$

å…·ä½“è®¡ç®—ï¼š

```python
from dataclasses import dataclass
import math

@dataclass
class MemoryCalculator:
    """æ˜¾å­˜å ç”¨è®¡ç®—å™¨"""
    num_params_b: float      # å‚æ•°é‡ï¼ˆåäº¿ï¼‰
    precision: str           # ç²¾åº¦ï¼ˆfp32/fp16/bf16ï¼‰
    optimizer: str           # ä¼˜åŒ–å™¨ï¼ˆadam/sgdï¼‰
    seq_length: int          # åºåˆ—é•¿åº¦
    batch_size: int          # æ‰¹æ¬¡å¤§å°
    gradient_checkpointing: bool = False  # æ˜¯å¦ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹

    @property
    def bytes_per_param(self) -> int:
        """æ¯ä¸ªå‚æ•°çš„å­—èŠ‚æ•°"""
        return {"fp32": 4, "fp16": 2, "bf16": 2}[self.precision]

    @property
    def model_memory_gb(self) -> float:
        """æ¨¡å‹å‚æ•°æ˜¾å­˜ï¼ˆGBï¼‰"""
        return self.num_params_b * self.bytes_per_param

    @property
    def optimizer_memory_gb(self) -> float:
        """ä¼˜åŒ–å™¨çŠ¶æ€æ˜¾å­˜ï¼ˆGBï¼‰"""
        if self.optimizer == "adam":
            # Adamå­˜å‚¨2ä¸ªçŠ¶æ€ï¼ˆmomentumå’Œvarianceï¼‰
            return self.num_params_b * 4 * 2  # FP32å­˜å‚¨
        elif self.optimizer == "sgd":
            return self.num_params_b * 4  # åªå­˜å‚¨momentum
        else:
            return 0

    @property
    def gradient_memory_gb(self) -> float:
        """æ¢¯åº¦æ˜¾å­˜ï¼ˆGBï¼‰"""
        return self.num_params_b * self.bytes_per_param

    @property
    def activation_memory_gb(self) -> float:
        """æ¿€æ´»å€¼æ˜¾å­˜ï¼ˆGBï¼‰- ç®€åŒ–ä¼°ç®—"""
        # æ¿€æ´»å€¼ä¸åºåˆ—é•¿åº¦ã€æ‰¹æ¬¡å¤§å°ã€å±‚æ•°ç›¸å…³
        num_layers = int(math.sqrt(self.num_params_b * 1e9 / 150e6))

        if self.gradient_checkpointing:
            # ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼šO(sqrt(N))
            return 0.1 * self.batch_size * self.seq_length * num_layers / 1024
        else:
            # ä¸ä½¿ç”¨æ£€æŸ¥ç‚¹ï¼šO(N)
            return 0.5 * self.batch_size * self.seq_length * num_layers / 1024

    @property
    def total_memory_gb(self) -> float:
        """æ€»æ˜¾å­˜éœ€æ±‚ï¼ˆGBï¼‰"""
        return (self.model_memory_gb +
                self.optimizer_memory_gb +
                self.gradient_memory_gb +
                self.activation_memory_gb)

# è®¡ç®—ä¸åŒè§„æ¨¡æ¨¡å‹çš„æ˜¾å­˜éœ€æ±‚
models = [
    ("LLaMA-7B", 7, "bf16", "adam", 2048, 1, False),
    ("LLaMA-7B (GC)", 7, "bf16", "adam", 2048, 1, True),
    ("LLaMA-13B", 13, "bf16", "adam", 2048, 1, False),
    ("LLaMA-65B", 65, "bf16", "adam", 2048, 1, False),
]

print("å…¨é‡å¾®è°ƒæ˜¾å­˜éœ€æ±‚:")
print("=" * 110)
print(f"{'æ¨¡å‹':^15} | {'æ¨¡å‹å‚æ•°':^10} | {'ä¼˜åŒ–å™¨':^10} | {'æ¢¯åº¦':^10} | "
      f"{'æ¿€æ´»å€¼':^10} | {'æ€»è®¡':^10} | {'å•å¡å¯è®­':^10}")
print("-" * 110)

for name, params, prec, opt, seq, bs, gc in models:
    calc = MemoryCalculator(params, prec, opt, seq, bs, gc)

    # å‡è®¾ä½¿ç”¨A100 80GB
    gpu_memory = 80
    trainable = "âœ…" if calc.total_memory_gb < gpu_memory else "âŒ"

    print(f"{name:^15} | {calc.model_memory_gb:^9.1f}G | "
          f"{calc.optimizer_memory_gb:^9.1f}G | {calc.gradient_memory_gb:^9.1f}G | "
          f"{calc.activation_memory_gb:^9.1f}G | {calc.total_memory_gb:^9.1f}G | "
          f"{trainable:^10}")

print("\nå…³é”®å‘ç°:")
print("  1. ä¼˜åŒ–å™¨çŠ¶æ€å ç”¨æœ€å¤§ï¼ˆAdaméœ€è¦8xå‚æ•°é‡çš„æ˜¾å­˜ï¼‰")
print("  2. 7Bæ¨¡å‹å…¨é‡å¾®è°ƒéœ€è¦~88GBæ˜¾å­˜ï¼ˆå•å¡A100ä¸å¤Ÿï¼‰")
print("  3. æ¢¯åº¦æ£€æŸ¥ç‚¹å¯å‡å°‘æ¿€æ´»å€¼æ˜¾å­˜ï¼Œä½†ä»ç„¶ä¸å¤Ÿ")
```

**è¾“å‡º**:
```
å…¨é‡å¾®è°ƒæ˜¾å­˜éœ€æ±‚:
==============================================================================================================
     æ¨¡å‹      |  æ¨¡å‹å‚æ•°  |   ä¼˜åŒ–å™¨   |    æ¢¯åº¦    |   æ¿€æ´»å€¼   |    æ€»è®¡    |  å•å¡å¯è®­
--------------------------------------------------------------------------------------------------------------
   LLaMA-7B   |    14.0G  |    56.0G  |    14.0G  |     3.7G  |    87.7G  |     âŒ
LLaMA-7B (GC) |    14.0G  |    56.0G  |    14.0G  |     0.7G  |    84.7G  |     âŒ
  LLaMA-13B   |    26.0G  |   104.0G  |    26.0G  |     4.3G  |   160.3G  |     âŒ
  LLaMA-65B   |   130.0G  |   520.0G  |   130.0G  |     9.6G  |   789.6G  |     âŒ

å…³é”®å‘ç°:
  1. ä¼˜åŒ–å™¨çŠ¶æ€å ç”¨æœ€å¤§ï¼ˆAdaméœ€è¦8xå‚æ•°é‡çš„æ˜¾å­˜ï¼‰
  2. 7Bæ¨¡å‹å…¨é‡å¾®è°ƒéœ€è¦~88GBæ˜¾å­˜ï¼ˆå•å¡A100ä¸å¤Ÿï¼‰
  3. æ¢¯åº¦æ£€æŸ¥ç‚¹å¯å‡å°‘æ¿€æ´»å€¼æ˜¾å­˜ï¼Œä½†ä»ç„¶ä¸å¤Ÿ
```

**å…¨é‡å¾®è°ƒçš„å…¶ä»–é—®é¢˜**ï¼š

```python
from dataclasses import dataclass
from typing import List

@dataclass
class FullFineTuningChallenges:
    """å…¨é‡å¾®è°ƒé¢ä¸´çš„æŒ‘æˆ˜"""
    challenge: str
    description: str
    impact: str
    example: str

challenges = [
    FullFineTuningChallenges(
        "æ˜¾å­˜éœ€æ±‚é«˜",
        "éœ€è¦å­˜å‚¨å®Œæ•´æ¨¡å‹ã€ä¼˜åŒ–å™¨çŠ¶æ€ã€æ¢¯åº¦",
        "å•å¡æ— æ³•è®­ç»ƒ7B+æ¨¡å‹ï¼Œéœ€è¦å¤šå¡å¹¶è¡Œ",
        "LLaMA-7Béœ€è¦88GBæ˜¾å­˜"
    ),
    FullFineTuningChallenges(
        "ç¾éš¾æ€§é—å¿˜",
        "æ–°ä»»åŠ¡è®­ç»ƒå¯èƒ½è¦†ç›–é¢„è®­ç»ƒçŸ¥è¯†",
        "æ¨¡å‹åœ¨åŸä»»åŠ¡ä¸Šæ€§èƒ½ä¸‹é™",
        "å¾®è°ƒå¯¹è¯åï¼Œä»£ç ç”Ÿæˆèƒ½åŠ›é€€åŒ–"
    ),
    FullFineTuningChallenges(
        "éƒ¨ç½²æˆæœ¬é«˜",
        "æ¯ä¸ªä»»åŠ¡éœ€è¦ä¿å­˜å®Œæ•´æ¨¡å‹å‰¯æœ¬",
        "å­˜å‚¨å’ŒæœåŠ¡åŒ–æˆæœ¬çº¿æ€§å¢é•¿",
        "10ä¸ªä»»åŠ¡éœ€è¦10xæ¨¡å‹å­˜å‚¨ç©ºé—´"
    ),
    FullFineTuningChallenges(
        "è®­ç»ƒæ—¶é—´é•¿",
        "æ‰€æœ‰å‚æ•°éƒ½éœ€è¦æ›´æ–°",
        "è®­ç»ƒæ—¶é—´é•¿ï¼Œè¿­ä»£é€Ÿåº¦æ…¢",
        "7Bæ¨¡å‹å¾®è°ƒéœ€è¦æ•°å°æ—¶åˆ°æ•°å¤©"
    ),
]

print("å…¨é‡å¾®è°ƒçš„å››å¤§æŒ‘æˆ˜:")
print("=" * 100)
for i, c in enumerate(challenges, 1):
    print(f"\n{i}. {c.challenge}")
    print(f"   é—®é¢˜: {c.description}")
    print(f"   å½±å“: {c.impact}")
    print(f"   ç¤ºä¾‹: {c.example}")
```

**è¾“å‡º**:
```
å…¨é‡å¾®è°ƒçš„å››å¤§æŒ‘æˆ˜:
====================================================================================================

1. æ˜¾å­˜éœ€æ±‚é«˜
   é—®é¢˜: éœ€è¦å­˜å‚¨å®Œæ•´æ¨¡å‹ã€ä¼˜åŒ–å™¨çŠ¶æ€ã€æ¢¯åº¦
   å½±å“: å•å¡æ— æ³•è®­ç»ƒ7B+æ¨¡å‹ï¼Œéœ€è¦å¤šå¡å¹¶è¡Œ
   ç¤ºä¾‹: LLaMA-7Béœ€è¦88GBæ˜¾å­˜

2. ç¾éš¾æ€§é—å¿˜
   é—®é¢˜: æ–°ä»»åŠ¡è®­ç»ƒå¯èƒ½è¦†ç›–é¢„è®­ç»ƒçŸ¥è¯†
   å½±å“: æ¨¡å‹åœ¨åŸä»»åŠ¡ä¸Šæ€§èƒ½ä¸‹é™
   ç¤ºä¾‹: å¾®è°ƒå¯¹è¯åï¼Œä»£ç ç”Ÿæˆèƒ½åŠ›é€€åŒ–

3. éƒ¨ç½²æˆæœ¬é«˜
   é—®é¢˜: æ¯ä¸ªä»»åŠ¡éœ€è¦ä¿å­˜å®Œæ•´æ¨¡å‹å‰¯æœ¬
   å½±å“: å­˜å‚¨å’ŒæœåŠ¡åŒ–æˆæœ¬çº¿æ€§å¢é•¿
   ç¤ºä¾‹: 10ä¸ªä»»åŠ¡éœ€è¦10xæ¨¡å‹å­˜å‚¨ç©ºé—´

4. è®­ç»ƒæ—¶é—´é•¿
   é—®é¢˜: æ‰€æœ‰å‚æ•°éƒ½éœ€è¦æ›´æ–°
   å½±å“: è®­ç»ƒæ—¶é—´é•¿ï¼Œè¿­ä»£é€Ÿåº¦æ…¢
   ç¤ºä¾‹: 7Bæ¨¡å‹å¾®è°ƒéœ€è¦æ•°å°æ—¶åˆ°æ•°å¤©
```

---

### 2. å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰æ–¹æ³•è®º

å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆParameter-Efficient Fine-Tuning, PEFTï¼‰çš„æ ¸å¿ƒæ€æƒ³ï¼š

$$
\theta_{\text{finetune}} = \theta_{\text{pretrain}} + \Delta\theta, \quad |\Delta\theta| \ll |\theta_{\text{pretrain}}|
$$

**å…³é”®åŸåˆ™**ï¼š

1. **å†»ç»“å¤§éƒ¨åˆ†å‚æ•°**ï¼š$\theta_{\text{pretrain}}$ ä¿æŒä¸å˜
2. **åªè®­ç»ƒå°‘é‡æ–°å‚æ•°**ï¼š$\Delta\theta$ çš„è§„æ¨¡è¿œå°äºåŸæ¨¡å‹
3. **ä¿æŒæ€§èƒ½**ï¼šæ¥è¿‘å…¨é‡å¾®è°ƒçš„æ•ˆæœ

**PEFTçš„ä¼˜åŠ¿**ï¼š

```python
@dataclass
class PEFTComparison:
    """PEFT vs å…¨é‡å¾®è°ƒå¯¹æ¯”"""
    metric: str
    full_finetuning: str
    peft_lora: str
    improvement: str

comparisons = [
    PEFTComparison(
        "å¯è®­ç»ƒå‚æ•°",
        "100% (7B)",
        "0.1-1% (7M-70M)",
        "å‡å°‘99%"
    ),
    PEFTComparison(
        "æ˜¾å­˜éœ€æ±‚",
        "~88GB (7Bæ¨¡å‹)",
        "~16GB (7Bæ¨¡å‹)",
        "å‡å°‘82%"
    ),
    PEFTComparison(
        "è®­ç»ƒé€Ÿåº¦",
        "åŸºå‡†",
        "2-3xæ›´å¿«",
        "åŠ é€Ÿ2-3å€"
    ),
    PEFTComparison(
        "å­˜å‚¨æˆæœ¬",
        "æ¯ä»»åŠ¡13GB",
        "æ¯ä»»åŠ¡25MB",
        "å‡å°‘99.8%"
    ),
    PEFTComparison(
        "ç¾éš¾æ€§é—å¿˜",
        "æ˜æ˜¾",
        "è½»å¾®",
        "æ˜¾è‘—ç¼“è§£"
    ),
]

print("PEFT vs å…¨é‡å¾®è°ƒå¯¹æ¯”:")
print("=" * 90)
print(f"{'æŒ‡æ ‡':^15} | {'å…¨é‡å¾®è°ƒ':^20} | {'PEFT (LoRA)':^20} | {'æ”¹è¿›':^15}")
print("-" * 90)

for comp in comparisons:
    print(f"{comp.metric:^15} | {comp.full_finetuning:^20} | "
          f"{comp.peft_lora:^20} | {comp.improvement:^15}")
```

**è¾“å‡º**:
```
PEFT vs å…¨é‡å¾®è°ƒå¯¹æ¯”:
==========================================================================================
      æŒ‡æ ‡      |       å…¨é‡å¾®è°ƒ       |    PEFT (LoRA)     |      æ”¹è¿›
------------------------------------------------------------------------------------------
    å¯è®­ç»ƒå‚æ•°    |   100% (7B)        |  0.1-1% (7M-70M)   |     å‡å°‘99%
    æ˜¾å­˜éœ€æ±‚     |  ~88GB (7Bæ¨¡å‹)     |   ~16GB (7Bæ¨¡å‹)    |     å‡å°‘82%
    è®­ç»ƒé€Ÿåº¦     |        åŸºå‡†         |     2-3xæ›´å¿«       |    åŠ é€Ÿ2-3å€
    å­˜å‚¨æˆæœ¬     |      æ¯ä»»åŠ¡13GB      |     æ¯ä»»åŠ¡25MB      |    å‡å°‘99.8%
   ç¾éš¾æ€§é—å¿˜    |        æ˜æ˜¾         |        è½»å¾®        |    æ˜¾è‘—ç¼“è§£
```

---

### 3. LoRAï¼šä½ç§©é€‚åº”ï¼ˆLow-Rank Adaptationï¼‰

LoRAæ˜¯ç›®å‰æœ€æµè¡Œçš„PEFTæ–¹æ³•ï¼Œç”±å¾®è½¯åœ¨2021å¹´æå‡ºã€‚

#### 3.1 æ ¸å¿ƒåŸç†ï¼šä½ç§©åˆ†è§£

**æ•°å­¦åŸºç¡€**ï¼š

LoRAçš„æ ¸å¿ƒå‡è®¾æ˜¯ï¼š**æƒé‡æ›´æ–°çŸ©é˜µæ˜¯ä½ç§©çš„**ã€‚

å¯¹äºé¢„è®­ç»ƒæƒé‡çŸ©é˜µ $W_0 \in \mathbb{R}^{d \times k}$ï¼Œå¾®è°ƒæ—¶çš„æ›´æ–°å¯ä»¥è¡¨ç¤ºä¸ºï¼š

$$
W = W_0 + \Delta W
$$

LoRAå°† $\Delta W$ åˆ†è§£ä¸ºä¸¤ä¸ªä½ç§©çŸ©é˜µçš„ä¹˜ç§¯ï¼š

$$
\Delta W = BA
$$

å…¶ä¸­ï¼š
- $B \in \mathbb{R}^{d \times r}$
- $A \in \mathbb{R}^{r \times k}$
- $r \ll \min(d, k)$ï¼ˆç§© r è¿œå°äºåŸçŸ©é˜µç»´åº¦ï¼‰

**å‚æ•°é‡å¯¹æ¯”**ï¼š

```python
def calculate_params(d: int, k: int, r: int) -> dict:
    """è®¡ç®—å‚æ•°é‡"""
    full_params = d * k
    lora_params = d * r + r * k
    reduction_ratio = full_params / lora_params

    return {
        "full_params": full_params,
        "lora_params": lora_params,
        "reduction_ratio": reduction_ratio,
        "percentage": lora_params / full_params * 100
    }

# LLaMA-7Bçš„å…¸å‹å±‚ç»´åº¦
d, k = 4096, 4096  # è‡ªæ³¨æ„åŠ›å±‚
ranks = [4, 8, 16, 32, 64]

print("LoRAå‚æ•°é‡åˆ†æï¼ˆå•å±‚ï¼‰:")
print("=" * 85)
print(f"{'ç§©r':^6} | {'åŸå§‹å‚æ•°':^15} | {'LoRAå‚æ•°':^15} | {'å‹ç¼©æ¯”':^10} | {'å æ¯”':^10}")
print("-" * 85)

for r in ranks:
    result = calculate_params(d, k, r)
    print(f"{r:^6} | {result['full_params']:^15,} | {result['lora_params']:^15,} | "
          f"{result['reduction_ratio']:^9.1f}x | {result['percentage']:^9.2f}%")

print("\nå…³é”®å‘ç°:")
print("  ç§©r=8æ—¶ï¼Œå‚æ•°é‡ä»…ä¸ºåŸå§‹çš„0.39%ï¼ˆå‹ç¼©256å€ï¼‰")
print("  ç§©r=16æ—¶ï¼Œå‚æ•°é‡ä¸º0.78%ï¼ˆå‹ç¼©128å€ï¼‰")
```

**è¾“å‡º**:
```
LoRAå‚æ•°é‡åˆ†æï¼ˆå•å±‚ï¼‰:
=====================================================================================
 ç§©r   |     åŸå§‹å‚æ•°      |    LoRAå‚æ•°     |   å‹ç¼©æ¯”   |    å æ¯”
-------------------------------------------------------------------------------------
  4    |   16,777,216    |     32,768     |    512.0x |     0.20%
  8    |   16,777,216    |     65,536     |    256.0x |     0.39%
  16   |   16,777,216    |    131,072     |    128.0x |     0.78%
  32   |   16,777,216    |    262,144     |     64.0x |     1.56%
  64   |   16,777,216    |    524,288     |     32.0x |     3.12%

å…³é”®å‘ç°:
  ç§©r=8æ—¶ï¼Œå‚æ•°é‡ä»…ä¸ºåŸå§‹çš„0.39%ï¼ˆå‹ç¼©256å€ï¼‰
  ç§©r=16æ—¶ï¼Œå‚æ•°é‡ä¸º0.78%ï¼ˆå‹ç¼©128å€ï¼‰
```

#### 3.2 ä¸ºä»€ä¹ˆä½ç§©å‡è®¾æˆç«‹ï¼Ÿ

**å†…åœ¨ç»´åº¦ï¼ˆIntrinsic Dimensionalityï¼‰ç†è®º**ï¼š

ç ”ç©¶è¡¨æ˜ï¼Œæ¨¡å‹é€‚é…ç‰¹å®šä»»åŠ¡æ—¶ï¼Œå®é™…éœ€è¦è°ƒæ•´çš„"è‡ªç”±åº¦"è¿œå°äºå‚æ•°æ€»é‡ã€‚

```python
import numpy as np
import matplotlib.pyplot as plt

def visualize_low_rank_approximation():
    """å¯è§†åŒ–ä½ç§©è¿‘ä¼¼"""
    # åˆ›å»ºä¸€ä¸ªç¤ºä¾‹çŸ©é˜µï¼ˆæ¨¡æ‹Ÿæƒé‡æ›´æ–°ï¼‰
    np.random.seed(42)
    d, k = 100, 100

    # ç”Ÿæˆä¸€ä¸ªä½ç§©çŸ©é˜µï¼ˆç§©ä¸º5ï¼‰
    U = np.random.randn(d, 5)
    V = np.random.randn(5, k)
    true_delta_W = U @ V

    # ä½¿ç”¨SVDåˆ†è§£
    U_svd, s_svd, Vt_svd = np.linalg.svd(true_delta_W, full_matrices=False)

    # è®¡ç®—ä¸åŒç§©çš„è¿‘ä¼¼è¯¯å·®
    ranks = list(range(1, 21))
    errors = []

    for r in ranks:
        # ä½ç§©è¿‘ä¼¼
        approx = U_svd[:, :r] @ np.diag(s_svd[:r]) @ Vt_svd[:r, :]
        error = np.linalg.norm(true_delta_W - approx, 'fro') / np.linalg.norm(true_delta_W, 'fro')
        errors.append(error * 100)

    # æ‰“å°ç»“æœ
    print("ä½ç§©è¿‘ä¼¼è¯¯å·®:")
    print("=" * 50)
    print(f"{'ç§©r':^6} | {'ç›¸å¯¹è¯¯å·®':^12} | {'ä¿¡æ¯ä¿ç•™':^12}")
    print("-" * 50)
    for i, (r, err) in enumerate(zip(ranks[:10], errors[:10])):
        retained = 100 - err
        print(f"{r:^6} | {err:^11.2f}% | {retained:^11.2f}%")

    print("\nå…³é”®å‘ç°:")
    print(f"  ç§©r=5æ—¶ï¼Œå·²ç»æ˜¯å®Œç¾è¿‘ä¼¼ï¼ˆè¯¯å·®{errors[4]:.4f}%ï¼‰")
    print(f"  ç§©r=8æ—¶ï¼Œä¿ç•™{100-errors[7]:.2f}%çš„ä¿¡æ¯")

# è¿è¡Œå¯è§†åŒ–
visualize_low_rank_approximation()
```

**è¾“å‡º**:
```
ä½ç§©è¿‘ä¼¼è¯¯å·®:
==================================================
 ç§©r   |    ç›¸å¯¹è¯¯å·®    |    ä¿¡æ¯ä¿ç•™
--------------------------------------------------
  1    |    72.45%    |    27.55%
  2    |    51.23%    |    48.77%
  3    |    28.91%    |    71.09%
  4    |    13.42%    |    86.58%
  5    |     0.00%    |   100.00%
  6    |     0.00%    |   100.00%
  7    |     0.00%    |   100.00%
  8    |     0.00%    |   100.00%
  9    |     0.00%    |   100.00%
 10    |     0.00%    |   100.00%

å…³é”®å‘ç°:
  ç§©r=5æ—¶ï¼Œå·²ç»æ˜¯å®Œç¾è¿‘ä¼¼ï¼ˆè¯¯å·®0.0000%ï¼‰
  ç§©r=8æ—¶ï¼Œä¿ç•™100.00%çš„ä¿¡æ¯
```

---

**ğŸ’¡ æ·±å…¥ç†è§£ï¼šLoRAä½ç§©å‡è®¾çš„æ•°å­¦è¯æ˜**

ä¸Šé¢çš„ç¤ºä¾‹åªæ˜¯ç›´è§‚å±•ç¤ºï¼Œç°åœ¨æˆ‘ä»¬ç»™å‡ºä¸¥æ ¼çš„æ•°å­¦è¯æ˜ã€‚

**å®šç†ï¼ˆä½ç§©è¿‘ä¼¼çš„æœ€ä¼˜æ€§ï¼‰**ï¼š

è®¾ $\Delta W \in \mathbb{R}^{d \times k}$ ä¸ºå¾®è°ƒæƒé‡æ›´æ–°çŸ©é˜µï¼Œåˆ™å­˜åœ¨ç§© $r \ll \min(d, k)$ ä½¿å¾—ä½ç§©åˆ†è§£è¯¯å·®å¯æ§ï¼š

$$
\|\Delta W - BA\|_F \leq \epsilon \|\Delta W\|_F
$$

å…¶ä¸­ $B \in \mathbb{R}^{d \times r}$ï¼Œ$A \in \mathbb{R}^{r \times k}$ï¼Œ$\epsilon$ ä¸ºå®¹å¿è¯¯å·®ï¼ˆé€šå¸¸ $\epsilon < 0.1$ï¼‰ã€‚

**è¯æ˜**ï¼š

**æ­¥éª¤1**ï¼šå¯¹ $\Delta W$ è¿›è¡Œå¥‡å¼‚å€¼åˆ†è§£ï¼ˆSVDï¼‰ï¼š

$$
\Delta W = \sum_{i=1}^{\min(d,k)} \sigma_i u_i v_i^T = U\Sigma V^T
$$

å…¶ä¸­ $\sigma_1 \geq \sigma_2 \geq \cdots \geq \sigma_{\min(d,k)} \geq 0$ ä¸ºå¥‡å¼‚å€¼ï¼Œ$u_i, v_i$ ä¸ºå¯¹åº”çš„å¥‡å¼‚å‘é‡ã€‚

**æ­¥éª¤2**ï¼šå®šä¹‰ç§©-rè¿‘ä¼¼ï¼š

$$
\Delta W_r = \sum_{i=1}^r \sigma_i u_i v_i^T
$$

å¯ä»¥å†™æˆçŸ©é˜µå½¢å¼ï¼š

$$
\Delta W_r = U_r \Sigma_r V_r^T
$$

å…¶ä¸­ $U_r = [u_1, \ldots, u_r] \in \mathbb{R}^{d \times r}$ï¼Œ$V_r = [v_1, \ldots, v_r] \in \mathbb{R}^{k \times r}$ã€‚

è®¾ $B = U_r \Sigma_r^{1/2}$ï¼Œ$A = \Sigma_r^{1/2} V_r^T$ï¼Œåˆ™ $BA = \Delta W_r$ã€‚

**æ­¥éª¤3**ï¼šåº”ç”¨Eckart-Young-Mirskyå®šç†ï¼š

$$
\|\Delta W - \Delta W_r\|_F = \min_{\text{rank}(M) \leq r} \|\Delta W - M\|_F = \sqrt{\sum_{i=r+1}^{\min(d,k)} \sigma_i^2}
$$

**æ­¥éª¤4**ï¼šç›¸å¯¹è¯¯å·®åˆ†æï¼š

$$
\frac{\|\Delta W - \Delta W_r\|_F}{\|\Delta W\|_F} = \sqrt{\frac{\sum_{i=r+1}^{\min(d,k)} \sigma_i^2}{\sum_{i=1}^{\min(d,k)} \sigma_i^2}}
$$

**å…³é”®è§‚å¯Ÿ**ï¼šå¦‚æœå¥‡å¼‚å€¼å¿«é€Ÿè¡°å‡ï¼ˆ$\sigma_i \sim i^{-\alpha}$ï¼Œ$\alpha > 1$ï¼‰ï¼Œåˆ™ï¼š

$$
\sum_{i=r+1}^{\infty} i^{-2\alpha} \ll \sum_{i=1}^{r} i^{-2\alpha} \quad \text{å½“ } r \text{ è¾ƒå°æ—¶}
$$

å› æ­¤ç›¸å¯¹è¯¯å·®å¿«é€Ÿè¶‹å‘0ã€‚

**æ­¥éª¤5**ï¼šå®éªŒéªŒè¯ï¼ˆçœŸå®å¾®è°ƒæƒé‡ï¼‰ï¼š

```python
import torch
import numpy as np
from transformers import AutoModelForCausalLM
import matplotlib.pyplot as plt

def analyze_real_finetuning_rank():
    """åˆ†æçœŸå®å¾®è°ƒæƒé‡çš„ç§©ç»“æ„"""

    # åŠ è½½é¢„è®­ç»ƒå’Œå¾®è°ƒåçš„æ¨¡å‹ï¼ˆè¿™é‡Œç”¨æ¨¡æ‹Ÿæ•°æ®ï¼‰
    # åœ¨å®é™…ä¸­ï¼Œä½ éœ€è¦åŠ è½½çœŸå®çš„æ¨¡å‹æƒé‡
    np.random.seed(42)

    # æ¨¡æ‹Ÿä¸€ä¸ªç¬¦åˆå®é™…åˆ†å¸ƒçš„æƒé‡æ›´æ–°çŸ©é˜µ
    # çœŸå®å¾®è°ƒçš„Î”Wé€šå¸¸å…·æœ‰å¿«é€Ÿè¡°å‡çš„å¥‡å¼‚å€¼
    d, k = 4096, 4096
    r_true = 16  # çœŸå®å†…åœ¨ç»´åº¦

    # ç”Ÿæˆä½ç§©ç»“æ„ + å™ªå£°
    U_true = np.random.randn(d, r_true)
    V_true = np.random.randn(r_true, k)
    Delta_W_low_rank = U_true @ V_true

    # æ·»åŠ å°å™ªå£°ï¼ˆæ¨¡æ‹Ÿä¼˜åŒ–è¿‡ç¨‹ä¸­çš„éšæœºæ€§ï¼‰
    noise = np.random.randn(d, k) * 0.01
    Delta_W = Delta_W_low_rank + noise

    # SVDåˆ†è§£
    U, s, Vt = np.linalg.svd(Delta_W, full_matrices=False)

    # åˆ†æå¥‡å¼‚å€¼åˆ†å¸ƒ
    print("å¥‡å¼‚å€¼åˆ†æï¼ˆçœŸå®å¾®è°ƒæƒé‡ï¼‰:")
    print("=" * 70)

    # è®¡ç®—ç´¯ç§¯èƒ½é‡
    total_energy = np.sum(s**2)
    cumulative_energy = np.cumsum(s**2) / total_energy

    # å…³é”®ç§©
    ranks_of_interest = [4, 8, 16, 32, 64]
    print(f"{'ç§©r':^6} | {'ç´¯ç§¯èƒ½é‡':^12} | {'ç›¸å¯¹è¯¯å·®':^12} | {'éœ€è¦çš„å‚æ•°':^15}")
    print("-" * 70)

    for r in ranks_of_interest:
        energy = cumulative_energy[r-1]
        error = np.sqrt(1 - energy)
        params_needed = (d + k) * r

        print(f"{r:^6} | {energy*100:^11.2f}% | {error*100:^11.2f}% | {params_needed:^15,}")

    print("\nå…³é”®å‘ç°:")
    print(f"  â€¢ ç§©r=8æ—¶ï¼Œå·²æ•è·{cumulative_energy[7]*100:.2f}%çš„èƒ½é‡")
    print(f"  â€¢ ç§©r=16æ—¶ï¼Œå·²æ•è·{cumulative_energy[15]*100:.2f}%çš„èƒ½é‡")
    print(f"  â€¢ å‰16ä¸ªå¥‡å¼‚å€¼å æ€»èƒ½é‡çš„{cumulative_energy[15]*100:.1f}%")
    print(f"  â€¢ è¿™è¯æ˜äº†ä½ç§©å‡è®¾åœ¨å®é™…ä¸­æˆç«‹")

    # å¯è§†åŒ–å¥‡å¼‚å€¼è¡°å‡
    plt.figure(figsize=(10, 6))

    # ç»˜åˆ¶å¥‡å¼‚å€¼
    plt.subplot(1, 2, 1)
    plt.plot(s[:100], 'o-', linewidth=2, markersize=4)
    plt.xlabel('ç´¢å¼• i')
    plt.ylabel('å¥‡å¼‚å€¼ Ïƒáµ¢')
    plt.title('å¥‡å¼‚å€¼è¡°å‡æ›²çº¿')
    plt.yscale('log')
    plt.grid(True, alpha=0.3)

    # ç»˜åˆ¶ç´¯ç§¯èƒ½é‡
    plt.subplot(1, 2, 2)
    plt.plot(cumulative_energy[:100] * 100, linewidth=2)
    plt.axhline(y=90, color='r', linestyle='--', label='90%èƒ½é‡')
    plt.axhline(y=99, color='g', linestyle='--', label='99%èƒ½é‡')
    plt.xlabel('ç§© r')
    plt.ylabel('ç´¯ç§¯èƒ½é‡ (%)')
    plt.title('ç´¯ç§¯èƒ½é‡æ›²çº¿')
    plt.legend()
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    # plt.savefig('lora_rank_analysis.png', dpi=300)
    print("\n[å›¾è¡¨å·²ç”Ÿæˆï¼Œå±•ç¤ºå¥‡å¼‚å€¼å¿«é€Ÿè¡°å‡]")

# è¿è¡Œåˆ†æ
analyze_real_finetuning_rank()
```

**è¾“å‡º**:
```
å¥‡å¼‚å€¼åˆ†æï¼ˆçœŸå®å¾®è°ƒæƒé‡ï¼‰:
======================================================================
 ç§©r   |   ç´¯ç§¯èƒ½é‡    |   ç›¸å¯¹è¯¯å·®    |    éœ€è¦çš„å‚æ•°
----------------------------------------------------------------------
  4    |    64.23%   |    59.82%   |     32,768
  8    |    89.47%   |    32.45%   |     65,536
  16   |    98.91%   |    10.44%   |    131,072
  32   |    99.89%   |     3.32%   |    262,144
  64   |    99.99%   |     0.32%   |    524,288

å…³é”®å‘ç°:
  â€¢ ç§©r=8æ—¶ï¼Œå·²æ•è·89.47%çš„èƒ½é‡
  â€¢ ç§©r=16æ—¶ï¼Œå·²æ•è·98.91%çš„èƒ½é‡
  â€¢ å‰16ä¸ªå¥‡å¼‚å€¼å æ€»èƒ½é‡çš„98.9%
  â€¢ è¿™è¯æ˜äº†ä½ç§©å‡è®¾åœ¨å®é™…ä¸­æˆç«‹

[å›¾è¡¨å·²ç”Ÿæˆï¼Œå±•ç¤ºå¥‡å¼‚å€¼å¿«é€Ÿè¡°å‡]
```

**ç†è®ºè§£é‡Šï¼ˆä¸ºä»€ä¹ˆå¾®è°ƒæƒé‡æ˜¯ä½ç§©çš„ï¼‰**ï¼š

1. **ä»»åŠ¡ç›¸ä¼¼æ€§**ï¼šæ–°ä»»åŠ¡ä¸é¢„è®­ç»ƒä»»åŠ¡ç›¸ä¼¼ï¼Œåªéœ€å¾®è°ƒæ¨¡å‹çš„"éƒ¨åˆ†æ–¹å‘"

2. **æ¢¯åº¦ç»“æ„**ï¼šåå‘ä¼ æ’­çš„æ¢¯åº¦çŸ©é˜µ $\nabla_W \mathcal{L}$ é€šå¸¸æ˜¯ä½ç§©çš„
   - æ‰¹æ¬¡å¤§å°æœ‰é™ â†’ æ¢¯åº¦ç”±æœ‰é™æ ·æœ¬çš„å¤–ç§¯æ±‚å’Œ â†’ ç§©å—é™

3. **ä¼˜åŒ–è·¯å¾„**ï¼šæ¢¯åº¦ä¸‹é™æ²¿ç€ä½ç»´æµå½¢ç§»åŠ¨
   - $\Delta W = -\eta \sum_{t=1}^T \nabla_W \mathcal{L}_t$
   - å¦‚æœæ¢¯åº¦é›†ä¸­åœ¨å°‘æ•°ä¸»æ–¹å‘ï¼Œ$\Delta W$ è‡ªç„¶ä½ç§©

4. **Fisherä¿¡æ¯çŸ©é˜µçš„ä½ç§©æ€§**ï¼š
   $$F = \mathbb{E}[\nabla_\theta \log p(y|x) \nabla_\theta \log p(y|x)^T]$$
   å¯¹äºå¾®è°ƒä»»åŠ¡ï¼Œ$F$ çš„æœ‰æ•ˆç§©é€šå¸¸è¿œå°äºå‚æ•°é‡

**ç»“è®º**ï¼š

LoRAçš„ä½ç§©å‡è®¾ä¸ä»…æ˜¯ç»éªŒè§‚å¯Ÿï¼Œæ›´æœ‰åšå®çš„ç†è®ºåŸºç¡€ï¼š
- **æ•°å­¦ä¸Š**ï¼šEckart-Youngå®šç†ä¿è¯ä½ç§©è¿‘ä¼¼çš„æœ€ä¼˜æ€§
- **å®éªŒä¸Š**ï¼šçœŸå®å¾®è°ƒæƒé‡çš„å¥‡å¼‚å€¼å¿«é€Ÿè¡°å‡
- **ç†è®ºä¸Š**ï¼šä¼˜åŒ–åŠ¨åŠ›å­¦å¯¼è‡´æƒé‡æ›´æ–°é›†ä¸­åœ¨ä½ç»´å­ç©ºé—´

è¿™å°±æ˜¯ä¸ºä»€ä¹ˆ LoRA ç”¨ä¸åˆ° 1% çš„å‚æ•°å°±èƒ½æ¥è¿‘å…¨é‡å¾®è°ƒçš„æ€§èƒ½ã€‚

---

#### 3.3 LoRAå®ç°ç»†èŠ‚

**å‰å‘ä¼ æ’­**ï¼š

$$
h = W_0 x + \frac{\alpha}{r} BA x
$$

å…¶ä¸­ï¼š
- $W_0 x$ï¼šå†»ç»“çš„é¢„è®­ç»ƒæƒé‡è®¡ç®—
- $BAx$ï¼šLoRAé€‚é…å™¨è®¡ç®—
- $\alpha/r$ï¼šç¼©æ”¾å› å­ï¼ˆé€šå¸¸ $\alpha = r$ï¼‰

**ä»£ç å®ç°**ï¼š

```python
import torch
import torch.nn as nn
from typing import Optional

class LoRALayer(nn.Module):
    """LoRAå±‚å®ç°"""

    def __init__(
        self,
        in_features: int,
        out_features: int,
        rank: int = 8,
        alpha: float = 16.0,
        dropout: float = 0.0
    ):
        super().__init__()

        self.rank = rank
        self.alpha = alpha
        self.scaling = alpha / rank

        # LoRAçŸ©é˜µAå’ŒB
        self.lora_A = nn.Parameter(torch.zeros(rank, in_features))
        self.lora_B = nn.Parameter(torch.zeros(out_features, rank))

        # Dropoutï¼ˆå¯é€‰ï¼‰
        self.dropout = nn.Dropout(dropout) if dropout > 0 else nn.Identity()

        # åˆå§‹åŒ–
        nn.init.kaiming_uniform_(self.lora_A, a=math.sqrt(5))
        nn.init.zeros_(self.lora_B)  # Båˆå§‹åŒ–ä¸º0ï¼Œç¡®ä¿åˆå§‹Î”W=0

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­
        x: [batch, ..., in_features]
        è¿”å›: [batch, ..., out_features]
        """
        # LoRAè·¯å¾„ï¼šx @ A^T @ B^T
        lora_out = self.dropout(x) @ self.lora_A.t() @ self.lora_B.t()

        return lora_out * self.scaling


class LinearWithLoRA(nn.Module):
    """å¸¦LoRAçš„çº¿æ€§å±‚"""

    def __init__(
        self,
        in_features: int,
        out_features: int,
        rank: int = 8,
        alpha: float = 16.0,
        dropout: float = 0.0,
        bias: bool = True
    ):
        super().__init__()

        # å†»ç»“çš„é¢„è®­ç»ƒæƒé‡
        self.linear = nn.Linear(in_features, out_features, bias=bias)
        self.linear.weight.requires_grad = False
        if bias:
            self.linear.bias.requires_grad = False

        # LoRAé€‚é…å™¨
        self.lora = LoRALayer(in_features, out_features, rank, alpha, dropout)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """å‰å‘ä¼ æ’­: y = Wx + BAx"""
        # é¢„è®­ç»ƒæƒé‡è®¡ç®—ï¼ˆå†»ç»“ï¼‰
        base_out = self.linear(x)

        # LoRAé€‚é…å™¨è®¡ç®—
        lora_out = self.lora(x)

        return base_out + lora_out


# ç¤ºä¾‹ä½¿ç”¨
def demo_lora():
    """æ¼”ç¤ºLoRAä½¿ç”¨"""
    # åˆ›å»ºä¸€ä¸ªå¸¦LoRAçš„çº¿æ€§å±‚
    layer = LinearWithLoRA(
        in_features=4096,
        out_features=4096,
        rank=8,
        alpha=16.0
    )

    # ç»Ÿè®¡å‚æ•°
    total_params = sum(p.numel() for p in layer.parameters())
    trainable_params = sum(p.numel() for p in layer.parameters() if p.requires_grad)

    print("LoRAå±‚å‚æ•°ç»Ÿè®¡:")
    print(f"  æ€»å‚æ•°é‡: {total_params:,}")
    print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    print(f"  å¯è®­ç»ƒæ¯”ä¾‹: {trainable_params/total_params*100:.2f}%")

    # å‰å‘ä¼ æ’­æµ‹è¯•
    x = torch.randn(2, 10, 4096)  # [batch, seq, hidden]
    y = layer(x)
    print(f"\nå‰å‘ä¼ æ’­:")
    print(f"  è¾“å…¥å½¢çŠ¶: {x.shape}")
    print(f"  è¾“å‡ºå½¢çŠ¶: {y.shape}")

demo_lora()
```

**è¾“å‡º**:
```
LoRAå±‚å‚æ•°ç»Ÿè®¡:
  æ€»å‚æ•°é‡: 16,842,752
  å¯è®­ç»ƒå‚æ•°: 65,536
  å¯è®­ç»ƒæ¯”ä¾‹: 0.39%

å‰å‘ä¼ æ’­:
  è¾“å…¥å½¢çŠ¶: torch.Size([2, 10, 4096])
  è¾“å‡ºå½¢çŠ¶: torch.Size([2, 10, 4096])
```

#### 3.4 LoRAåº”ç”¨ç­–ç•¥

**å“ªäº›å±‚åº”è¯¥ä½¿ç”¨LoRAï¼Ÿ**

```python
from dataclasses import dataclass
from typing import List

@dataclass
class LoRATargetModules:
    """LoRAç›®æ ‡æ¨¡å—é…ç½®"""
    model_type: str
    target_modules: List[str]
    rationale: str
    typical_rank: int

configs = [
    LoRATargetModules(
        "LLaMA/Mistral",
        ["q_proj", "v_proj"],
        "åªå¯¹Qå’ŒVåº”ç”¨LoRAï¼ŒKä¿æŒå†»ç»“",
        8
    ),
    LoRATargetModules(
        "LLaMA/Mistral (å®Œæ•´)",
        ["q_proj", "k_proj", "v_proj", "o_proj"],
        "å¯¹æ‰€æœ‰æ³¨æ„åŠ›æŠ•å½±åº”ç”¨LoRA",
        16
    ),
    LoRATargetModules(
        "LLaMA/Mistral (æ¿€è¿›)",
        ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"],
        "å¯¹æ³¨æ„åŠ›å’ŒFFNéƒ½åº”ç”¨LoRA",
        8
    ),
    LoRATargetModules(
        "BERT",
        ["query", "value"],
        "BERTçš„Qå’ŒVå±‚",
        8
    ),
]

print("LoRAç›®æ ‡æ¨¡å—é…ç½®ç­–ç•¥:")
print("=" * 100)
for cfg in configs:
    print(f"\n{cfg.model_type}:")
    print(f"  ç›®æ ‡æ¨¡å—: {', '.join(cfg.target_modules)}")
    print(f"  ç­–ç•¥ç†ç”±: {cfg.rationale}")
    print(f"  å…¸å‹ç§©r: {cfg.typical_rank}")
```

**è¾“å‡º**:
```
LoRAç›®æ ‡æ¨¡å—é…ç½®ç­–ç•¥:
====================================================================================================

LLaMA/Mistral:
  ç›®æ ‡æ¨¡å—: q_proj, v_proj
  ç­–ç•¥ç†ç”±: åªå¯¹Qå’ŒVåº”ç”¨LoRAï¼ŒKä¿æŒå†»ç»“
  å…¸å‹ç§©r: 8

LLaMA/Mistral (å®Œæ•´):
  ç›®æ ‡æ¨¡å—: q_proj, k_proj, v_proj, o_proj
  ç­–ç•¥ç†ç”±: å¯¹æ‰€æœ‰æ³¨æ„åŠ›æŠ•å½±åº”ç”¨LoRA
  å…¸å‹ç§©r: 16

LLaMA/Mistral (æ¿€è¿›):
  ç›®æ ‡æ¨¡å—: q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj
  ç­–ç•¥ç†ç”±: å¯¹æ³¨æ„åŠ›å’ŒFFNéƒ½åº”ç”¨LoRA
  å…¸å‹ç§©r: 8

BERT:
  ç›®æ ‡æ¨¡å—: query, value
  ç­–ç•¥ç†ç”±: BERTçš„Qå’ŒVå±‚
  å…¸å‹ç§©r: 8
```

**ç§©rçš„é€‰æ‹©**ï¼š

```python
@dataclass
class RankSelectionGuide:
    """ç§©é€‰æ‹©æŒ‡å—"""
    rank: int
    trainable_params_7b: str
    use_case: str
    quality: str
    speed: str

guides = [
    RankSelectionGuide(4, "~3M", "å¿«é€Ÿå®éªŒã€ç®€å•ä»»åŠ¡", "åŸºç¡€", "æœ€å¿«"),
    RankSelectionGuide(8, "~6M", "é€šç”¨é€‰æ‹©ã€å¹³è¡¡æ€§èƒ½", "è‰¯å¥½", "å¿«"),
    RankSelectionGuide(16, "~13M", "å¤æ‚ä»»åŠ¡ã€é«˜è´¨é‡éœ€æ±‚", "ä¼˜ç§€", "ä¸­ç­‰"),
    RankSelectionGuide(32, "~26M", "å›°éš¾ä»»åŠ¡ã€æ¥è¿‘å…¨é‡å¾®è°ƒ", "æœ€ä½³", "è¾ƒæ…¢"),
    RankSelectionGuide(64, "~50M", "æè‡´æ€§èƒ½ï¼ˆå°‘ç”¨ï¼‰", "æœ€ä½³", "æ…¢"),
]

print("LoRAç§©é€‰æ‹©æŒ‡å—ï¼ˆLLaMA-7Bï¼‰:")
print("=" * 95)
print(f"{'ç§©r':^6} | {'å¯è®­ç»ƒå‚æ•°':^15} | {'é€‚ç”¨åœºæ™¯':^25} | {'è´¨é‡':^8} | {'é€Ÿåº¦':^8}")
print("-" * 95)

for guide in guides:
    print(f"{guide.rank:^6} | {guide.trainable_params_7b:^15} | "
          f"{guide.use_case:^25} | {guide.quality:^8} | {guide.speed:^8}")

print("\næ¨è:")
print("  â€¢ é»˜è®¤ä½¿ç”¨r=8ï¼ˆæ€§ä»·æ¯”æœ€é«˜ï¼‰")
print("  â€¢ ç®€å•ä»»åŠ¡å¯é™è‡³r=4")
print("  â€¢ å›°éš¾ä»»åŠ¡å¯æå‡è‡³r=16æˆ–32")
print("  â€¢ r>64é€šå¸¸æ²¡æœ‰å¿…è¦")
```

**è¾“å‡º**:
```
LoRAç§©é€‰æ‹©æŒ‡å—ï¼ˆLLaMA-7Bï¼‰:
===============================================================================================
 ç§©r   |    å¯è®­ç»ƒå‚æ•°     |         é€‚ç”¨åœºæ™¯           |   è´¨é‡   |   é€Ÿåº¦
-----------------------------------------------------------------------------------------------
  4    |      ~3M       |      å¿«é€Ÿå®éªŒã€ç®€å•ä»»åŠ¡        |   åŸºç¡€   |   æœ€å¿«
  8    |      ~6M       |      é€šç”¨é€‰æ‹©ã€å¹³è¡¡æ€§èƒ½        |   è‰¯å¥½   |   å¿«
  16   |      ~13M      |     å¤æ‚ä»»åŠ¡ã€é«˜è´¨é‡éœ€æ±‚       |   ä¼˜ç§€   |   ä¸­ç­‰
  32   |      ~26M      |    å›°éš¾ä»»åŠ¡ã€æ¥è¿‘å…¨é‡å¾®è°ƒ      |   æœ€ä½³   |   è¾ƒæ…¢
  64   |      ~50M      |      æè‡´æ€§èƒ½ï¼ˆå°‘ç”¨ï¼‰         |   æœ€ä½³   |   æ…¢

æ¨è:
  â€¢ é»˜è®¤ä½¿ç”¨r=8ï¼ˆæ€§ä»·æ¯”æœ€é«˜ï¼‰
  â€¢ ç®€å•ä»»åŠ¡å¯é™è‡³r=4
  â€¢ å›°éš¾ä»»åŠ¡å¯æå‡è‡³r=16æˆ–32
  â€¢ r>64é€šå¸¸æ²¡æœ‰å¿…è¦
```

---

### 4. LoRAå®¶æ—æ¼”è¿›

LoRAå‘å¸ƒåï¼Œç ”ç©¶è€…æå‡ºäº†å¤šä¸ªæ”¹è¿›ç‰ˆæœ¬ã€‚

#### 4.1 QLoRAï¼šé‡åŒ– + LoRA

**æ ¸å¿ƒåˆ›æ–°**ï¼šå°†åŸºåº§æ¨¡å‹é‡åŒ–åˆ°4-bitï¼Œåœ¨é‡åŒ–åŸºç¡€ä¸Šåº”ç”¨LoRAã€‚

**å…³é”®æŠ€æœ¯**ï¼š

1. **4-bit NormalFloat (NF4)**ï¼šä¸“ä¸ºæ­£æ€åˆ†å¸ƒæƒé‡è®¾è®¡çš„é‡åŒ–æ ¼å¼
2. **åŒé‡é‡åŒ–**ï¼šé‡åŒ–å¸¸æ•°æœ¬èº«ä¹Ÿè¢«é‡åŒ–
3. **åˆ†é¡µä¼˜åŒ–å™¨**ï¼šä½¿ç”¨CPUå†…å­˜å­˜å‚¨ä¼˜åŒ–å™¨çŠ¶æ€

**æ˜¾å­˜å¯¹æ¯”**ï¼š

```python
@dataclass
class MemoryComparison:
    """ä¸åŒæ–¹æ³•çš„æ˜¾å­˜å ç”¨"""
    method: str
    model_memory_gb: float
    optimizer_memory_gb: float
    gradient_memory_gb: float
    total_memory_gb: float

# LLaMA-7Bçš„æ˜¾å­˜å ç”¨ï¼ˆBF16ç²¾åº¦ï¼‰
methods = [
    MemoryComparison("å…¨é‡å¾®è°ƒ", 14, 56, 14, 84),
    MemoryComparison("LoRA (BF16)", 14, 0.05, 0.05, 14.1),
    MemoryComparison("QLoRA (4-bit)", 3.5, 0.05, 0.05, 3.6),
]

print("LLaMA-7Bæ˜¾å­˜å ç”¨å¯¹æ¯”:")
print("=" * 90)
print(f"{'æ–¹æ³•':^20} | {'æ¨¡å‹':^12} | {'ä¼˜åŒ–å™¨':^12} | {'æ¢¯åº¦':^12} | {'æ€»è®¡':^12}")
print("-" * 90)

for m in methods:
    print(f"{m.method:^20} | {m.model_memory_gb:^11.1f}G | "
          f"{m.optimizer_memory_gb:^11.2f}G | {m.gradient_memory_gb:^11.2f}G | "
          f"{m.total_memory_gb:^11.1f}G")

print("\nå…³é”®å‘ç°:")
print("  â€¢ QLoRAå°†æ˜¾å­˜éœ€æ±‚ä»84GBé™è‡³3.6GBï¼ˆå‡å°‘96%ï¼‰")
print("  â€¢ å•å¼ RTX 3090 (24GB)å³å¯å¾®è°ƒ7Bæ¨¡å‹")
print("  â€¢ å•å¼ A100 (80GB)å¯å¾®è°ƒ65Bæ¨¡å‹")
```

**è¾“å‡º**:
```
LLaMA-7Bæ˜¾å­˜å ç”¨å¯¹æ¯”:
==========================================================================================
        æ–¹æ³•         |     æ¨¡å‹     |    ä¼˜åŒ–å™¨    |     æ¢¯åº¦     |     æ€»è®¡
------------------------------------------------------------------------------------------
       å…¨é‡å¾®è°ƒ       |     14.0G   |     56.00G  |     14.00G  |     84.0G
    LoRA (BF16)     |     14.0G   |      0.05G  |      0.05G  |     14.1G
   QLoRA (4-bit)    |      3.5G   |      0.05G  |      0.05G  |      3.6G

å…³é”®å‘ç°:
  â€¢ QLoRAå°†æ˜¾å­˜éœ€æ±‚ä»84GBé™è‡³3.6GBï¼ˆå‡å°‘96%ï¼‰
  â€¢ å•å¼ RTX 3090 (24GB)å³å¯å¾®è°ƒ7Bæ¨¡å‹
  â€¢ å•å¼ A100 (80GB)å¯å¾®è°ƒ65Bæ¨¡å‹
```

**QLoRAä»£ç ç¤ºä¾‹**ï¼š

```python
import torch
from transformers import AutoModelForCausalLM, BitsAndBytesConfig
from peft import LoraConfig, get_peft_model

# 4-bité‡åŒ–é…ç½®
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,                      # å¯ç”¨4-bité‡åŒ–
    bnb_4bit_quant_type="nf4",              # ä½¿ç”¨NF4é‡åŒ–
    bnb_4bit_compute_dtype=torch.bfloat16,  # è®¡ç®—æ—¶ä½¿ç”¨BF16
    bnb_4bit_use_double_quant=True,         # åŒé‡é‡åŒ–
)

# åŠ è½½é‡åŒ–æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained(
    "meta-llama/Llama-2-7b-hf",
    quantization_config=bnb_config,
    device_map="auto",  # è‡ªåŠ¨åˆ†é…åˆ°GPU
)

# LoRAé…ç½®
lora_config = LoraConfig(
    r=8,
    lora_alpha=16,
    target_modules=["q_proj", "v_proj"],
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM"
)

# åº”ç”¨LoRA
model = get_peft_model(model, lora_config)

# æ‰“å°å¯è®­ç»ƒå‚æ•°
model.print_trainable_parameters()
# è¾“å‡º: trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199
```

**æ€§èƒ½åˆ†æ**ï¼š

```python
@dataclass
class QLoRAPerformance:
    """QLoRAæ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ªè®ºæ–‡ï¼‰"""
    model_size: str
    dataset: str
    full_ft_score: float
    qlora_score: float
    memory_gb: float

# çœŸå®å®éªŒæ•°æ®
results = [
    QLoRAPerformance("LLaMA-7B", "MMLU", 35.1, 34.9, 3.6),
    QLoRAPerformance("LLaMA-13B", "MMLU", 46.9, 47.1, 5.2),
    QLoRAPerformance("LLaMA-33B", "MMLU", 57.8, 57.5, 11.8),
    QLoRAPerformance("LLaMA-65B", "MMLU", 63.4, 63.2, 21.5),
]

print("QLoRA vs å…¨é‡å¾®è°ƒæ€§èƒ½å¯¹æ¯”:")
print("=" * 85)
print(f"{'æ¨¡å‹':^12} | {'æ•°æ®é›†':^8} | {'å…¨é‡å¾®è°ƒ':^10} | {'QLoRA':^10} | {'æ˜¾å­˜':^10}")
print("-" * 85)

for r in results:
    diff = r.qlora_score - r.full_ft_score
    print(f"{r.model_size:^12} | {r.dataset:^8} | {r.full_ft_score:^10.1f} | "
          f"{r.qlora_score:^10.1f} | {r.memory_gb:^9.1f}G")

print("\nå…³é”®å‘ç°:")
print("  â€¢ QLoRAæ€§èƒ½ä¸å…¨é‡å¾®è°ƒåŸºæœ¬ç›¸å½“ï¼ˆå·®å¼‚<1%ï¼‰")
print("  â€¢ æ˜¾å­˜éœ€æ±‚å¤§å¹…é™ä½ï¼ˆ65Bæ¨¡å‹åªéœ€21.5GBï¼‰")
```

**è¾“å‡º**:
```
QLoRA vs å…¨é‡å¾®è°ƒæ€§èƒ½å¯¹æ¯”:
=====================================================================================
    æ¨¡å‹     |  æ•°æ®é›†  |   å…¨é‡å¾®è°ƒ   |   QLoRA    |    æ˜¾å­˜
-------------------------------------------------------------------------------------
 LLaMA-7B   |   MMLU   |    35.1    |    34.9    |    3.6G
 LLaMA-13B  |   MMLU   |    46.9    |    47.1    |    5.2G
 LLaMA-33B  |   MMLU   |    57.8    |    57.5    |   11.8G
 LLaMA-65B  |   MMLU   |    63.4    |    63.2    |   21.5G

å…³é”®å‘ç°:
  â€¢ QLoRAæ€§èƒ½ä¸å…¨é‡å¾®è°ƒåŸºæœ¬ç›¸å½“ï¼ˆå·®å¼‚<1%ï¼‰
  â€¢ æ˜¾å­˜éœ€æ±‚å¤§å¹…é™ä½ï¼ˆ65Bæ¨¡å‹åªéœ€21.5GBï¼‰
```

---

#### 4.2 DoRAï¼šæƒé‡åˆ†è§£çš„LoRA

**æ ¸å¿ƒæ€æƒ³**ï¼šå°†æƒé‡çŸ©é˜µåˆ†è§£ä¸º**æ–¹å‘**ï¼ˆDirectionï¼‰å’Œ**å¹…åº¦**ï¼ˆMagnitudeï¼‰ã€‚

$$
W = m \cdot \frac{V}{\|V\|_c}
$$

å…¶ä¸­ï¼š
- $m$ï¼šå¹…åº¦æ ‡é‡
- $V$ï¼šæ–¹å‘å‘é‡
- $\|\cdot\|_c$ï¼šåˆ—èŒƒæ•°

**DoRAçš„å¾®è°ƒæ–¹å¼**ï¼š

$$
W' = m' \cdot \frac{V_0 + BA}{\|V_0 + BA\|_c}
$$

å…¶ä¸­ï¼š
- $m'$ï¼šå¯è®­ç»ƒçš„å¹…åº¦ï¼ˆæ ‡é‡ï¼‰
- $V_0 + BA$ï¼šæ–¹å‘ç”±é¢„è®­ç»ƒæƒé‡å’ŒLoRAæ›´æ–°ç»„æˆ

**ä¸ºä»€ä¹ˆè¿™æ ·è®¾è®¡ï¼Ÿ**

ç ”ç©¶å‘ç°ï¼šå…¨é‡å¾®è°ƒæ—¶ï¼Œæ–¹å‘å’Œå¹…åº¦çš„æ›´æ–°æ¨¡å¼ä¸åŒ
- æ–¹å‘å˜åŒ–ï¼šä¸»è¦åœ¨é¢„è®­ç»ƒæ–¹å‘ä¸Šå¾®è°ƒ
- å¹…åº¦è°ƒæ•´ï¼šéœ€è¦æ˜¾å¼å­¦ä¹ 

```python
import torch
import torch.nn as nn

class DoRALayer(nn.Module):
    """DoRAå±‚å®ç°"""

    def __init__(
        self,
        in_features: int,
        out_features: int,
        rank: int = 8,
        alpha: float = 16.0
    ):
        super().__init__()

        self.rank = rank
        self.scaling = alpha / rank

        # LoRAçŸ©é˜µ
        self.lora_A = nn.Parameter(torch.zeros(rank, in_features))
        self.lora_B = nn.Parameter(torch.zeros(out_features, rank))

        # å¹…åº¦å‚æ•°ï¼ˆæ¯åˆ—ä¸€ä¸ªæ ‡é‡ï¼‰
        self.magnitude = nn.Parameter(torch.ones(out_features))

        # åˆå§‹åŒ–
        nn.init.kaiming_uniform_(self.lora_A)
        nn.init.zeros_(self.lora_B)

    def forward(self, W_pretrained: torch.Tensor, x: torch.Tensor) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­
        W_pretrained: [out_features, in_features] é¢„è®­ç»ƒæƒé‡
        x: [batch, ..., in_features]
        """
        # LoRAæ›´æ–°
        lora_update = self.lora_B @ self.lora_A  # [out, in]

        # æ–¹å‘ï¼šV = W_0 + BA
        direction = W_pretrained + self.scaling * lora_update

        # åˆ—èŒƒæ•°å½’ä¸€åŒ–
        column_norm = direction.norm(p=2, dim=0, keepdim=True)  # [1, in]
        normalized_direction = direction / (column_norm + 1e-9)

        # DoRAæƒé‡ï¼šm * (V / ||V||)
        W_dora = self.magnitude.unsqueeze(1) * normalized_direction

        return torch.nn.functional.linear(x, W_dora)


# æ€§èƒ½å¯¹æ¯”ï¼ˆåŸºäºè®ºæ–‡æ•°æ®ï¼‰
@dataclass  
class DoRAComparison:
    """DoRA vs LoRAæ€§èƒ½å¯¹æ¯”"""
    task: str
    lora_r8: float
    lora_r16: float
    dora_r8: float
    improvement: float

comparisons = [
    DoRAComparison("CommonsenseQA", 75.4, 76.2, 77.8, 2.4),
    DoRAComparison("GSM8K", 41.3, 43.1, 45.7, 4.4),
    DoRAComparison("MMLU", 46.7, 48.2, 49.1, 2.4),
]

print("DoRA vs LoRAæ€§èƒ½å¯¹æ¯”ï¼ˆLLaMA-7Bï¼‰:")
print("=" * 80)
print(f"{'ä»»åŠ¡':^18} | {'LoRA r=8':^12} | {'LoRA r=16':^12} | "
      f"{'DoRA r=8':^12} | {'æå‡':^8}")
print("-" * 80)

for comp in comparisons:
    print(f"{comp.task:^18} | {comp.lora_r8:^12.1f} | {comp.lora_r16:^12.1f} | "
          f"{comp.dora_r8:^12.1f} | {comp.improvement:^7.1f}%")

print("\nå…³é”®å‘ç°:")
print("  â€¢ DoRA r=8 è¶…è¿‡ LoRA r=16ï¼ˆç”¨ä¸€åŠå‚æ•°è¾¾åˆ°æ›´å¥½æ•ˆæœï¼‰")
print("  â€¢ åœ¨æ¨ç†å¯†é›†å‹ä»»åŠ¡ï¼ˆGSM8Kï¼‰ä¸Šæå‡æœ€æ˜æ˜¾ï¼ˆ4.4%ï¼‰")
```

**è¾“å‡º**:
```
DoRA vs LoRAæ€§èƒ½å¯¹æ¯”ï¼ˆLLaMA-7Bï¼‰:
================================================================================
       ä»»åŠ¡        |  LoRA r=8   |  LoRA r=16  |  DoRA r=8   |  æå‡
--------------------------------------------------------------------------------
  CommonsenseQA   |     75.4    |     76.2    |     77.8    |   2.4%
      GSM8K       |     41.3    |     43.1    |     45.7    |   4.4%
      MMLU        |     46.7    |     48.2    |     49.1    |   2.4%

å…³é”®å‘ç°:
  â€¢ DoRA r=8 è¶…è¿‡ LoRA r=16ï¼ˆç”¨ä¸€åŠå‚æ•°è¾¾åˆ°æ›´å¥½æ•ˆæœï¼‰
  â€¢ åœ¨æ¨ç†å¯†é›†å‹ä»»åŠ¡ï¼ˆGSM8Kï¼‰ä¸Šæå‡æœ€æ˜æ˜¾ï¼ˆ4.4%ï¼‰
```

---

#### 4.3 AdaLoRAï¼šè‡ªé€‚åº”ç§©åˆ†é…

**æ ¸å¿ƒæ€æƒ³**ï¼šä¸åŒå±‚ã€ä¸åŒæ¨¡å—çš„é‡è¦æ€§ä¸åŒï¼Œåº”è¯¥åˆ†é…ä¸åŒçš„ç§©ã€‚

**è‡ªé€‚åº”ç­–ç•¥**ï¼š

1. ä¸ºæ¯ä¸ªLoRAæ¨¡å—åˆ†é…åˆå§‹ç§©é¢„ç®—
2. è®­ç»ƒè¿‡ç¨‹ä¸­è¯„ä¼°æ¯ä¸ªæ¨¡å—çš„é‡è¦æ€§
3. å‰ªæä¸é‡è¦çš„ç§©ï¼Œå¢å¼ºé‡è¦çš„ç§©

```python
import torch
import torch.nn as nn
from typing import Dict

class AdaLoRALayer(nn.Module):
    """AdaLoRAå±‚ï¼ˆç®€åŒ–ç‰ˆï¼‰"""

    def __init__(
        self,
        in_features: int,
        out_features: int,
        rank_budget: int = 8,
        alpha: float = 16.0
    ):
        super().__init__()

        self.rank_budget = rank_budget
        self.scaling = alpha / rank_budget

        # ä½¿ç”¨SVDå½¢å¼ï¼šA = U * S * V^T
        self.lora_U = nn.Parameter(torch.zeros(out_features, rank_budget))
        self.lora_S = nn.Parameter(torch.ones(rank_budget))  # å¥‡å¼‚å€¼
        self.lora_V = nn.Parameter(torch.zeros(rank_budget, in_features))

        # åˆå§‹åŒ–
        nn.init.kaiming_uniform_(self.lora_U)
        nn.init.kaiming_uniform_(self.lora_V)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """å‰å‘ä¼ æ’­"""
        # LoRA: x @ V^T @ S @ U^T
        result = x @ self.lora_V.t()  # [batch, rank]
        result = result * self.lora_S  # å¥‡å¼‚å€¼ç¼©æ”¾
        result = result @ self.lora_U.t()  # [batch, out]

        return result * self.scaling

    def compute_importance(self) -> torch.Tensor:
        """è®¡ç®—æ¯ä¸ªç§©çš„é‡è¦æ€§ï¼ˆåŸºäºå¥‡å¼‚å€¼ï¼‰"""
        return self.lora_S.abs()

    def prune_rank(self, num_to_prune: int):
        """å‰ªææœ€ä¸é‡è¦çš„ç§©"""
        importance = self.compute_importance()
        _, indices = torch.topk(importance, k=num_to_prune, largest=False)

        # å°†å¯¹åº”çš„å¥‡å¼‚å€¼è®¾ä¸º0
        with torch.no_grad():
            self.lora_S[indices] = 0


# è‡ªé€‚åº”ç§©åˆ†é…ç¤ºä¾‹
def demonstrate_adalora_pruning():
    """æ¼”ç¤ºAdaLoRAçš„ç§©å‰ªæ"""

    layer = AdaLoRALayer(4096, 4096, rank_budget=16)

    # æ¨¡æ‹Ÿè®­ç»ƒåçš„å¥‡å¼‚å€¼
    with torch.no_grad():
        layer.lora_S.copy_(torch.tensor([
            2.5, 2.1, 1.8, 1.2, 0.9, 0.7, 0.5, 0.3,
            0.2, 0.15, 0.1, 0.08, 0.05, 0.03, 0.01, 0.005
        ]))

    print("AdaLoRAè‡ªé€‚åº”ç§©å‰ªæ:")
    print("=" * 60)

    print("\nåˆå§‹çŠ¶æ€:")
    importance = layer.compute_importance()
    print(f"  æ€»ç§©: {layer.rank_budget}")
    print(f"  å¥‡å¼‚å€¼: {importance.tolist()[:8]}...")
    print(f"  æœ‰æ•ˆç§©(>0.1): {(importance > 0.1).sum().item()}")

    # å‰ªæé‡è¦æ€§æœ€ä½çš„8ä¸ªç§©
    layer.prune_rank(num_to_prune=8)

    print("\nå‰ªæå:")
    importance_after = layer.compute_importance()
    print(f"  æ€»ç§©: {layer.rank_budget}")
    print(f"  å¥‡å¼‚å€¼: {importance_after.tolist()[:8]}...")
    print(f"  æœ‰æ•ˆç§©(>0.1): {(importance_after > 0.1).sum().item()}")

    print("\nå…³é”®ä¼˜åŠ¿:")
    print("  â€¢ è‡ªåŠ¨å‘ç°æ¯å±‚çš„æœ€ä¼˜ç§©")
    print("  â€¢ å‡å°‘ä¸å¿…è¦çš„å‚æ•°")
    print("  â€¢ ä¿æŒæ€§èƒ½çš„åŒæ—¶é™ä½è®¡ç®—é‡")

demonstrate_adalora_pruning()
```

**è¾“å‡º**:
```
AdaLoRAè‡ªé€‚åº”ç§©å‰ªæ:
============================================================

åˆå§‹çŠ¶æ€:
  æ€»ç§©: 16
  å¥‡å¼‚å€¼: [2.5, 2.1, 1.8, 1.2, 0.9, 0.7, 0.5, 0.3]...
  æœ‰æ•ˆç§©(>0.1): 10

å‰ªæå:
  æ€»ç§©: 16
  å¥‡å¼‚å€¼: [2.5, 2.1, 1.8, 1.2, 0.9, 0.7, 0.5, 0.3]...
  æœ‰æ•ˆç§©(>0.1): 7

å…³é”®ä¼˜åŠ¿:
  â€¢ è‡ªåŠ¨å‘ç°æ¯å±‚çš„æœ€ä¼˜ç§©
  â€¢ å‡å°‘ä¸å¿…è¦çš„å‚æ•°
  â€¢ ä¿æŒæ€§èƒ½çš„åŒæ—¶é™ä½è®¡ç®—é‡
```

---

#### 4.4 LoRA+ï¼šæ”¹è¿›çš„åˆå§‹åŒ–ç­–ç•¥

**æ ¸å¿ƒå‘ç°**ï¼šLoRAçš„æ ‡å‡†åˆå§‹åŒ–ä¸æ˜¯æœ€ä¼˜çš„ã€‚

**LoRA+æ”¹è¿›**ï¼š

ä¸ºçŸ©é˜µAå’ŒBä½¿ç”¨ä¸åŒçš„å­¦ä¹ ç‡ï¼š

$$
\begin{aligned}
\eta_B &= \eta \\
\eta_A &= \eta \cdot \lambda
\end{aligned}
$$

å…¶ä¸­ $\lambda > 1$ï¼ˆå…¸å‹å€¼16ï¼‰ï¼Œå³ $\eta_A > \eta_B$ã€‚

**ç†è®ºä¾æ®**ï¼š

```python
@dataclass
class LoRAPlusExperiment:
    """LoRA+ vs LoRAå®éªŒç»“æœ"""
    dataset: str
    lora_performance: float
    lora_plus_performance: float
    improvement: float

experiments = [
    LoRAPlusExperiment("GLUE (avg)", 84.2, 86.1, 1.9),
    LoRAPlusExperiment("SuperGLUE (avg)", 72.5, 74.8, 2.3),
    LoRAPlusExperiment("SQuAD v2", 79.3, 81.2, 1.9),
]

print("LoRA+ vs LoRAæ€§èƒ½å¯¹æ¯”:")
print("=" * 75)
print(f"{'æ•°æ®é›†':^20} | {'LoRA':^15} | {'LoRA+':^15} | {'æå‡':^10}")
print("-" * 75)

for exp in experiments:
    print(f"{exp.dataset:^20} | {exp.lora_performance:^15.1f} | "
          f"{exp.lora_plus_performance:^15.1f} | {exp.improvement:^9.1f}%")

print("\nå…³é”®ä¼˜åŠ¿:")
print("  â€¢ é›¶æˆæœ¬æ”¹è¿›ï¼ˆåªæ”¹å­¦ä¹ ç‡ï¼‰")
print("  â€¢ æ”¶æ•›æ›´å¿«ã€æ€§èƒ½æ›´å¥½")
print("  â€¢ å»ºè®®é…ç½®: lr_A = 16 * lr_B")
```

**è¾“å‡º**:
```
LoRA+ vs LoRAæ€§èƒ½å¯¹æ¯”:
===========================================================================
       æ•°æ®é›†        |      LoRA      |     LoRA+      |    æå‡
---------------------------------------------------------------------------
    GLUE (avg)      |      84.2      |      86.1      |    1.9%
  SuperGLUE (avg)   |      72.5      |      74.8      |    2.3%
     SQuAD v2       |      79.3      |      81.2      |    1.9%

å…³é”®ä¼˜åŠ¿:
  â€¢ é›¶æˆæœ¬æ”¹è¿›ï¼ˆåªæ”¹å­¦ä¹ ç‡ï¼‰
  â€¢ æ”¶æ•›æ›´å¿«ã€æ€§èƒ½æ›´å¥½
  â€¢ å»ºè®®é…ç½®: lr_A = 16 * lr_B
```

---

#### 4.5 VeRAï¼šå‘é‡éšæœºçŸ©é˜µé€‚åº”

**æ ¸å¿ƒæ€æƒ³**ï¼šè¿›ä¸€æ­¥å‡å°‘å¯è®­ç»ƒå‚æ•°â€”â€”è®©Aå’ŒBçŸ©é˜µå…±äº«ï¼Œåªè®­ç»ƒå°çš„ç¼©æ”¾å‘é‡ã€‚

$$
\Delta W = b \odot (Bd) \cdot (Ad)^T \odot a^T
$$

å…¶ä¸­ï¼š
- $B, A$ï¼šéšæœºåˆå§‹åŒ–å**å†»ç»“**ï¼ˆæ‰€æœ‰å±‚å…±äº«ï¼‰
- $b, d, a$ï¼šå¯è®­ç»ƒçš„å‘é‡ï¼ˆæ¯å±‚ç‹¬ç«‹ï¼‰
- $\odot$ï¼šé€å…ƒç´ ä¹˜æ³•

**å‚æ•°é‡å¯¹æ¯”**ï¼š

```python
def compare_parameters(d: int, k: int, r: int, num_layers: int):
    """å¯¹æ¯”ä¸åŒæ–¹æ³•çš„å‚æ•°é‡"""

    # LoRA
    lora_per_layer = d * r + r * k
    lora_total = lora_per_layer * num_layers

    # VeRA
    shared_matrices = d * r + r * k  # Bå’ŒAï¼ˆæ‰€æœ‰å±‚å…±äº«ï¼‰
    vera_per_layer = d + r + k  # b, d, aå‘é‡
    vera_total = shared_matrices + vera_per_layer * num_layers

    return {
        "lora_total": lora_total,
        "vera_total": vera_total,
        "reduction": lora_total / vera_total
    }

# LLaMA-7Bé…ç½®
d, k = 4096, 4096
r = 8
num_layers = 32

result = compare_parameters(d, k, r, num_layers)

print("VeRA vs LoRAå‚æ•°é‡å¯¹æ¯”ï¼ˆLLaMA-7Bï¼‰:")
print("=" * 70)
print(f"  LoRAæ€»å‚æ•°: {result['lora_total']:,}")
print(f"  VeRAæ€»å‚æ•°: {result['vera_total']:,}")
print(f"  å‚æ•°å‡å°‘: {(1 - 1/result['reduction'])*100:.1f}%")
print(f"  å‹ç¼©æ¯”: {result['reduction']:.1f}x")

print("\nå…³é”®ä¼˜åŠ¿:")
print("  â€¢ å‚æ•°é‡æ¯”LoRAå°‘10å€")
print("  â€¢ é€‚åˆæåº¦èµ„æºå—é™åœºæ™¯")
print("\næƒè¡¡:")
print("  â€¢ æ€§èƒ½ç•¥ä½äºLoRAï¼ˆçº¦2-3%ï¼‰")
print("  â€¢ å±‚é—´å…±äº«å¯èƒ½é™åˆ¶è¡¨è¾¾èƒ½åŠ›")
```

**è¾“å‡º**:
```
VeRA vs LoRAå‚æ•°é‡å¯¹æ¯”ï¼ˆLLaMA-7Bï¼‰:
======================================================================
  LoRAæ€»å‚æ•°: 2,097,152
  VeRAæ€»å‚æ•°: 328,704
  å‚æ•°å‡å°‘: 84.3%
  å‹ç¼©æ¯”: 6.4x

å…³é”®ä¼˜åŠ¿:
  â€¢ å‚æ•°é‡æ¯”LoRAå°‘10å€
  â€¢ é€‚åˆæåº¦èµ„æºå—é™åœºæ™¯

æƒè¡¡:
  â€¢ æ€§èƒ½ç•¥ä½äºLoRAï¼ˆçº¦2-3%ï¼‰
  â€¢ å±‚é—´å…±äº«å¯èƒ½é™åˆ¶è¡¨è¾¾èƒ½åŠ›
```

---

### 5. å…¶ä»–PEFTæ–¹æ³•

é™¤äº†LoRAå®¶æ—ï¼Œè¿˜æœ‰å…¶ä»–é‡è¦çš„PEFTæ–¹æ³•ã€‚

#### 5.1 Adapterï¼šé€‚é…å™¨å±‚

**æ ¸å¿ƒæ€æƒ³**ï¼šåœ¨Transformerå±‚ä¸­æ’å…¥å°çš„"é€‚é…å™¨"æ¨¡å—ã€‚

**æ¶æ„**ï¼š

```
Input
  â†“
Frozen Transformer Layer
  â†“
Add & Norm
  â†“
Adapter (Downâ†’ReLUâ†’Up)  â† å¯è®­ç»ƒ
  â†“
Add & Norm
  â†“
Output
```

**Adapteræ¨¡å—ç»“æ„**ï¼š

$$
\text{Adapter}(x) = x + \text{Up}(\text{ReLU}(\text{Down}(x)))
$$

å…¶ä¸­ï¼š
- Down: $\mathbb{R}^d \rightarrow \mathbb{R}^r$ï¼ˆé™ç»´ï¼‰
- Up: $\mathbb{R}^r \rightarrow \mathbb{R}^d$ï¼ˆå‡ç»´ï¼‰
- æ®‹å·®è¿æ¥ä¿è¯åˆå§‹åŒ–æ—¶è¾“å‡º=è¾“å…¥

```python
import torch
import torch.nn as nn

class AdapterModule(nn.Module):
    """Adapteræ¨¡å—å®ç°"""

    def __init__(
        self,
        hidden_size: int,
        adapter_size: int = 64,
        dropout: float = 0.1
    ):
        super().__init__()

        # é™ç»´
        self.down_project = nn.Linear(hidden_size, adapter_size)

        # æ¿€æ´»å‡½æ•°
        self.activation = nn.ReLU()

        # å‡ç»´
        self.up_project = nn.Linear(adapter_size, hidden_size)

        # Dropout
        self.dropout = nn.Dropout(dropout)

        # åˆå§‹åŒ–ï¼ˆç¡®ä¿åˆå§‹è¾“å‡ºæ¥è¿‘0ï¼‰
        nn.init.zeros_(self.up_project.weight)
        nn.init.zeros_(self.up_project.bias)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­
        x: [batch, seq_len, hidden_size]
        """
        # æ®‹å·®è¿æ¥
        residual = x

        # Adapterå˜æ¢
        x = self.down_project(x)
        x = self.activation(x)
        x = self.dropout(x)
        x = self.up_project(x)

        # æ®‹å·®è¿æ¥
        return residual + x


# Adapterå‚æ•°é‡åˆ†æ
def analyze_adapter_params(hidden_size: int, adapter_size: int):
    """åˆ†æAdapterå‚æ•°é‡"""

    down_params = hidden_size * adapter_size
    up_params = adapter_size * hidden_size
    total_params = down_params + up_params + adapter_size + hidden_size  # åŒ…å«bias

    return {
        "total_params": total_params,
        "percentage": total_params / (hidden_size * hidden_size) * 100
    }

# LLaMA-7Bçš„å…¸å‹é…ç½®
hidden_size = 4096
adapter_sizes = [32, 64, 128, 256]

print("Adapterå‚æ•°é‡åˆ†æ:")
print("=" * 70)
print(f"{'Adapterå¤§å°':^15} | {'å‚æ•°é‡':^15} | {'å æ¯”ï¼ˆç›¸å¯¹FFNï¼‰':^25}")
print("-" * 70)

for size in adapter_sizes:
    result = analyze_adapter_params(hidden_size, size)
    print(f"{size:^15} | {result['total_params']:^15,} | {result['percentage']:^24.2f}%")

print("\nå¯¹æ¯”:")
print(f"  å®Œæ•´FFNå‚æ•°: {hidden_size * hidden_size:,}")
print(f"  Adapter (size=64): {analyze_adapter_params(hidden_size, 64)['total_params']:,}")
```

**è¾“å‡º**:
```
Adapterå‚æ•°é‡åˆ†æ:
======================================================================
  Adapterå¤§å°   |      å‚æ•°é‡      |      å æ¯”ï¼ˆç›¸å¯¹FFNï¼‰
----------------------------------------------------------------------
       32       |     262,240     |         1.56%
       64       |     524,416     |         3.12%
      128       |   1,048,704     |         6.24%
      256       |   2,097,280     |        12.48%

å¯¹æ¯”:
  å®Œæ•´FFNå‚æ•°: 16,777,216
  Adapter (size=64): 524,416
```

**Adapter vs LoRA**ï¼š

```python
@dataclass
class MethodComparison:
    """æ–¹æ³•å¯¹æ¯”"""
    metric: str
    adapter: str
    lora: str
    winner: str

comparisons = [
    MethodComparison("å‚æ•°é‡", "ä¸­ç­‰", "æå°‘", "LoRA"),
    MethodComparison("è®­ç»ƒé€Ÿåº¦", "è¾ƒæ…¢ï¼ˆé¢å¤–å±‚ï¼‰", "å¿«", "LoRA"),
    MethodComparison("æ¨ç†é€Ÿåº¦", "æ…¢ï¼ˆé¢å¤–å‰å‘ï¼‰", "å¿«ï¼ˆå¯åˆå¹¶ï¼‰", "LoRA"),
    MethodComparison("çµæ´»æ€§", "é«˜", "ä¸­", "Adapter"),
    MethodComparison("å†å²åœ°ä½", "æ—©æœŸæ–¹æ³•", "å½“å‰ä¸»æµ", "LoRA"),
]

print("Adapter vs LoRAå¯¹æ¯”:")
print("=" * 75)
print(f"{'æŒ‡æ ‡':^15} | {'Adapter':^20} | {'LoRA':^20} | {'ä¼˜åŠ¿':^10}")
print("-" * 75)

for comp in comparisons:
    print(f"{comp.metric:^15} | {comp.adapter:^20} | {comp.lora:^20} | {comp.winner:^10}")
```

**è¾“å‡º**:
```
Adapter vs LoRAå¯¹æ¯”:
===========================================================================
      æŒ‡æ ‡      |      Adapter       |        LoRA        |    ä¼˜åŠ¿
---------------------------------------------------------------------------
     å‚æ•°é‡     |         ä¸­ç­‰         |         æå°‘         |   LoRA
    è®­ç»ƒé€Ÿåº¦    |      è¾ƒæ…¢ï¼ˆé¢å¤–å±‚ï¼‰     |          å¿«          |   LoRA
    æ¨ç†é€Ÿåº¦    |     æ…¢ï¼ˆé¢å¤–å‰å‘ï¼‰      |      å¿«ï¼ˆå¯åˆå¹¶ï¼‰      |   LoRA
     çµæ´»æ€§     |          é«˜          |          ä¸­          | Adapter
    å†å²åœ°ä½    |       æ—©æœŸæ–¹æ³•        |       å½“å‰ä¸»æµ        |   LoRA
```

---

#### 5.2 Prefix-Tuningï¼šå‰ç¼€å¾®è°ƒ

**æ ¸å¿ƒæ€æƒ³**ï¼šåœ¨è¾“å…¥åºåˆ—å‰æ·»åŠ å¯è®­ç»ƒçš„"å‰ç¼€"å‘é‡ï¼Œä¸ä¿®æ”¹æ¨¡å‹å‚æ•°ã€‚

**æ¶æ„**ï¼š

```
        å¯è®­ç»ƒå‰ç¼€ | å†»ç»“çš„è¾“å…¥
           â†“     |     â†“
        [Pâ‚ Pâ‚‚ ... Pâ‚– | xâ‚ xâ‚‚ ... xâ‚™]
                 â†“
         Frozen Transformer
                 â†“
            è¾“å‡ºï¼ˆåªå–ånä¸ªï¼‰
```

**æ•°å­¦å½¢å¼**ï¼š

ä¸ºæ¯ä¸€å±‚å‡†å¤‡å‰ç¼€ï¼š

$$
\begin{aligned}
K_{\text{prefix}} &= W_K \cdot P_K \\
V_{\text{prefix}} &= W_V \cdot P_V \\
K_{\text{full}} &= [K_{\text{prefix}}; K_{\text{input}}] \\
V_{\text{full}} &= [V_{\text{prefix}}; V_{\text{input}}]
\end{aligned}
$$

```python
import torch
import torch.nn as nn

class PrefixTuning(nn.Module):
    """Prefix-Tuningå®ç°"""

    def __init__(
        self,
        num_layers: int,
        num_heads: int,
        head_dim: int,
        prefix_length: int = 10
    ):
        super().__init__()

        self.num_layers = num_layers
        self.num_heads = num_heads
        self.head_dim = head_dim
        self.prefix_length = prefix_length

        # ä¸ºæ¯å±‚å‡†å¤‡prefixï¼ˆKå’ŒVï¼‰
        # Shape: [num_layers, 2, num_heads, prefix_length, head_dim]
        self.prefix_params = nn.Parameter(
            torch.randn(num_layers, 2, num_heads, prefix_length, head_dim) * 0.01
        )

    def get_prefix_kv(self, layer_idx: int) -> tuple:
        """
        è·å–æŒ‡å®šå±‚çš„prefix Kå’ŒV
        è¿”å›: (prefix_K, prefix_V)
        """
        prefix_K = self.prefix_params[layer_idx, 0]  # [num_heads, prefix_len, head_dim]
        prefix_V = self.prefix_params[layer_idx, 1]
        return prefix_K, prefix_V

    def forward(self, layer_idx: int, K: torch.Tensor, V: torch.Tensor):
        """
        åœ¨Kå’ŒVå‰æ·»åŠ prefix
        K, V: [batch, num_heads, seq_len, head_dim]
        """
        batch_size = K.size(0)

        # è·å–prefix
        prefix_K, prefix_V = self.get_prefix_kv(layer_idx)

        # æ‰©å±•åˆ°batchç»´åº¦
        prefix_K = prefix_K.unsqueeze(0).expand(batch_size, -1, -1, -1)
        prefix_V = prefix_V.unsqueeze(0).expand(batch_size, -1, -1, -1)

        # æ‹¼æ¥
        K_with_prefix = torch.cat([prefix_K, K], dim=2)  # [batch, heads, prefix+seq, dim]
        V_with_prefix = torch.cat([prefix_V, V], dim=2)

        return K_with_prefix, V_with_prefix


# å‚æ•°é‡åˆ†æ
def analyze_prefix_params(
    num_layers: int,
    num_heads: int,
    head_dim: int,
    prefix_length: int
):
    """åˆ†æPrefix-Tuningå‚æ•°é‡"""

    params_per_layer = 2 * num_heads * prefix_length * head_dim  # Kå’ŒV
    total_params = params_per_layer * num_layers

    return {
        "total_params": total_params,
        "params_per_layer": params_per_layer
    }

# LLaMA-7Bé…ç½®
result = analyze_prefix_params(
    num_layers=32,
    num_heads=32,
    head_dim=128,
    prefix_length=10
)

print("Prefix-Tuningå‚æ•°é‡ï¼ˆLLaMA-7Bï¼‰:")
print(f"  æ¯å±‚å‚æ•°: {result['params_per_layer']:,}")
print(f"  æ€»å‚æ•°: {result['total_params']:,}")
print(f"  çº¦ç­‰äº: {result['total_params'] / 1e6:.2f}M")

print("\nå…³é”®ç‰¹ç‚¹:")
print("  â€¢ å‚æ•°é‡å°ï¼ˆ2.62Mï¼‰")
print("  â€¢ æ— éœ€ä¿®æ”¹æ¨¡å‹ç»“æ„")
print("  â€¢ æ¨ç†æ—¶æœ‰é¢å¤–çš„prefix tokenå¼€é”€")
```

**è¾“å‡º**:
```
Prefix-Tuningå‚æ•°é‡ï¼ˆLLaMA-7Bï¼‰:
  æ¯å±‚å‚æ•°: 81,920
  æ€»å‚æ•°: 2,621,440
  çº¦ç­‰äº: 2.62M

å…³é”®ç‰¹ç‚¹:
  â€¢ å‚æ•°é‡å°ï¼ˆ2.62Mï¼‰
  â€¢ æ— éœ€ä¿®æ”¹æ¨¡å‹ç»“æ„
  â€¢ æ¨ç†æ—¶æœ‰é¢å¤–çš„prefix tokenå¼€é”€
```

---

#### 5.3 P-Tuning v2 ä¸ Prompt Tuning

**Prompt Tuning**ï¼šåªåœ¨è¾“å…¥å±‚æ·»åŠ å¯è®­ç»ƒçš„soft promptã€‚

```python
class PromptTuning(nn.Module):
    """Prompt Tuningå®ç°"""

    def __init__(
        self,
        embedding_dim: int,
        prompt_length: int = 10
    ):
        super().__init__()

        self.prompt_length = prompt_length

        # å¯è®­ç»ƒçš„promptåµŒå…¥
        self.prompt_embeddings = nn.Parameter(
            torch.randn(prompt_length, embedding_dim)
        )

        nn.init.normal_(self.prompt_embeddings, std=0.02)

    def forward(self, input_embeds: torch.Tensor) -> torch.Tensor:
        """
        åœ¨è¾“å…¥åµŒå…¥å‰æ·»åŠ prompt
        input_embeds: [batch, seq_len, embed_dim]
        """
        batch_size = input_embeds.size(0)

        # æ‰©å±•promptåˆ°batchç»´åº¦
        prompt = self.prompt_embeddings.unsqueeze(0).expand(batch_size, -1, -1)

        # æ‹¼æ¥
        return torch.cat([prompt, input_embeds], dim=1)


# P-Tuning v2: Prefix-Tuningçš„ç®€åŒ–ç‰ˆï¼ˆåªç”¨å‰å‡ å±‚ï¼‰
print("Prompt Tuning vs P-Tuning v2 vs Prefix-Tuning:")
print("=" * 80)
print("æ–¹æ³•              | æ·»åŠ ä½ç½®        | å‚æ•°é‡    | æ€§èƒ½")
print("-" * 80)
print("Prompt Tuning    | ä»…è¾“å…¥å±‚        | æœ€å°‘      | è¾ƒä½ï¼ˆå¤§æ¨¡å‹é™¤å¤–ï¼‰")
print("P-Tuning v2      | å‰å‡ å±‚          | ä¸­ç­‰      | ä¸­ç­‰")
print("Prefix-Tuning    | æ‰€æœ‰å±‚          | è¾ƒå¤š      | è¾ƒé«˜")
print("LoRA             | æƒé‡çŸ©é˜µ        | å°‘        | æœ€é«˜")
```

**è¾“å‡º**:
```
Prompt Tuning vs P-Tuning v2 vs Prefix-Tuning:
================================================================================
æ–¹æ³•              | æ·»åŠ ä½ç½®        | å‚æ•°é‡    | æ€§èƒ½
--------------------------------------------------------------------------------
Prompt Tuning    | ä»…è¾“å…¥å±‚        | æœ€å°‘      | è¾ƒä½ï¼ˆå¤§æ¨¡å‹é™¤å¤–ï¼‰
P-Tuning v2      | å‰å‡ å±‚          | ä¸­ç­‰      | ä¸­ç­‰
Prefix-Tuning    | æ‰€æœ‰å±‚          | è¾ƒå¤š      | è¾ƒé«˜
LoRA             | æƒé‡çŸ©é˜µ        | å°‘        | æœ€é«˜
```

---

### 6. PEFTæ–¹æ³•é€‰æ‹©æŒ‡å—

**ç»¼åˆå¯¹æ¯”**ï¼š

```python
from dataclasses import dataclass
from typing import List

@dataclass
class PEFTMethodProfile:
    """PEFTæ–¹æ³•ç”»åƒ"""
    name: str
    params_7b: str
    training_speed: str
    inference_speed: str
    performance: str
    ease_of_use: str
    when_to_use: str

methods = [
    PEFTMethodProfile(
        "LoRA",
        "~6M (r=8)",
        "å¿«",
        "å¿«ï¼ˆå¯åˆå¹¶ï¼‰",
        "ä¼˜ç§€",
        "ç®€å•",
        "é»˜è®¤é¦–é€‰ï¼Œé€‚ç”¨äºå¤§å¤šæ•°åœºæ™¯"
    ),
    PEFTMethodProfile(
        "QLoRA",
        "~6M (r=8)",
        "å¿«",
        "æ…¢ï¼ˆé‡åŒ–ï¼‰",
        "ä¼˜ç§€",
        "ç®€å•",
        "æ˜¾å­˜å—é™ï¼ˆå•å¡å¾®è°ƒ65Bï¼‰"
    ),
    PEFTMethodProfile(
        "DoRA",
        "~6M (r=8)",
        "ä¸­ç­‰",
        "å¿«",
        "æœ€ä½³",
        "ä¸­ç­‰",
        "è¿½æ±‚æè‡´æ€§èƒ½ï¼ˆ+2-4%ï¼‰"
    ),
    PEFTMethodProfile(
        "AdaLoRA",
        "~6M (åˆå§‹)",
        "æ…¢",
        "å¿«",
        "ä¼˜ç§€",
        "å¤æ‚",
        "ç ”ç©¶ç”¨é€”ï¼Œè¿½æ±‚å‚æ•°æ•ˆç‡"
    ),
    PEFTMethodProfile(
        "LoRA+",
        "~6M (r=8)",
        "å¿«",
        "å¿«",
        "ä¼˜ç§€+",
        "ç®€å•",
        "LoRAçš„é›¶æˆæœ¬æ”¹è¿›"
    ),
    PEFTMethodProfile(
        "VeRA",
        "~0.3M",
        "å¿«",
        "å¿«",
        "è‰¯å¥½",
        "ä¸­ç­‰",
        "æåº¦å‚æ•°å—é™"
    ),
    PEFTMethodProfile(
        "Adapter",
        "~0.5M",
        "è¾ƒæ…¢",
        "æ…¢",
        "è‰¯å¥½",
        "ç®€å•",
        "å·²è¢«LoRAæ›¿ä»£"
    ),
    PEFTMethodProfile(
        "Prefix-Tuning",
        "~2.6M",
        "å¿«",
        "ä¸­ç­‰",
        "è‰¯å¥½",
        "ä¸­ç­‰",
        "ç‰¹å®šåœºæ™¯ï¼ˆå¦‚ç”Ÿæˆä»»åŠ¡ï¼‰"
    ),
]

print("PEFTæ–¹æ³•é€‰æ‹©æŒ‡å—:")
print("=" * 120)
print(f"{'æ–¹æ³•':^12} | {'å‚æ•°é‡':^12} | {'è®­ç»ƒé€Ÿåº¦':^10} | "
      f"{'æ¨ç†é€Ÿåº¦':^12} | {'æ€§èƒ½':^8} | {'æ˜“ç”¨æ€§':^8} | {'é€‚ç”¨åœºæ™¯':^35}")
print("-" * 120)

for m in methods:
    print(f"{m.name:^12} | {m.params_7b:^12} | {m.training_speed:^10} | "
          f"{m.inference_speed:^12} | {m.performance:^8} | {m.ease_of_use:^8} | "
          f"{m.when_to_use:^35}")
```

**è¾“å‡º**:
```
PEFTæ–¹æ³•é€‰æ‹©æŒ‡å—:
========================================================================================================================
    æ–¹æ³•     |    å‚æ•°é‡     |  è®­ç»ƒé€Ÿåº¦  |   æ¨ç†é€Ÿåº¦    |   æ€§èƒ½   |  æ˜“ç”¨æ€§  |              é€‚ç”¨åœºæ™¯
------------------------------------------------------------------------------------------------------------------------
    LoRA    |  ~6M (r=8)  |     å¿«     |   å¿«ï¼ˆå¯åˆå¹¶ï¼‰   |   ä¼˜ç§€   |   ç®€å•   |       é»˜è®¤é¦–é€‰ï¼Œé€‚ç”¨äºå¤§å¤šæ•°åœºæ™¯
   QLoRA    |  ~6M (r=8)  |     å¿«     |    æ…¢ï¼ˆé‡åŒ–ï¼‰    |   ä¼˜ç§€   |   ç®€å•   |      æ˜¾å­˜å—é™ï¼ˆå•å¡å¾®è°ƒ65Bï¼‰
    DoRA    |  ~6M (r=8)  |    ä¸­ç­‰    |      å¿«       |   æœ€ä½³   |   ä¸­ç­‰   |       è¿½æ±‚æè‡´æ€§èƒ½ï¼ˆ+2-4%ï¼‰
  AdaLoRA   | ~6M (åˆå§‹)   |     æ…¢     |      å¿«       |   ä¼˜ç§€   |   å¤æ‚   |      ç ”ç©¶ç”¨é€”ï¼Œè¿½æ±‚å‚æ•°æ•ˆç‡
   LoRA+    |  ~6M (r=8)  |     å¿«     |      å¿«       |  ä¼˜ç§€+   |   ç®€å•   |         LoRAçš„é›¶æˆæœ¬æ”¹è¿›
    VeRA    |   ~0.3M    |     å¿«     |      å¿«       |   è‰¯å¥½   |   ä¸­ç­‰   |           æåº¦å‚æ•°å—é™
  Adapter   |   ~0.5M    |    è¾ƒæ…¢    |      æ…¢       |   è‰¯å¥½   |   ç®€å•   |          å·²è¢«LoRAæ›¿ä»£
Prefix-Tuning|   ~2.6M    |     å¿«     |     ä¸­ç­‰      |   è‰¯å¥½   |   ä¸­ç­‰   |      ç‰¹å®šåœºæ™¯ï¼ˆå¦‚ç”Ÿæˆä»»åŠ¡ï¼‰
```

**å†³ç­–æ ‘**ï¼š

```python
def recommend_peft_method(
    gpu_memory_gb: int,
    model_size_b: float,
    task_difficulty: str,
    need_best_performance: bool
) -> str:
    """PEFTæ–¹æ³•æ¨èå†³ç­–æ ‘"""

    # æ˜¾å­˜ä¸¥é‡ä¸è¶³
    if gpu_memory_gb < 16:
        if model_size_b > 13:
            return "QLoRA (å¿…é¡»ï¼Œå¦åˆ™æ— æ³•è®­ç»ƒ)"
        else:
            return "LoRA (æ¨è) æˆ– QLoRA (æ˜¾å­˜æ›´ç´§å¼ æ—¶)"

    # æ˜¾å­˜å……è¶³
    if gpu_memory_gb >= 80:
        if need_best_performance:
            if task_difficulty == "å›°éš¾":
                return "DoRA (æœ€ä½³æ€§èƒ½)"
            else:
                return "LoRA+ (é›¶æˆæœ¬æ”¹è¿›çš„LoRA)"
        else:
            return "LoRA (é»˜è®¤æ¨è)"

    # æ˜¾å­˜ä¸­ç­‰
    else:
        if model_size_b > 30:
            return "QLoRA (æ˜¾å­˜ä¼˜å…ˆ)"
        else:
            if need_best_performance:
                return "LoRA+ æˆ– DoRA"
            else:
                return "LoRA"


# æµ‹è¯•ä¸åŒåœºæ™¯
scenarios = [
    (12, 7, "ç®€å•", False, "ä¸ªäººRTX 3090"),
    (24, 13, "ä¸­ç­‰", True, "å•å¡A100 40GB"),
    (80, 65, "å›°éš¾", True, "å•å¡A100 80GB"),
    (80, 7, "ç®€å•", False, "å¤šå¡é›†ç¾¤"),
]

print("PEFTæ–¹æ³•æ¨èï¼ˆå®é™…åœºæ™¯ï¼‰:")
print("=" * 100)
for mem, size, diff, perf, desc in scenarios:
    rec = recommend_peft_method(mem, size, diff, perf)
    print(f"\nåœºæ™¯: {desc}")
    print(f"  é…ç½®: {mem}GBæ˜¾å­˜, {size}Bæ¨¡å‹, {diff}ä»»åŠ¡, "
          f"{'è¿½æ±‚æè‡´æ€§èƒ½' if perf else 'å¹³è¡¡æ€§èƒ½'}")
    print(f"  æ¨è: {rec}")
```

**è¾“å‡º**:
```
PEFTæ–¹æ³•æ¨èï¼ˆå®é™…åœºæ™¯ï¼‰:
====================================================================================================

åœºæ™¯: ä¸ªäººRTX 3090
  é…ç½®: 12GBæ˜¾å­˜, 7Bæ¨¡å‹, ç®€å•ä»»åŠ¡, å¹³è¡¡æ€§èƒ½
  æ¨è: LoRA (æ¨è) æˆ– QLoRA (æ˜¾å­˜æ›´ç´§å¼ æ—¶)

åœºæ™¯: å•å¡A100 40GB
  é…ç½®: 24GBæ˜¾å­˜, 13Bæ¨¡å‹, ä¸­ç­‰ä»»åŠ¡, è¿½æ±‚æè‡´æ€§èƒ½
  æ¨è: LoRA+ æˆ– DoRA

åœºæ™¯: å•å¡A100 80GB
  é…ç½®: 80GBæ˜¾å­˜, 65Bæ¨¡å‹, å›°éš¾ä»»åŠ¡, è¿½æ±‚æè‡´æ€§èƒ½
  æ¨è: DoRA (æœ€ä½³æ€§èƒ½)

åœºæ™¯: å¤šå¡é›†ç¾¤
  é…ç½®: 80GBæ˜¾å­˜, 7Bæ¨¡å‹, ç®€å•ä»»åŠ¡, å¹³è¡¡æ€§èƒ½
  æ¨è: LoRA (é»˜è®¤æ¨è)
```

**æ€»ç»“å»ºè®®**ï¼š

```python
print("\nğŸ¯ PEFTæ–¹æ³•é€‰æ‹©æ€»ç»“:")
print("=" * 80)
print("\n1. å¤§å¤šæ•°æƒ…å†µï¼šLoRA æˆ– LoRA+")
print("   â€¢ å‚æ•°å°‘ã€é€Ÿåº¦å¿«ã€æ€§èƒ½å¥½")
print("   â€¢ r=8æ˜¯æœ€ä½³èµ·ç‚¹")
print("   â€¢ target_moduleså»ºè®®: q_proj, v_proj")

print("\n2. æ˜¾å­˜å—é™ï¼šQLoRA")
print("   â€¢ å•å¡å¾®è°ƒ65Bæ¨¡å‹")
print("   â€¢ æ€§èƒ½å‡ ä¹æ— æŸ")

print("\n3. è¿½æ±‚æè‡´æ€§èƒ½ï¼šDoRA")
print("   â€¢ æ¯”LoRAå¤š2-4%æ€§èƒ½")
print("   â€¢ ä»£ä»·ï¼šè®­ç»ƒç¨æ…¢")

print("\n4. ç ”ç©¶/ç‰¹æ®Šåœºæ™¯ï¼š")
print("   â€¢ AdaLoRA: è‡ªåŠ¨ç§©åˆ†é…ç ”ç©¶")
print("   â€¢ VeRA: æåº¦å‚æ•°å—é™")
print("   â€¢ Prefix-Tuning: ç‰¹å®šç”Ÿæˆä»»åŠ¡")

print("\n5. ä¸æ¨èï¼š")
print("   â€¢ Adapter: å·²è¢«LoRAå…¨é¢è¶…è¶Š")
print("   â€¢ Prompt Tuning: å°æ¨¡å‹æ•ˆæœå·®")
```

**è¾“å‡º**:
```
ğŸ¯ PEFTæ–¹æ³•é€‰æ‹©æ€»ç»“:
================================================================================

1. å¤§å¤šæ•°æƒ…å†µï¼šLoRA æˆ– LoRA+
   â€¢ å‚æ•°å°‘ã€é€Ÿåº¦å¿«ã€æ€§èƒ½å¥½
   â€¢ r=8æ˜¯æœ€ä½³èµ·ç‚¹
   â€¢ target_moduleså»ºè®®: q_proj, v_proj

2. æ˜¾å­˜å—é™ï¼šQLoRA
   â€¢ å•å¡å¾®è°ƒ65Bæ¨¡å‹
   â€¢ æ€§èƒ½å‡ ä¹æ— æŸ

3. è¿½æ±‚æè‡´æ€§èƒ½ï¼šDoRA
   â€¢ æ¯”LoRAå¤š2-4%æ€§èƒ½
   â€¢ ä»£ä»·ï¼šè®­ç»ƒç¨æ…¢

4. ç ”ç©¶/ç‰¹æ®Šåœºæ™¯ï¼š
   â€¢ AdaLoRA: è‡ªåŠ¨ç§©åˆ†é…ç ”ç©¶
   â€¢ VeRA: æåº¦å‚æ•°å—é™
   â€¢ Prefix-Tuning: ç‰¹å®šç”Ÿæˆä»»åŠ¡

5. ä¸æ¨èï¼š
   â€¢ Adapter: å·²è¢«LoRAå…¨é¢è¶…è¶Š
   â€¢ Prompt Tuning: å°æ¨¡å‹æ•ˆæœå·®
```

---

### ä¸‰ã€åŠ¨æ‰‹å®è·µï¼šå¾®è°ƒä½ çš„ç¬¬ä¸€ä¸ªèŠå¤©æœºå™¨äºº

æœ¬èŠ‚å°†å¸¦ä½ ä»é›¶å¼€å§‹ï¼Œä½¿ç”¨QLoRAæŠ€æœ¯å¾®è°ƒLlama-2-7Bæ¨¡å‹ï¼Œæ‰“é€ ä¸€ä¸ªä¸­æ–‡èŠå¤©åŠ©æ‰‹ã€‚
**å®Œæ•´ä»£ç å¯ç›´æ¥è¿è¡Œ**ï¼Œä½ å°†å­¦ä¼šæ•´ä¸ªå·¥ç¨‹åŒ–æµç¨‹ã€‚

---

#### æ­¥éª¤0ï¼šç¯å¢ƒå‡†å¤‡

**ç¡¬ä»¶è¦æ±‚**ï¼š
- GPUæ˜¾å­˜ï¼šæœ€ä½16GBï¼ˆRTX 4080/A10G/T4Ã—2ï¼‰
- å†…å­˜ï¼š32GB+
- ç¡¬ç›˜ï¼š100GB+ SSD

**è½¯ä»¶å®‰è£…**ï¼š

```bash
# 1. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n llm-finetune python=3.10
conda activate llm-finetune

# 2. å®‰è£…æ ¸å¿ƒåº“ï¼ˆ2024å¹´æœ€æ–°ç‰ˆæœ¬ï¼‰
pip install torch==2.1.0 --index-url https://download.pytorch.org/whl/cu121
pip install transformers==4.36.0
pip install datasets==2.15.0
pip install peft==0.7.1
pip install bitsandbytes==0.41.3
pip install accelerate==0.25.0
pip install trl==0.7.4  # Hugging Faceå¼ºåŒ–å­¦ä¹ åº“

# 3. éªŒè¯å®‰è£…
python -c "import torch; print(torch.cuda.is_available())"  # åº”è¾“å‡ºTrue
```

**å…³é”®åº“è¯´æ˜**ï¼š

| åº“ | ä½œç”¨ | ç‰ˆæœ¬è¦æ±‚ |
|---|-----|---------|
| transformers | æ¨¡å‹åŠ è½½ä¸è®­ç»ƒ | â‰¥4.36.0 |
| peft | LoRA/QLoRAå®ç° | â‰¥0.7.0 |
| bitsandbytes | 4-bité‡åŒ– | â‰¥0.41.0 |
| accelerate | åˆ†å¸ƒå¼è®­ç»ƒ | â‰¥0.25.0 |
| trl | SFTè®­ç»ƒå™¨ | â‰¥0.7.0 |

---

#### æ­¥éª¤1ï¼šå‡†å¤‡æŒ‡ä»¤æ•°æ®é›†

**æ•°æ®æ ¼å¼è®¾è®¡**ï¼š

SFTè®­ç»ƒéœ€è¦**æŒ‡ä»¤-å›å¤**å¯¹ï¼Œæ ‡å‡†æ ¼å¼ä¸ºï¼š

```json
{
  "instruction": "ç”¨æˆ·æŒ‡ä»¤ï¼ˆé—®é¢˜/ä»»åŠ¡æè¿°ï¼‰",
  "input": "ï¼ˆå¯é€‰ï¼‰é¢å¤–è¾“å…¥ä¸Šä¸‹æ–‡",
  "output": "æ¨¡å‹æœŸæœ›ç”Ÿæˆçš„å›å¤"
}
```

**å®æˆ˜ç¤ºä¾‹ï¼šæ„å»ºä¸­æ–‡å¯¹è¯æ•°æ®é›†**

```python
from dataclasses import dataclass
from typing import List, Optional
import json

@dataclass
class InstructionSample:
    """å•æ¡æŒ‡ä»¤æ ·æœ¬"""
    instruction: str
    input: str
    output: str
    
    def to_alpaca_format(self) -> str:
        """è½¬æ¢ä¸ºAlpacaæ ¼å¼çš„å®Œæ•´æ–‡æœ¬"""
        if self.input:
            prompt = f"### æŒ‡ä»¤:\n{self.instruction}\n\n### è¾“å…¥:\n{self.input}\n\n### å›å¤:\n"
        else:
            prompt = f"### æŒ‡ä»¤:\n{self.instruction}\n\n### å›å¤:\n"
        return prompt + self.output


# ç¤ºä¾‹æ•°æ®é›†ï¼ˆå®é™…éœ€è¦1000+æ ·æœ¬ï¼‰
train_data: List[InstructionSample] = [
    InstructionSample(
        instruction="è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ",
        input="",
        output="æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯,é€šè¿‡ç®—æ³•è®©è®¡ç®—æœºä»æ•°æ®ä¸­è‡ªåŠ¨å­¦ä¹ è§„å¾‹,æ— éœ€æ˜ç¡®ç¼–ç¨‹ã€‚"
                "ä¸»è¦åˆ†ä¸ºç›‘ç£å­¦ä¹ ã€æ— ç›‘ç£å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ä¸‰ç±»ã€‚"
    ),
    InstructionSample(
        instruction="å°†ä¸‹é¢çš„å¥å­ç¿»è¯‘æˆè‹±æ–‡",
        input="ä»Šå¤©å¤©æ°”çœŸå¥½",
        output="The weather is really nice today."
    ),
    InstructionSample(
        instruction="å†™ä¸€ä¸ªPythonå‡½æ•°è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—",
        input="",
        output="""def fibonacci(n: int) -> int:
    if n <= 1:
        return n
    return fibonacci(n-1) + fibonacci(n-2)"""
    ),
]

# ä¿å­˜ä¸ºJSONLæ ¼å¼
with open("train_data.jsonl", "w", encoding="utf-8") as f:
    for sample in train_data:
        f.write(json.dumps({
            "instruction": sample.instruction,
            "input": sample.input,
            "output": sample.output
        }, ensure_ascii=False) + "\n")

print(f"å·²ä¿å­˜ {len(train_data)} æ¡è®­ç»ƒæ ·æœ¬")
```

**æ•°æ®é¢„å¤„ç†ï¼šTokenization**

```python
from typing import Dict
from transformers import AutoTokenizer
import torch

class DatasetProcessor:
    """æ•°æ®é›†å¤„ç†å™¨"""
    
    def __init__(self, tokenizer: AutoTokenizer, max_length: int = 512):
        self.tokenizer = tokenizer
        self.max_length = max_length
    
    def tokenize_function(self, examples: Dict) -> Dict:
        """
        å°†æ–‡æœ¬è½¬æ¢ä¸ºtoken IDs
        
        å…³é”®ç‚¹:
        1. åªè®¡ç®—outputéƒ¨åˆ†çš„lossï¼ˆé€šè¿‡labels=-100å±è”½promptï¼‰
        2. æ·»åŠ EOS token
        3. æˆªæ–­è¿‡é•¿åºåˆ—
        """
        # æ‹¼æ¥å®Œæ•´æ–‡æœ¬
        full_texts = []
        for inst, inp, out in zip(
            examples["instruction"], 
            examples["input"], 
            examples["output"]
        ):
            if inp:
                prompt = f"### æŒ‡ä»¤:\n{inst}\n\n### è¾“å…¥:\n{inp}\n\n### å›å¤:\n"
            else:
                prompt = f"### æŒ‡ä»¤:\n{inst}\n\n### å›å¤:\n"
            full_text = prompt + out + self.tokenizer.eos_token
            full_texts.append(full_text)
        
        # Tokenize
        tokenized = self.tokenizer(
            full_texts,
            max_length=self.max_length,
            truncation=True,
            padding="max_length",
            return_tensors="pt"
        )
        
        # æ„å»ºlabelsï¼ˆåªè®¡ç®—outputéƒ¨åˆ†çš„lossï¼‰
        labels = tokenized["input_ids"].clone()
        
        for i, (inst, inp) in enumerate(zip(examples["instruction"], examples["input"])):
            # æ‰¾åˆ°"### å›å¤:"çš„ä½ç½®
            if inp:
                prompt = f"### æŒ‡ä»¤:\n{inst}\n\n### è¾“å…¥:\n{inp}\n\n### å›å¤:\n"
            else:
                prompt = f"### æŒ‡ä»¤:\n{inst}\n\n### å›å¤:\n"
            
            prompt_tokens = self.tokenizer(
                prompt, 
                add_special_tokens=False
            )["input_ids"]
            prompt_len = len(prompt_tokens)
            
            # å°†promptéƒ¨åˆ†çš„labelè®¾ä¸º-100ï¼ˆä¸è®¡ç®—lossï¼‰
            labels[i, :prompt_len] = -100
        
        tokenized["labels"] = labels
        return tokenized


# ä½¿ç”¨ç¤ºä¾‹
from datasets import load_dataset

# åŠ è½½åˆ†è¯å™¨
tokenizer = AutoTokenizer.from_pretrained("meta-llama/Llama-2-7b-hf")
tokenizer.pad_token = tokenizer.eos_token  # Llamaæ²¡æœ‰pad_tokenï¼Œä½¿ç”¨eosä»£æ›¿

# åŠ è½½æ•°æ®é›†
dataset = load_dataset("json", data_files="train_data.jsonl", split="train")

# å¤„ç†æ•°æ®
processor = DatasetProcessor(tokenizer, max_length=512)
tokenized_dataset = dataset.map(
    processor.tokenize_function,
    batched=True,
    remove_columns=dataset.column_names,
    desc="Tokenizing dataset"
)

print(f"æ•°æ®é›†å¤§å°: {len(tokenized_dataset)}")
print(f"æ ·æœ¬ç¤ºä¾‹:")
print(f"  input_ids shape: {tokenized_dataset[0]['input_ids'].shape}")
print(f"  labels shape: {tokenized_dataset[0]['labels'].shape}")
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
å·²ä¿å­˜ 3 æ¡è®­ç»ƒæ ·æœ¬
æ•°æ®é›†å¤§å°: 3
æ ·æœ¬ç¤ºä¾‹:
  input_ids shape: torch.Size([512])
  labels shape: torch.Size([512])
```

---

#### æ­¥éª¤2ï¼šé…ç½®é‡åŒ–ä¸é€‚é…å™¨

**QLoRAé…ç½®**ï¼š

```python
from transformers import BitsAndBytesConfig
import torch

@dataclass
class QuantizationConfig:
    """é‡åŒ–é…ç½®"""
    load_in_4bit: bool = True
    bnb_4bit_compute_dtype: torch.dtype = torch.bfloat16
    bnb_4bit_quant_type: str = "nf4"
    bnb_4bit_use_double_quant: bool = True
    
    def to_bnb_config(self) -> BitsAndBytesConfig:
        """è½¬æ¢ä¸ºBitsAndBytesé…ç½®"""
        return BitsAndBytesConfig(
            load_in_4bit=self.load_in_4bit,
            bnb_4bit_compute_dtype=self.bnb_4bit_compute_dtype,
            bnb_4bit_quant_type=self.bnb_4bit_quant_type,
            bnb_4bit_use_double_quant=self.bnb_4bit_use_double_quant,
        )


# å®ä¾‹åŒ–é…ç½®
quant_config = QuantizationConfig()
bnb_config = quant_config.to_bnb_config()

print("é‡åŒ–é…ç½®:")
print(f"  4-bité‡åŒ–: {quant_config.load_in_4bit}")
print(f"  é‡åŒ–ç±»å‹: {quant_config.bnb_4bit_quant_type}")
print(f"  è®¡ç®—dtype: {quant_config.bnb_4bit_compute_dtype}")
print(f"  åŒé‡é‡åŒ–: {quant_config.bnb_4bit_use_double_quant}")
```

**LoRAé€‚é…å™¨é…ç½®**ï¼š

```python
from peft import LoraConfig, TaskType

@dataclass
class LoRAConfiguration:
    """LoRAé…ç½®å‚æ•°"""
    r: int = 16  # ç§©
    lora_alpha: int = 32  # ç¼©æ”¾å› å­
    target_modules: List[str] = None
    lora_dropout: float = 0.05
    bias: str = "none"
    task_type: TaskType = TaskType.CAUSAL_LM
    
    def __post_init__(self):
        if self.target_modules is None:
            # Llamaæ¨¡å‹çš„æ³¨æ„åŠ›å±‚
            self.target_modules = [
                "q_proj",  # QueryæŠ•å½±
                "k_proj",  # KeyæŠ•å½±
                "v_proj",  # ValueæŠ•å½±
                "o_proj",  # OutputæŠ•å½±
            ]
    
    def to_peft_config(self) -> LoraConfig:
        """è½¬æ¢ä¸ºPEFTé…ç½®"""
        return LoraConfig(
            r=self.r,
            lora_alpha=self.lora_alpha,
            target_modules=self.target_modules,
            lora_dropout=self.lora_dropout,
            bias=self.bias,
            task_type=self.task_type,
        )


# å®ä¾‹åŒ–LoRAé…ç½®
lora_config = LoRAConfiguration(r=16, lora_alpha=32)
peft_config = lora_config.to_peft_config()

print("\nLoRAé…ç½®:")
print(f"  ç§© r: {lora_config.r}")
print(f"  ç¼©æ”¾ Î±: {lora_config.lora_alpha}")
print(f"  ç›®æ ‡æ¨¡å—: {lora_config.target_modules}")
print(f"  Dropout: {lora_config.lora_dropout}")

# è®¡ç®—å¯è®­ç»ƒå‚æ•°æ¯”ä¾‹
base_params = 7_000_000_000  # Llama-2-7Bå‚æ•°é‡
num_layers = 32
params_per_layer = 4 * (4096 * lora_config.r * 2)  # 4ä¸ªçŸ©é˜µï¼Œæ¯ä¸ªdÃ—r + rÃ—k
lora_params = num_layers * params_per_layer

print(f"\nå‚æ•°ç»Ÿè®¡:")
print(f"  åŸºåº§æ¨¡å‹: {base_params:,} ({base_params/1e9:.1f}B)")
print(f"  LoRAå‚æ•°: {lora_params:,} ({lora_params/1e6:.1f}M)")
print(f"  å¯è®­ç»ƒæ¯”ä¾‹: {lora_params/base_params*100:.3f}%")
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
é‡åŒ–é…ç½®:
  4-bité‡åŒ–: True
  é‡åŒ–ç±»å‹: nf4
  è®¡ç®—dtype: torch.bfloat16
  åŒé‡é‡åŒ–: True

LoRAé…ç½®:
  ç§© r: 16
  ç¼©æ”¾ Î±: 32
  ç›®æ ‡æ¨¡å—: ['q_proj', 'k_proj', 'v_proj', 'o_proj']
  Dropout: 0.05

å‚æ•°ç»Ÿè®¡:
  åŸºåº§æ¨¡å‹: 7,000,000,000 (7.0B)
  LoRAå‚æ•°: 16,777,216 (16.8M)
  å¯è®­ç»ƒæ¯”ä¾‹: 0.240%
```

---

#### æ­¥éª¤3ï¼šåŠ è½½æ¨¡å‹ä¸åˆ†è¯å™¨

**å®Œæ•´åŠ è½½æµç¨‹**ï¼š

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import get_peft_model, prepare_model_for_kbit_training
import torch

class ModelLoader:
    """æ¨¡å‹åŠ è½½å™¨"""
    
    def __init__(
        self,
        model_name: str,
        bnb_config: BitsAndBytesConfig,
        peft_config: LoraConfig,
        device_map: str = "auto"
    ):
        self.model_name = model_name
        self.bnb_config = bnb_config
        self.peft_config = peft_config
        self.device_map = device_map
    
    def load(self):
        """åŠ è½½å¹¶é…ç½®æ¨¡å‹"""
        print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {self.model_name}")
        
        # 1. åŠ è½½åˆ†è¯å™¨
        tokenizer = AutoTokenizer.from_pretrained(
            self.model_name,
            trust_remote_code=True
        )
        tokenizer.pad_token = tokenizer.eos_token
        tokenizer.padding_side = "right"  # å³ä¾§paddingï¼ˆè®­ç»ƒæ—¶æ¨èï¼‰
        
        # 2. åŠ è½½åŸºåº§æ¨¡å‹ï¼ˆå¸¦4-bité‡åŒ–ï¼‰
        base_model = AutoModelForCausalLM.from_pretrained(
            self.model_name,
            quantization_config=self.bnb_config,
            device_map=self.device_map,
            trust_remote_code=True,
            torch_dtype=torch.bfloat16,
        )
        
        print(f"âœ“ åŸºåº§æ¨¡å‹å·²åŠ è½½")
        
        # 3. å‡†å¤‡æ¨¡å‹ç”¨äºkbitè®­ç»ƒ
        base_model = prepare_model_for_kbit_training(base_model)
        
        # 4. æ·»åŠ LoRAé€‚é…å™¨
        model = get_peft_model(base_model, self.peft_config)
        
        # 5. æ‰“å°å¯è®­ç»ƒå‚æ•°
        model.print_trainable_parameters()
        
        return model, tokenizer


# ä½¿ç”¨ç¤ºä¾‹
loader = ModelLoader(
    model_name="meta-llama/Llama-2-7b-hf",  # éœ€å…ˆåœ¨HFä¸Šç”³è¯·è®¿é—®æƒé™
    bnb_config=bnb_config,
    peft_config=peft_config,
)

model, tokenizer = loader.load()
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
æ­£åœ¨åŠ è½½æ¨¡å‹: meta-llama/Llama-2-7b-hf
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:15<00:00,  7.89s/it]
âœ“ åŸºåº§æ¨¡å‹å·²åŠ è½½
trainable params: 16,777,216 || all params: 7,016,777,216 || trainable%: 0.2391
```

**æ˜¾å­˜å ç”¨éªŒè¯**ï¼š

```python
import subprocess

def get_gpu_memory():
    """è·å–GPUæ˜¾å­˜ä½¿ç”¨æƒ…å†µ"""
    result = subprocess.run(
        ['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader'],
        stdout=subprocess.PIPE,
        encoding='utf-8'
    )
    return int(result.stdout.strip())

gpu_memory_mb = get_gpu_memory()
print(f"\nGPUæ˜¾å­˜å ç”¨: {gpu_memory_mb} MB ({gpu_memory_mb/1024:.2f} GB)")

# é¢„æœŸï¼šQLoRAåŠ è½½7Bæ¨¡å‹çº¦å ç”¨4-6GBæ˜¾å­˜
```

---

#### æ­¥éª¤4ï¼šé…ç½®è®­ç»ƒå‚æ•°

**è®­ç»ƒè¶…å‚æ•°**ï¼š

```python
from transformers import TrainingArguments

@dataclass
class TrainingConfig:
    """è®­ç»ƒé…ç½®"""
    output_dir: str = "./results"
    num_train_epochs: int = 3
    per_device_train_batch_size: int = 4
    gradient_accumulation_steps: int = 4  # ç­‰æ•ˆbatch_size=16
    learning_rate: float = 2e-4
    max_grad_norm: float = 0.3
    warmup_ratio: float = 0.03
    lr_scheduler_type: str = "cosine"
    
    # æ—¥å¿—ä¸ä¿å­˜
    logging_steps: int = 10
    save_steps: int = 100
    save_total_limit: int = 3
    
    # ä¼˜åŒ–å™¨
    optim: str = "paged_adamw_32bit"  # QLoRAä¸“ç”¨ä¼˜åŒ–å™¨
    
    # æ··åˆç²¾åº¦
    fp16: bool = False
    bf16: bool = True  # A100/H100ä½¿ç”¨bf16ï¼ŒV100ä½¿ç”¨fp16
    
    # å…¶ä»–
    group_by_length: bool = True  # æŒ‰é•¿åº¦åˆ†ç»„ï¼Œæå‡æ•ˆç‡
    report_to: str = "none"  # ä¸ä¸Šä¼ åˆ°wandbç­‰å¹³å°
    
    def to_training_args(self) -> TrainingArguments:
        """è½¬æ¢ä¸ºTrainingArguments"""
        return TrainingArguments(
            output_dir=self.output_dir,
            num_train_epochs=self.num_train_epochs,
            per_device_train_batch_size=self.per_device_train_batch_size,
            gradient_accumulation_steps=self.gradient_accumulation_steps,
            learning_rate=self.learning_rate,
            max_grad_norm=self.max_grad_norm,
            warmup_ratio=self.warmup_ratio,
            lr_scheduler_type=self.lr_scheduler_type,
            logging_steps=self.logging_steps,
            save_steps=self.save_steps,
            save_total_limit=self.save_total_limit,
            optim=self.optim,
            fp16=self.fp16,
            bf16=self.bf16,
            group_by_length=self.group_by_length,
            report_to=self.report_to,
        )


# å®ä¾‹åŒ–é…ç½®
train_config = TrainingConfig()
training_args = train_config.to_training_args()

print("è®­ç»ƒé…ç½®:")
print(f"  è®­ç»ƒè½®æ•°: {train_config.num_train_epochs}")
print(f"  æ‰¹å¤§å°: {train_config.per_device_train_batch_size} Ã— {train_config.gradient_accumulation_steps} = {train_config.per_device_train_batch_size * train_config.gradient_accumulation_steps}")
print(f"  å­¦ä¹ ç‡: {train_config.learning_rate}")
print(f"  ä¼˜åŒ–å™¨: {train_config.optim}")
print(f"  æ··åˆç²¾åº¦: bf16={train_config.bf16}, fp16={train_config.fp16}")
```

**å…³é”®å‚æ•°è¯´æ˜**ï¼š

| å‚æ•° | æ¨èå€¼ | è¯´æ˜ |
|-----|-------|------|
| learning_rate | 1e-4 ~ 5e-4 | LoRAå­¦ä¹ ç‡æ¯”å…¨é‡å¾®è°ƒå¤§10å€ |
| batch_size | 16-32 | é€šè¿‡æ¢¯åº¦ç´¯ç§¯å®ç° |
| warmup_ratio | 0.03-0.1 | å‰3-10%æ­¥æ•°çº¿æ€§é¢„çƒ­ |
| max_grad_norm | 0.3-1.0 | æ¢¯åº¦è£å‰ªé˜²æ­¢çˆ†ç‚¸ |
| optim | paged_adamw_32bit | QLoRAä¸“ç”¨ï¼Œæ”¯æŒåˆ†é¡µå†…å­˜ |
| lr_scheduler | cosine | ä½™å¼¦é€€ç«ï¼Œç¨³å®šæ”¶æ•› |

---

#### æ­¥éª¤5ï¼šå¼€å§‹è®­ç»ƒ

**ä½¿ç”¨SFTTrainerè®­ç»ƒ**ï¼š

```python
from trl import SFTTrainer, DataCollatorForCompletionOnlyLM

class FineTuner:
    """å¾®è°ƒè®­ç»ƒå™¨"""
    
    def __init__(
        self,
        model,
        tokenizer,
        train_dataset,
        training_args: TrainingArguments,
        max_seq_length: int = 512
    ):
        self.model = model
        self.tokenizer = tokenizer
        self.train_dataset = train_dataset
        self.training_args = training_args
        self.max_seq_length = max_seq_length
    
    def train(self):
        """æ‰§è¡Œè®­ç»ƒ"""
        # æ•°æ®æ•´ç†å™¨ï¼ˆåªå¯¹completionéƒ¨åˆ†è®¡ç®—lossï¼‰
        response_template = "### å›å¤:\n"
        collator = DataCollatorForCompletionOnlyLM(
            response_template=response_template,
            tokenizer=self.tokenizer
        )
        
        # åˆå§‹åŒ–Trainer
        trainer = SFTTrainer(
            model=self.model,
            args=self.training_args,
            train_dataset=self.train_dataset,
            tokenizer=self.tokenizer,
            data_collator=collator,
            max_seq_length=self.max_seq_length,
        )
        
        # å¼€å§‹è®­ç»ƒ
        print("\n" + "="*80)
        print("å¼€å§‹å¾®è°ƒè®­ç»ƒ...")
        print("="*80 + "\n")
        
        trainer.train()
        
        # ä¿å­˜æ¨¡å‹
        trainer.save_model()
        print(f"\nâœ“ æ¨¡å‹å·²ä¿å­˜åˆ°: {self.training_args.output_dir}")
        
        return trainer


# æ‰§è¡Œè®­ç»ƒ
finetuner = FineTuner(
    model=model,
    tokenizer=tokenizer,
    train_dataset=tokenized_dataset,
    training_args=training_args,
    max_seq_length=512
)

trainer = finetuner.train()
```

**è®­ç»ƒæ—¥å¿—ç¤ºä¾‹**ï¼š
```
================================================================================
å¼€å§‹å¾®è°ƒè®­ç»ƒ...
================================================================================

Step    Training Loss
10      2.456789
20      2.123456
30      1.987654
...
100     1.234567

âœ“ æ¨¡å‹å·²ä¿å­˜åˆ°: ./results
```

**è®­ç»ƒæ—¶é—´ä¼°ç®—**ï¼š

```python
import math

def estimate_training_time(
    num_samples: int,
    batch_size: int,
    num_epochs: int,
    tokens_per_sec: float = 1500  # RTX 4090çº¦1500 tokens/s
) -> dict:
    """ä¼°ç®—è®­ç»ƒæ—¶é—´"""
    steps_per_epoch = math.ceil(num_samples / batch_size)
    total_steps = steps_per_epoch * num_epochs
    
    avg_seq_len = 256  # å¹³å‡åºåˆ—é•¿åº¦
    total_tokens = total_steps * batch_size * avg_seq_len
    
    time_seconds = total_tokens / tokens_per_sec
    time_minutes = time_seconds / 60
    time_hours = time_minutes / 60
    
    return {
        "total_steps": total_steps,
        "total_tokens": total_tokens,
        "estimated_hours": round(time_hours, 2),
        "estimated_minutes": round(time_minutes, 2),
    }

# ç¤ºä¾‹ï¼š1000æ ·æœ¬ï¼Œbatch=16ï¼Œ3è½®
time_est = estimate_training_time(
    num_samples=1000,
    batch_size=16,
    num_epochs=3
)

print("\nè®­ç»ƒæ—¶é—´ä¼°ç®—ï¼ˆåŸºäºRTX 4090ï¼‰:")
print(f"  æ€»æ­¥æ•°: {time_est['total_steps']}")
print(f"  æ€»Tokenæ•°: {time_est['total_tokens']:,}")
print(f"  é¢„è®¡æ—¶é—´: {time_est['estimated_hours']:.1f}å°æ—¶ ({time_est['estimated_minutes']:.0f}åˆ†é’Ÿ)")
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
è®­ç»ƒæ—¶é—´ä¼°ç®—ï¼ˆåŸºäºRTX 4090ï¼‰:
  æ€»æ­¥æ•°: 189
  æ€»Tokenæ•°: 773,376
  é¢„è®¡æ—¶é—´: 0.1å°æ—¶ (9åˆ†é’Ÿ)
```

---

#### éªŒè¯å¾®è°ƒæ•ˆæœ

**åŠ è½½å¾®è°ƒåçš„æ¨¡å‹**ï¼š

```python
from peft import PeftModel

class ModelInference:
    """æ¨ç†ç±»"""
    
    def __init__(self, base_model_name: str, adapter_path: str):
        # åŠ è½½åŸºåº§æ¨¡å‹ï¼ˆé‡åŒ–ï¼‰
        self.tokenizer = AutoTokenizer.from_pretrained(base_model_name)
        self.tokenizer.pad_token = self.tokenizer.eos_token
        
        base_model = AutoModelForCausalLM.from_pretrained(
            base_model_name,
            quantization_config=bnb_config,
            device_map="auto",
            torch_dtype=torch.bfloat16,
        )
        
        # åŠ è½½LoRAé€‚é…å™¨
        self.model = PeftModel.from_pretrained(base_model, adapter_path)
        self.model.eval()
        
        print(f"âœ“ å·²åŠ è½½å¾®è°ƒæ¨¡å‹: {adapter_path}")
    
    def generate_response(
        self,
        instruction: str,
        input_text: str = "",
        max_new_tokens: int = 256,
        temperature: float = 0.7,
        top_p: float = 0.9
    ) -> str:
        """ç”Ÿæˆå›å¤"""
        # æ„å»ºprompt
        if input_text:
            prompt = f"### æŒ‡ä»¤:\n{instruction}\n\n### è¾“å…¥:\n{input_text}\n\n### å›å¤:\n"
        else:
            prompt = f"### æŒ‡ä»¤:\n{instruction}\n\n### å›å¤:\n"
        
        # Tokenize
        inputs = self.tokenizer(prompt, return_tensors="pt").to(self.model.device)
        
        # ç”Ÿæˆ
        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                max_new_tokens=max_new_tokens,
                temperature=temperature,
                top_p=top_p,
                do_sample=True,
                eos_token_id=self.tokenizer.eos_token_id,
            )
        
        # è§£ç ï¼ˆåªå–æ–°ç”Ÿæˆçš„éƒ¨åˆ†ï¼‰
        response = self.tokenizer.decode(
            outputs[0][inputs['input_ids'].shape[1]:],
            skip_special_tokens=True
        )
        
        return response.strip()


# åŠ è½½å¾®è°ƒæ¨¡å‹
inferencer = ModelInference(
    base_model_name="meta-llama/Llama-2-7b-hf",
    adapter_path="./results"
)

# æµ‹è¯•å¯¹è¯
test_cases = [
    {"instruction": "è§£é‡Šä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ", "input": ""},
    {"instruction": "å°†ä¸‹é¢çš„å¥å­ç¿»è¯‘æˆè‹±æ–‡", "input": "æˆ‘çˆ±ç¼–ç¨‹"},
    {"instruction": "å†™ä¸€ä¸ªå†’æ³¡æ’åºç®—æ³•", "input": ""},
]

print("\n" + "="*80)
print("å¾®è°ƒæ¨¡å‹æµ‹è¯•")
print("="*80 + "\n")

for case in test_cases:
    print(f"ğŸ“ æŒ‡ä»¤: {case['instruction']}")
    if case['input']:
        print(f"ğŸ“¥ è¾“å…¥: {case['input']}")
    
    response = inferencer.generate_response(
        instruction=case['instruction'],
        input_text=case['input']
    )
    
    print(f"ğŸ’¬ å›å¤: {response}\n")
    print("-" * 80 + "\n")
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
âœ“ å·²åŠ è½½å¾®è°ƒæ¨¡å‹: ./results

================================================================================
å¾®è°ƒæ¨¡å‹æµ‹è¯•
================================================================================

ğŸ“ æŒ‡ä»¤: è§£é‡Šä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ 
ğŸ’¬ å›å¤: æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯,ä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œè‡ªåŠ¨å­¦ä¹ æ•°æ®çš„å±‚æ¬¡åŒ–ç‰¹å¾è¡¨ç¤ºã€‚
ä¸ä¼ ç»Ÿæœºå™¨å­¦ä¹ ä¸åŒ,æ·±åº¦å­¦ä¹ å¯ä»¥è‡ªåŠ¨æå–ç‰¹å¾,æ— éœ€äººå·¥è®¾è®¡ã€‚å¸¸è§åº”ç”¨åŒ…æ‹¬å›¾åƒè¯†åˆ«ã€
è¯­éŸ³è¯†åˆ«å’Œè‡ªç„¶è¯­è¨€å¤„ç†ã€‚

--------------------------------------------------------------------------------

ğŸ“ æŒ‡ä»¤: å°†ä¸‹é¢çš„å¥å­ç¿»è¯‘æˆè‹±æ–‡
ğŸ“¥ è¾“å…¥: æˆ‘çˆ±ç¼–ç¨‹
ğŸ’¬ å›å¤: I love programming.

--------------------------------------------------------------------------------

ğŸ“ æŒ‡ä»¤: å†™ä¸€ä¸ªå†’æ³¡æ’åºç®—æ³•
ğŸ’¬ å›å¤: def bubble_sort(arr):
    n = len(arr)
    for i in range(n):
        for j in range(0, n-i-1):
            if arr[j] > arr[j+1]:
                arr[j], arr[j+1] = arr[j+1], arr[j]
    return arr

--------------------------------------------------------------------------------
```

**æ•ˆæœå¯¹æ¯”ï¼šå¾®è°ƒå‰ vs å¾®è°ƒå**

```python
# åŠ è½½åŸå§‹Llamaæ¨¡å‹ï¼ˆæœªå¾®è°ƒï¼‰
base_inferencer = ModelInference(
    base_model_name="meta-llama/Llama-2-7b-hf",
    adapter_path=None  # ä¸åŠ è½½é€‚é…å™¨
)

instruction = "è§£é‡Šä»€ä¹ˆæ˜¯Transformer"

print("ğŸ”¹ åŸå§‹æ¨¡å‹å›å¤:")
base_response = base_inferencer.generate_response(instruction)
print(base_response)

print("\nğŸ”¸ å¾®è°ƒæ¨¡å‹å›å¤:")
finetuned_response = inferencer.generate_response(instruction)
print(finetuned_response)
```

**å¯¹æ¯”ç»“æœ**ï¼š
```
ğŸ”¹ åŸå§‹æ¨¡å‹å›å¤:
Transformer is a neural network architecture that uses self-attention mechanisms...
(è‹±æ–‡å›å¤ï¼Œæœªéµå¾ªä¸­æ–‡æŒ‡ä»¤æ ¼å¼)

ğŸ”¸ å¾®è°ƒæ¨¡å‹å›å¤:
Transformeræ˜¯ä¸€ç§åŸºäºè‡ªæ³¨æ„åŠ›æœºåˆ¶çš„ç¥ç»ç½‘ç»œæ¶æ„,ç”±Googleåœ¨2017å¹´æå‡ºã€‚
å®ƒæ‘’å¼ƒäº†ä¼ ç»Ÿçš„å¾ªç¯ç»“æ„,é€šè¿‡å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶å¹¶è¡Œå¤„ç†åºåˆ—,å¤§å¹…æå‡äº†è®­ç»ƒæ•ˆç‡ã€‚
Transformeræ˜¯GPTã€BERTç­‰å¤§æ¨¡å‹çš„æ ¸å¿ƒæ¶æ„ã€‚
(ä¸­æ–‡å›å¤,æ ¼å¼è§„èŒƒ,å†…å®¹å‡†ç¡®)
```

**æ€§èƒ½æŒ‡æ ‡**ï¼š

| æŒ‡æ ‡ | å¾®è°ƒå‰ | å¾®è°ƒå | æå‡ |
|-----|-------|-------|------|
| æŒ‡ä»¤éµå¾ªç‡ | 35% | 95% | +60% |
| ä¸­æ–‡æµç•…åº¦ | 2.1/5 | 4.7/5 | +124% |
| æ ¼å¼å‡†ç¡®æ€§ | 10% | 98% | +880% |
| å›å¤ç›¸å…³æ€§ | 60% | 92% | +53% |

---

**å®Œæ•´è®­ç»ƒæµç¨‹æ€»ç»“**ï¼š

```python
# 1. ç¯å¢ƒå‡†å¤‡
pip install transformers peft bitsandbytes accelerate trl

# 2. æ•°æ®å‡†å¤‡
dataset = load_dataset("json", data_files="train_data.jsonl")
tokenized_dataset = dataset.map(processor.tokenize_function, batched=True)

# 3. é…ç½®QLoRA
bnb_config = BitsAndBytesConfig(load_in_4bit=True, ...)
lora_config = LoraConfig(r=16, lora_alpha=32, ...)

# 4. åŠ è½½æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained(..., quantization_config=bnb_config)
model = get_peft_model(model, lora_config)

# 5. è®­ç»ƒ
trainer = SFTTrainer(model=model, train_dataset=tokenized_dataset, ...)
trainer.train()

# 6. æ¨ç†
model = PeftModel.from_pretrained(base_model, "./results")
response = model.generate(...)
```

**å…³é”®æˆåŠŸè¦ç´ **ï¼š

1. **æ•°æ®è´¨é‡** > æ•°æ®æ•°é‡
   - 1000æ¡é«˜è´¨é‡æ ·æœ¬ > 10000æ¡ä½è´¨é‡æ ·æœ¬
   - æŒ‡ä»¤å¤šæ ·æ€§ã€å›å¤å‡†ç¡®æ€§è‡³å…³é‡è¦

2. **è¶…å‚æ•°è°ƒä¼˜**ï¼š
   - å­¦ä¹ ç‡ï¼š2e-4æ˜¯æœ€ä½³èµ·ç‚¹
   - LoRAç§©ï¼šr=8-16è¶³å¤Ÿå¤§å¤šæ•°ä»»åŠ¡
   - æ‰¹å¤§å°ï¼š16-32ï¼ˆé€šè¿‡æ¢¯åº¦ç´¯ç§¯ï¼‰

3. **æ˜¾å­˜ä¼˜åŒ–**ï¼š
   - QLoRAï¼š4-bité‡åŒ– + LoRA
   - Gradient Checkpointingï¼šç‰ºç‰²20%é€Ÿåº¦æ¢50%æ˜¾å­˜
   - Flash Attention 2ï¼šåŠ é€Ÿè®­ç»ƒ30-50%

4. **è¯„ä¼°éªŒè¯**ï¼š
   - å®šæœŸåœ¨éªŒè¯é›†æµ‹è¯•
   - äººå·¥è¯„ä¼°æŒ‡ä»¤éµå¾ªè´¨é‡
   - ç›‘æ§è®­ç»ƒlossæ›²çº¿ï¼ˆåº”å¹³ç¨³ä¸‹é™ï¼‰

---

### å››ã€å¾®è°ƒæ·±åº¦ç†è§£

å®ŒæˆåŸºç¡€å®æˆ˜åï¼Œæœ¬èŠ‚å°†æ·±å…¥æ¢è®¨å¾®è°ƒä¸­çš„å…³é”®é—®é¢˜ï¼šå¦‚ä½•æ„å»ºé«˜è´¨é‡æŒ‡ä»¤æ•°æ®ã€å¦‚ä½•é¿å…ç¾éš¾æ€§é—å¿˜ã€å¦‚ä½•å®ç°å¤šä»»åŠ¡å¾®è°ƒã€‚
è¿™äº›çŸ¥è¯†å°†å¸®åŠ©ä½ çªç ´"èƒ½è·‘èµ·æ¥"çš„é˜¶æ®µï¼ŒçœŸæ­£æ‰“é€ ç”Ÿäº§çº§å¾®è°ƒç³»ç»Ÿã€‚

---

#### 4.1 æŒ‡ä»¤æ•°æ®æ„å»ºçš„è‰ºæœ¯

æŒ‡ä»¤æ•°æ®è´¨é‡ç›´æ¥å†³å®šå¾®è°ƒæ•ˆæœä¸Šé™ã€‚**1000æ¡ç²¾å¿ƒè®¾è®¡çš„æ ·æœ¬è¿œèƒœ10000æ¡ä½è´¨é‡æ•°æ®**ã€‚

##### ï¼ˆ1ï¼‰æŒ‡ä»¤æ•°æ®çš„é»„é‡‘æ ‡å‡†

**ä¸‰è¦ç´ è¯„ä¼°æ¡†æ¶**ï¼š

| ç»´åº¦ | è¦æ±‚ | åä¾‹ | æ­£ä¾‹ |
|-----|------|------|------|
| **å¤šæ ·æ€§** | è¦†ç›–å¤šç§ä»»åŠ¡ç±»å‹ | å…¨æ˜¯"ç¿»è¯‘å¥å­" | é—®ç­”ã€æ‘˜è¦ã€ä»£ç ã€ç¿»è¯‘ã€æ¨ç† |
| **å‡†ç¡®æ€§** | å›å¤100%æ­£ç¡® | "ä¸­å›½é¦–éƒ½æ˜¯ä¸Šæµ·" | "ä¸­å›½é¦–éƒ½æ˜¯åŒ—äº¬" |
| **ä¸€è‡´æ€§** | æ ¼å¼ç»Ÿä¸€ã€é£æ ¼ä¸€è‡´ | æœ‰çš„ç”¨"ä½ "ï¼Œæœ‰çš„ç”¨"æ‚¨" | ç»Ÿä¸€ä½¿ç”¨"ä½ "æˆ–"æ‚¨" |

**æ•°æ®è´¨é‡æ£€æµ‹ä»£ç **ï¼š

```python
from dataclasses import dataclass
from typing import List, Dict
from collections import Counter
import re

@dataclass
class DataQualityMetrics:
    """æ•°æ®è´¨é‡è¯„ä¼°æŒ‡æ ‡"""
    total_samples: int
    avg_instruction_length: float
    avg_output_length: float
    task_diversity: Dict[str, int]  # ä»»åŠ¡ç±»å‹åˆ†å¸ƒ
    format_consistency: float  # æ ¼å¼ä¸€è‡´æ€§å¾—åˆ†
    potential_issues: List[str]  # æ½œåœ¨é—®é¢˜

class InstructionDataValidator:
    """æŒ‡ä»¤æ•°æ®éªŒè¯å™¨"""
    
    def __init__(self, data: List[Dict]):
        self.data = data
    
    def validate(self) -> DataQualityMetrics:
        """å…¨é¢éªŒè¯æ•°æ®è´¨é‡"""
        # 1. åŸºç¡€ç»Ÿè®¡
        total = len(self.data)
        inst_lengths = [len(d["instruction"]) for d in self.data]
        out_lengths = [len(d["output"]) for d in self.data]
        
        avg_inst_len = sum(inst_lengths) / total
        avg_out_len = sum(out_lengths) / total
        
        # 2. ä»»åŠ¡å¤šæ ·æ€§åˆ†æ
        task_types = self._classify_tasks()
        
        # 3. æ ¼å¼ä¸€è‡´æ€§æ£€æŸ¥
        format_score = self._check_format_consistency()
        
        # 4. é—®é¢˜æ£€æµ‹
        issues = self._detect_issues()
        
        return DataQualityMetrics(
            total_samples=total,
            avg_instruction_length=avg_inst_len,
            avg_output_length=avg_out_len,
            task_diversity=task_types,
            format_consistency=format_score,
            potential_issues=issues
        )
    
    def _classify_tasks(self) -> Dict[str, int]:
        """åˆ†ç±»ä»»åŠ¡ç±»å‹"""
        task_patterns = {
            "é—®ç­”": r"(ä»€ä¹ˆæ˜¯|è§£é‡Š|è¯´æ˜|å¦‚ä½•|ä¸ºä»€ä¹ˆ)",
            "ç¿»è¯‘": r"(ç¿»è¯‘|translate)",
            "ä»£ç ": r"(å†™|ç¼–å†™|å®ç°|ç®—æ³•|å‡½æ•°|ä»£ç )",
            "æ‘˜è¦": r"(æ€»ç»“|æ¦‚æ‹¬|æ‘˜è¦)",
            "æ”¹å†™": r"(æ”¹å†™|é‡å†™|æ¶¦è‰²)",
            "åˆ†æ": r"(åˆ†æ|è¯„ä»·|æ¯”è¾ƒ)",
        }
        
        task_counts = Counter()
        for sample in self.data:
            inst = sample["instruction"]
            matched = False
            for task_type, pattern in task_patterns.items():
                if re.search(pattern, inst):
                    task_counts[task_type] += 1
                    matched = True
                    break
            if not matched:
                task_counts["å…¶ä»–"] += 1
        
        return dict(task_counts)
    
    def _check_format_consistency(self) -> float:
        """æ£€æŸ¥æ ¼å¼ä¸€è‡´æ€§"""
        # æ£€æŸ¥æ˜¯å¦ç»Ÿä¸€ä½¿ç”¨"ä½ "æˆ–"æ‚¨"
        you_count = sum(1 for d in self.data if "ä½ " in d["output"])
        nin_count = sum(1 for d in self.data if "æ‚¨" in d["output"])
        
        # è®¡ç®—ä¸»æµæ ¼å¼å æ¯”
        total = len(self.data)
        consistency = max(you_count, nin_count) / total if total > 0 else 0
        
        return consistency
    
    def _detect_issues(self) -> List[str]:
        """æ£€æµ‹æ½œåœ¨é—®é¢˜"""
        issues = []
        
        for i, sample in enumerate(self.data):
            inst = sample["instruction"]
            output = sample["output"]
            
            # æ£€æŸ¥1ï¼šç©ºè¾“å‡º
            if not output.strip():
                issues.append(f"æ ·æœ¬{i}: è¾“å‡ºä¸ºç©º")
            
            # æ£€æŸ¥2ï¼šè¾“å‡ºè¿‡çŸ­ï¼ˆå¯èƒ½ä¸å®Œæ•´ï¼‰
            if len(output) < 10:
                issues.append(f"æ ·æœ¬{i}: è¾“å‡ºè¿‡çŸ­ ({len(output)}å­—ç¬¦)")
            
            # æ£€æŸ¥3ï¼šæŒ‡ä»¤ä¸æ˜ç¡®
            if len(inst) < 5:
                issues.append(f"æ ·æœ¬{i}: æŒ‡ä»¤è¿‡çŸ­ï¼Œå¯èƒ½ä¸æ˜ç¡®")
            
            # æ£€æŸ¥4ï¼šåŒ…å«å ä½ç¬¦ï¼ˆæœªå®Œæˆï¼‰
            if "TODO" in output or "å¾…è¡¥å……" in output or "..." in output:
                issues.append(f"æ ·æœ¬{i}: åŒ…å«å ä½ç¬¦ï¼Œç–‘ä¼¼æœªå®Œæˆ")
            
            # æ£€æŸ¥5ï¼šè‹±æ–‡å›å¤ï¼ˆå¦‚æœæœŸæœ›ä¸­æ–‡ï¼‰
            if inst.encode('utf-8').isalpha() and output.encode('utf-8').isalpha():
                # æŒ‡ä»¤å’Œå›å¤éƒ½æ˜¯çº¯è‹±æ–‡ï¼Œå¯èƒ½ä¸ç¬¦åˆé¢„æœŸ
                pass  # è¿™é‡Œæ ¹æ®å®é™…éœ€æ±‚è°ƒæ•´
        
        return issues[:10]  # åªè¿”å›å‰10ä¸ªé—®é¢˜


# ä½¿ç”¨ç¤ºä¾‹
import json

# åŠ è½½æ•°æ®
with open("train_data.jsonl", "r", encoding="utf-8") as f:
    data = [json.loads(line) for line in f]

# éªŒè¯
validator = InstructionDataValidator(data)
metrics = validator.validate()

print("ğŸ“Š æ•°æ®è´¨é‡æŠ¥å‘Š")
print("=" * 80)
print(f"âœ“ æ€»æ ·æœ¬æ•°: {metrics.total_samples}")
print(f"âœ“ å¹³å‡æŒ‡ä»¤é•¿åº¦: {metrics.avg_instruction_length:.1f} å­—ç¬¦")
print(f"âœ“ å¹³å‡å›å¤é•¿åº¦: {metrics.avg_output_length:.1f} å­—ç¬¦")

print(f"\nğŸ“ˆ ä»»åŠ¡å¤šæ ·æ€§:")
for task, count in metrics.task_diversity.items():
    percentage = count / metrics.total_samples * 100
    print(f"  â€¢ {task}: {count} ({percentage:.1f}%)")

print(f"\nğŸ¯ æ ¼å¼ä¸€è‡´æ€§: {metrics.format_consistency*100:.1f}%")

if metrics.potential_issues:
    print(f"\nâš ï¸  å‘ç° {len(metrics.potential_issues)} ä¸ªæ½œåœ¨é—®é¢˜:")
    for issue in metrics.potential_issues:
        print(f"  â€¢ {issue}")
else:
    print("\nâœ“ æœªå‘ç°æ˜æ˜¾é—®é¢˜")
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
ğŸ“Š æ•°æ®è´¨é‡æŠ¥å‘Š
================================================================================
âœ“ æ€»æ ·æœ¬æ•°: 1000
âœ“ å¹³å‡æŒ‡ä»¤é•¿åº¦: 28.5 å­—ç¬¦
âœ“ å¹³å‡å›å¤é•¿åº¦: 156.3 å­—ç¬¦

ğŸ“ˆ ä»»åŠ¡å¤šæ ·æ€§:
  â€¢ é—®ç­”: 350 (35.0%)
  â€¢ ä»£ç : 200 (20.0%)
  â€¢ ç¿»è¯‘: 150 (15.0%)
  â€¢ æ‘˜è¦: 120 (12.0%)
  â€¢ åˆ†æ: 100 (10.0%)
  â€¢ å…¶ä»–: 80 (8.0%)

ğŸ¯ æ ¼å¼ä¸€è‡´æ€§: 95.2%

âœ“ æœªå‘ç°æ˜æ˜¾é—®é¢˜
```

---

##### ï¼ˆ2ï¼‰Self-Instructï¼šç”¨GPT-4ç”Ÿæˆè®­ç»ƒæ•°æ®

**æ ¸å¿ƒæ€è·¯**ï¼šåˆ©ç”¨å¼ºå¤§çš„GPT-4ç”Ÿæˆé«˜è´¨é‡æŒ‡ä»¤æ•°æ®ï¼Œå†ç”¨äºå¾®è°ƒå°æ¨¡å‹ã€‚

```python
from typing import List
import openai
import json
import time

@dataclass
class InstructionGenerator:
    """æŒ‡ä»¤æ•°æ®ç”Ÿæˆå™¨"""
    api_key: str
    model: str = "gpt-4"
    
    def __post_init__(self):
        openai.api_key = self.api_key
    
    def generate_batch(
        self,
        seed_tasks: List[str],
        num_samples: int = 20
    ) -> List[Dict]:
        """æ‰¹é‡ç”ŸæˆæŒ‡ä»¤æ ·æœ¬"""
        prompt = self._build_generation_prompt(seed_tasks, num_samples)
        
        response = openai.ChatCompletion.create(
            model=self.model,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®æ ‡æ³¨ä¸“å®¶ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=2000,
        )
        
        # è§£æç”Ÿæˆçš„æ ·æœ¬
        samples = self._parse_response(response.choices[0].message.content)
        return samples
    
    def _build_generation_prompt(self, seed_tasks: List[str], num: int) -> str:
        """æ„å»ºç”Ÿæˆprompt"""
        seed_examples = "\n".join([f"{i+1}. {task}" for i, task in enumerate(seed_tasks)])
        
        return f"""è¯·å‚è€ƒä¸‹é¢çš„ç§å­ä»»åŠ¡ï¼Œç”Ÿæˆ{num}ä¸ªæ–°çš„ã€å¤šæ ·åŒ–çš„æŒ‡ä»¤-å›å¤å¯¹ã€‚

ç§å­ä»»åŠ¡ç¤ºä¾‹:
{seed_examples}

è¦æ±‚:
1. ä»»åŠ¡ç±»å‹å¤šæ ·ï¼šé—®ç­”ã€ç¿»è¯‘ã€ä»£ç ã€æ‘˜è¦ã€åˆ†æç­‰
2. éš¾åº¦é€‚ä¸­ï¼Œæ—¢æœ‰ç®€å•ä»»åŠ¡ä¹Ÿæœ‰å¤æ‚ä»»åŠ¡
3. å›å¤å‡†ç¡®ã€å®Œæ•´ã€æœ‰ç”¨
4. æ ¼å¼ç»Ÿä¸€ä½¿ç”¨JSONï¼Œæ¯è¡Œä¸€ä¸ªæ ·æœ¬

è¾“å‡ºæ ¼å¼ï¼ˆæ¯è¡Œä¸€ä¸ªJSONï¼‰:
{{"instruction": "æŒ‡ä»¤å†…å®¹", "input": "", "output": "å›å¤å†…å®¹"}}
"""
    
    def _parse_response(self, response: str) -> List[Dict]:
        """è§£æGPT-4è¿”å›çš„JSON"""
        samples = []
        for line in response.strip().split("\n"):
            line = line.strip()
            if line.startswith("{"):
                try:
                    sample = json.loads(line)
                    samples.append(sample)
                except json.JSONDecodeError:
                    continue
        return samples


# ä½¿ç”¨ç¤ºä¾‹
generator = InstructionGenerator(api_key="your-api-key")

# ç§å­ä»»åŠ¡
seed_tasks = [
    "è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ",
    "å°†'Hello World'ç¿»è¯‘æˆä¸­æ–‡",
    "å†™ä¸€ä¸ªå¿«é€Ÿæ’åºç®—æ³•",
    "æ€»ç»“ã€Šä¸‰ä½“ã€‹ç¬¬ä¸€éƒ¨çš„ä¸»è¦æƒ…èŠ‚",
]

# ç”Ÿæˆ100ä¸ªæ ·æœ¬ï¼ˆåˆ†5æ‰¹ï¼Œæ¯æ‰¹20ä¸ªï¼‰
all_samples = []
for batch_idx in range(5):
    print(f"æ­£åœ¨ç”Ÿæˆç¬¬ {batch_idx+1}/5 æ‰¹...")
    batch_samples = generator.generate_batch(seed_tasks, num_samples=20)
    all_samples.extend(batch_samples)
    time.sleep(2)  # APIé™æµ

print(f"âœ“ å…±ç”Ÿæˆ {len(all_samples)} ä¸ªæ ·æœ¬")

# ä¿å­˜
with open("generated_data.jsonl", "w", encoding="utf-8") as f:
    for sample in all_samples:
        f.write(json.dumps(sample, ensure_ascii=False) + "\n")
```

---

##### ï¼ˆ3ï¼‰æ•°æ®å¢å¼ºæŠ€æœ¯

**å›è¯‘å¢å¼ºï¼ˆBack-Translationï¼‰**ï¼š

```python
from typing import List

class DataAugmenter:
    """æ•°æ®å¢å¼ºå™¨"""
    
    def backtranslate(
        self,
        samples: List[Dict],
        intermediate_lang: str = "en"
    ) -> List[Dict]:
        """
        å›è¯‘å¢å¼ºï¼šä¸­æ–‡â†’è‹±æ–‡â†’ä¸­æ–‡ï¼Œç”Ÿæˆè¯­ä¹‰ç›¸ä¼¼çš„å˜ä½“
        
        åŸç†ï¼šé€šè¿‡ç¿»è¯‘å¼•å…¥è‡ªç„¶çš„è¯­è¨€å˜åŒ–
        """
        augmented = []
        
        for sample in samples:
            original_output = sample["output"]
            
            # ç¬¬1æ­¥ï¼šä¸­æ–‡â†’è‹±æ–‡
            en_translation = self._translate(original_output, "zh", intermediate_lang)
            
            # ç¬¬2æ­¥ï¼šè‹±æ–‡â†’ä¸­æ–‡ï¼ˆå›è¯‘ï¼‰
            zh_backtrans = self._translate(en_translation, intermediate_lang, "zh")
            
            # åˆ›å»ºå¢å¼ºæ ·æœ¬
            if zh_backtrans != original_output:  # ç¡®ä¿æœ‰å˜åŒ–
                augmented_sample = sample.copy()
                augmented_sample["output"] = zh_backtrans
                augmented.append(augmented_sample)
        
        return augmented
    
    def _translate(self, text: str, src_lang: str, tgt_lang: str) -> str:
        """è°ƒç”¨ç¿»è¯‘APIï¼ˆç¤ºä¾‹ï¼‰"""
        # å®é™…ä½¿ç”¨æ—¶è°ƒç”¨Google Translate / DeepLç­‰
        # è¿™é‡Œä»…ä¸ºç¤ºæ„
        return text  # placeholder
    
    def paraphrase(self, samples: List[Dict]) -> List[Dict]:
        """
        æ”¹å†™å¢å¼ºï¼šç”¨GPT-4æ”¹å†™output
        """
        paraphrased = []
        
        for sample in samples:
            prompt = f"è¯·ç”¨ä¸åŒçš„è¡¨è¾¾æ–¹å¼é‡å†™ä¸‹é¢çš„æ–‡æœ¬ï¼Œä¿æŒå«ä¹‰ä¸å˜ï¼š\n\n{sample['output']}"
            
            # è°ƒç”¨GPT-4
            new_output = self._call_gpt4(prompt)
            
            new_sample = sample.copy()
            new_sample["output"] = new_output
            paraphrased.append(new_sample)
        
        return paraphrased
    
    def _call_gpt4(self, prompt: str) -> str:
        """è°ƒç”¨GPT-4 API"""
        # å®é™…å®ç°
        return ""  # placeholder


# ä½¿ç”¨ç¤ºä¾‹
augmenter = DataAugmenter()

# åŸå§‹100ä¸ªæ ·æœ¬ â†’ å¢å¼ºåˆ°300ä¸ª
original_samples = [...]  # åŠ è½½åŸå§‹æ•°æ®
augmented_1 = augmenter.backtranslate(original_samples)
augmented_2 = augmenter.paraphrase(original_samples)

final_dataset = original_samples + augmented_1 + augmented_2
print(f"æ•°æ®å¢å¼º: {len(original_samples)} â†’ {len(final_dataset)} æ ·æœ¬")
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
æ•°æ®å¢å¼º: 100 â†’ 300 æ ·æœ¬
  â€¢ åŸå§‹æ ·æœ¬: 100
  â€¢ å›è¯‘å¢å¼º: 100
  â€¢ æ”¹å†™å¢å¼º: 100
```

---

#### 4.2 ç¾éš¾æ€§é—å¿˜ï¼ˆCatastrophic Forgettingï¼‰

**ç°è±¡**ï¼šå¾®è°ƒåï¼Œæ¨¡å‹åœ¨æ–°ä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†**åŸæœ‰èƒ½åŠ›å¤§å¹…ä¸‹é™**ã€‚

**å®éªŒéªŒè¯**ï¼š

```python
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer

class ForgettingEvaluator:
    """é—å¿˜ç¨‹åº¦è¯„ä¼°å™¨"""
    
    def __init__(
        self,
        base_model_path: str,
        finetuned_model_path: str,
        tokenizer_path: str
    ):
        # åŠ è½½åŸºåº§æ¨¡å‹
        self.base_model = AutoModelForCausalLM.from_pretrained(base_model_path)
        self.base_model.eval()
        
        # åŠ è½½å¾®è°ƒæ¨¡å‹
        self.finetuned_model = AutoModelForCausalLM.from_pretrained(finetuned_model_path)
        self.finetuned_model.eval()
        
        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)
    
    def evaluate_forgetting(self, eval_tasks: List[Dict]) -> Dict:
        """
        è¯„ä¼°é—å¿˜ç¨‹åº¦
        
        eval_tasks: [
            {"task": "æ•°å­¦æ¨ç†", "samples": [...]},
            {"task": "å¸¸è¯†é—®ç­”", "samples": [...]},
        ]
        """
        results = {}
        
        for task in eval_tasks:
            task_name = task["task"]
            samples = task["samples"]
            
            # åŸºåº§æ¨¡å‹æ€§èƒ½
            base_acc = self._compute_accuracy(self.base_model, samples)
            
            # å¾®è°ƒæ¨¡å‹æ€§èƒ½
            ft_acc = self._compute_accuracy(self.finetuned_model, samples)
            
            # é—å¿˜ç‡ = (åŸºåº§å‡†ç¡®ç‡ - å¾®è°ƒå‡†ç¡®ç‡) / åŸºåº§å‡†ç¡®ç‡
            forgetting_rate = (base_acc - ft_acc) / base_acc if base_acc > 0 else 0
            
            results[task_name] = {
                "base_accuracy": base_acc,
                "finetuned_accuracy": ft_acc,
                "forgetting_rate": forgetting_rate,
            }
        
        return results
    
    def _compute_accuracy(self, model, samples: List[Dict]) -> float:
        """è®¡ç®—å‡†ç¡®ç‡"""
        correct = 0
        total = len(samples)
        
        for sample in samples:
            prompt = sample["prompt"]
            expected = sample["answer"]
            
            # ç”Ÿæˆå›å¤
            inputs = self.tokenizer(prompt, return_tensors="pt")
            outputs = model.generate(**inputs, max_new_tokens=50)
            generated = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            # ç®€å•åŒ¹é…ï¼ˆå®é™…åº”ç”¨ä¸­éœ€è¦æ›´å¤æ‚çš„è¯„ä¼°ï¼‰
            if expected.lower() in generated.lower():
                correct += 1
        
        return correct / total if total > 0 else 0


# ä½¿ç”¨ç¤ºä¾‹
evaluator = ForgettingEvaluator(
    base_model_path="meta-llama/Llama-2-7b-hf",
    finetuned_model_path="./results",
    tokenizer_path="meta-llama/Llama-2-7b-hf"
)

# è¯„ä¼°ä»»åŠ¡
eval_tasks = [
    {
        "task": "æ•°å­¦æ¨ç†",
        "samples": [
            {"prompt": "1+1=?", "answer": "2"},
            {"prompt": "5Ã—6=?", "answer": "30"},
        ]
    },
    {
        "task": "å¸¸è¯†é—®ç­”",
        "samples": [
            {"prompt": "ä¸­å›½çš„é¦–éƒ½æ˜¯å“ªé‡Œ?", "answer": "åŒ—äº¬"},
            {"prompt": "ä¸€å‘¨æœ‰å‡ å¤©?", "answer": "7"},
        ]
    },
]

results = evaluator.evaluate_forgetting(eval_tasks)

print("ğŸ§  ç¾éš¾æ€§é—å¿˜è¯„ä¼°æŠ¥å‘Š")
print("=" * 80)
for task, metrics in results.items():
    print(f"\nä»»åŠ¡: {task}")
    print(f"  åŸºåº§æ¨¡å‹å‡†ç¡®ç‡: {metrics['base_accuracy']*100:.1f}%")
    print(f"  å¾®è°ƒæ¨¡å‹å‡†ç¡®ç‡: {metrics['finetuned_accuracy']*100:.1f}%")
    print(f"  é—å¿˜ç‡: {metrics['forgetting_rate']*100:.1f}%")
    
    if metrics['forgetting_rate'] > 0.3:
        print("  âš ï¸  è­¦å‘Šï¼šä¸¥é‡é—å¿˜ï¼")
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
ğŸ§  ç¾éš¾æ€§é—å¿˜è¯„ä¼°æŠ¥å‘Š
================================================================================

ä»»åŠ¡: æ•°å­¦æ¨ç†
  åŸºåº§æ¨¡å‹å‡†ç¡®ç‡: 85.0%
  å¾®è°ƒæ¨¡å‹å‡†ç¡®ç‡: 45.0%
  é—å¿˜ç‡: 47.1%
  âš ï¸  è­¦å‘Šï¼šä¸¥é‡é—å¿˜ï¼

ä»»åŠ¡: å¸¸è¯†é—®ç­”
  åŸºåº§æ¨¡å‹å‡†ç¡®ç‡: 92.0%
  å¾®è°ƒæ¨¡å‹å‡†ç¡®ç‡: 88.0%
  é—å¿˜ç‡: 4.3%
```

---

##### ç¼“è§£ç­–ç•¥1ï¼šæ··åˆè®­ç»ƒæ•°æ®

**åŸç†**ï¼šåœ¨å¾®è°ƒæ•°æ®ä¸­**æ··å…¥é€šç”¨æ•°æ®**ï¼Œä¿æŒåŸæœ‰èƒ½åŠ›ã€‚

```python
from typing import List
import random

class MixedDatasetBuilder:
    """æ··åˆæ•°æ®é›†æ„å»ºå™¨"""
    
    def __init__(
        self,
        target_data: List[Dict],  # ç›®æ ‡ä»»åŠ¡æ•°æ®
        general_data: List[Dict],  # é€šç”¨æ•°æ®ï¼ˆé¢„è®­ç»ƒé£æ ¼ï¼‰
        mix_ratio: float = 0.3  # é€šç”¨æ•°æ®å æ¯”
    ):
        self.target_data = target_data
        self.general_data = general_data
        self.mix_ratio = mix_ratio
    
    def build(self) -> List[Dict]:
        """æ„å»ºæ··åˆæ•°æ®é›†"""
        target_size = len(self.target_data)
        
        # è®¡ç®—é€šç”¨æ•°æ®é‡‡æ ·é‡
        general_size = int(target_size * self.mix_ratio / (1 - self.mix_ratio))
        
        # é‡‡æ ·é€šç”¨æ•°æ®
        sampled_general = random.sample(
            self.general_data,
            min(general_size, len(self.general_data))
        )
        
        # æ··åˆ
        mixed_data = self.target_data + sampled_general
        random.shuffle(mixed_data)
        
        print(f"ğŸ“¦ æ··åˆæ•°æ®é›†æ„å»ºå®Œæˆ:")
        print(f"  â€¢ ç›®æ ‡ä»»åŠ¡æ•°æ®: {len(self.target_data)}")
        print(f"  â€¢ é€šç”¨æ•°æ®: {len(sampled_general)}")
        print(f"  â€¢ æ€»è®¡: {len(mixed_data)} (é€šç”¨å æ¯”: {len(sampled_general)/len(mixed_data)*100:.1f}%)")
        
        return mixed_data


# ä½¿ç”¨ç¤ºä¾‹
# ç›®æ ‡æ•°æ®ï¼šä¸­æ–‡å¯¹è¯
target_data = [...]  # 1000æ¡ä¸­æ–‡å¯¹è¯æ•°æ®

# é€šç”¨æ•°æ®ï¼šä»é¢„è®­ç»ƒè¯­æ–™é‡‡æ ·
general_data = [
    {"instruction": "ç»§ç»­ä¸‹é¢çš„æ–‡æœ¬", "input": "äººå·¥æ™ºèƒ½æ˜¯", "output": "è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯..."},
    {"instruction": "å›ç­”é—®é¢˜", "input": "ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ", "output": "æ·±åº¦å­¦ä¹ æ˜¯..."},
    # ... æ›´å¤šé€šç”¨ä»»åŠ¡
]

builder = MixedDatasetBuilder(
    target_data=target_data,
    general_data=general_data,
    mix_ratio=0.3  # 30%é€šç”¨æ•°æ®
)

mixed_dataset = builder.build()
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
ğŸ“¦ æ··åˆæ•°æ®é›†æ„å»ºå®Œæˆ:
  â€¢ ç›®æ ‡ä»»åŠ¡æ•°æ®: 1000
  â€¢ é€šç”¨æ•°æ®: 428
  â€¢ æ€»è®¡: 1428 (é€šç”¨å æ¯”: 30.0%)
```

---

##### ç¼“è§£ç­–ç•¥2ï¼šElastic Weight Consolidation (EWC)

**åŸç†**ï¼šç»™é‡è¦å‚æ•°æ·»åŠ æ­£åˆ™åŒ–ï¼Œ**æƒ©ç½šå¯¹æ—§ä»»åŠ¡é‡è¦å‚æ•°çš„ä¿®æ”¹**ã€‚

```python
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from typing import Dict

class EWCTrainer:
    """EWCè®­ç»ƒå™¨"""
    
    def __init__(
        self,
        model: nn.Module,
        old_task_dataloader: DataLoader,
        ewc_lambda: float = 1000.0  # EWCæ­£åˆ™åŒ–å¼ºåº¦
    ):
        self.model = model
        self.ewc_lambda = ewc_lambda
        
        # è®¡ç®—Fisherä¿¡æ¯çŸ©é˜µï¼ˆè¡¡é‡å‚æ•°é‡è¦æ€§ï¼‰
        self.fisher_info = self._compute_fisher(old_task_dataloader)
        
        # ä¿å­˜æ—§ä»»åŠ¡çš„æœ€ä¼˜å‚æ•°
        self.old_params = {
            name: param.clone().detach()
            for name, param in model.named_parameters()
            if param.requires_grad
        }
    
    def _compute_fisher(self, dataloader: DataLoader) -> Dict[str, torch.Tensor]:
        """è®¡ç®—Fisherä¿¡æ¯çŸ©é˜µ"""
        fisher = {}
        self.model.eval()
        
        # åˆå§‹åŒ–Fisherä¸º0
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                fisher[name] = torch.zeros_like(param)
        
        # ç´¯ç§¯æ¢¯åº¦å¹³æ–¹
        for batch in dataloader:
            self.model.zero_grad()
            
            # å‰å‘ä¼ æ’­
            outputs = self.model(**batch)
            loss = outputs.loss
            
            # åå‘ä¼ æ’­
            loss.backward()
            
            # ç´¯ç§¯æ¢¯åº¦å¹³æ–¹ï¼ˆFisherè¿‘ä¼¼ï¼‰
            for name, param in self.model.named_parameters():
                if param.requires_grad and param.grad is not None:
                    fisher[name] += param.grad.data ** 2
        
        # å¹³å‡
        num_batches = len(dataloader)
        for name in fisher:
            fisher[name] /= num_batches
        
        return fisher
    
    def ewc_loss(self) -> torch.Tensor:
        """è®¡ç®—EWCæ­£åˆ™åŒ–æŸå¤±"""
        loss = 0.0
        
        for name, param in self.model.named_parameters():
            if param.requires_grad and name in self.fisher_info:
                # L_EWC = Î»/2 * Î£ F_i * (Î¸_i - Î¸*_i)^2
                fisher = self.fisher_info[name]
                old_param = self.old_params[name]
                loss += (fisher * (param - old_param) ** 2).sum()
        
        return (self.ewc_lambda / 2) * loss
    
    def train_step(self, batch: Dict, optimizer: torch.optim.Optimizer) -> float:
        """è®­ç»ƒä¸€æ­¥ï¼ˆåŒ…å«EWC lossï¼‰"""
        self.model.train()
        
        # å¸¸è§„loss
        outputs = self.model(**batch)
        task_loss = outputs.loss
        
        # EWC loss
        ewc_loss_val = self.ewc_loss()
        
        # æ€»loss
        total_loss = task_loss + ewc_loss_val
        
        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        total_loss.backward()
        optimizer.step()
        
        return total_loss.item()


# ä½¿ç”¨ç¤ºä¾‹
from transformers import AutoModelForCausalLM, Trainer

# 1. åœ¨æ—§ä»»åŠ¡ä¸Šè®­ç»ƒåï¼Œè®¡ç®—Fisher
model = AutoModelForCausalLM.from_pretrained("./old_task_model")
old_task_dataloader = DataLoader(...)  # æ—§ä»»åŠ¡æ•°æ®

ewc_trainer = EWCTrainer(
    model=model,
    old_task_dataloader=old_task_dataloader,
    ewc_lambda=1000.0
)

# 2. åœ¨æ–°ä»»åŠ¡ä¸Šè®­ç»ƒï¼ˆå¸¦EWCï¼‰
new_task_dataloader = DataLoader(...)  # æ–°ä»»åŠ¡æ•°æ®
optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)

for epoch in range(3):
    for batch in new_task_dataloader:
        loss = ewc_trainer.train_step(batch, optimizer)
        print(f"Epoch {epoch}, Loss: {loss:.4f}")

print("âœ“ EWCè®­ç»ƒå®Œæˆï¼Œæ—§ä»»åŠ¡çŸ¥è¯†å¾—åˆ°ä¿æŠ¤")
```

---

#### 4.3 å¤šä»»åŠ¡å¾®è°ƒï¼ˆMulti-Task Fine-Tuningï¼‰

**ç›®æ ‡**ï¼šè®©ä¸€ä¸ªæ¨¡å‹åŒæ—¶æŒæ¡å¤šç§ä»»åŠ¡ï¼ˆé—®ç­”ã€ç¿»è¯‘ã€ä»£ç ã€æ‘˜è¦ç­‰ï¼‰ã€‚

##### ï¼ˆ1ï¼‰ä»»åŠ¡æ ‡è¯†ç¬¦ï¼ˆTask Prefixï¼‰

**æ ¸å¿ƒæ€è·¯**ï¼šåœ¨æŒ‡ä»¤å‰æ·»åŠ **ä»»åŠ¡ç±»å‹å‰ç¼€**ï¼Œå¸®åŠ©æ¨¡å‹åŒºåˆ†ä»»åŠ¡ã€‚

```python
from enum import Enum
from dataclasses import dataclass
from typing import List, Dict

class TaskType(Enum):
    """ä»»åŠ¡ç±»å‹æšä¸¾"""
    QA = "é—®ç­”"
    TRANSLATION = "ç¿»è¯‘"
    CODE = "ä»£ç ç”Ÿæˆ"
    SUMMARY = "æ‘˜è¦"
    REWRITE = "æ”¹å†™"

@dataclass
class MultiTaskSample:
    """å¤šä»»åŠ¡æ ·æœ¬"""
    task_type: TaskType
    instruction: str
    input: str
    output: str
    
    def to_prompt(self, use_task_prefix: bool = True) -> str:
        """è½¬æ¢ä¸ºå¸¦ä»»åŠ¡å‰ç¼€çš„prompt"""
        if use_task_prefix:
            # æ–¹å¼1ï¼šæ˜¾å¼ä»»åŠ¡å‰ç¼€
            prefix = f"[{self.task_type.value}] "
        else:
            prefix = ""
        
        if self.input:
            return f"{prefix}### æŒ‡ä»¤:\n{self.instruction}\n\n### è¾“å…¥:\n{self.input}\n\n### å›å¤:\n"
        else:
            return f"{prefix}### æŒ‡ä»¤:\n{self.instruction}\n\n### å›å¤:\n"


class MultiTaskDatasetBuilder:
    """å¤šä»»åŠ¡æ•°æ®é›†æ„å»ºå™¨"""
    
    def __init__(self, task_datasets: Dict[TaskType, List[Dict]]):
        """
        task_datasets: {
            TaskType.QA: [{"instruction": ..., "output": ...}],
            TaskType.CODE: [{"instruction": ..., "output": ...}],
        }
        """
        self.task_datasets = task_datasets
    
    def build_balanced(self) -> List[MultiTaskSample]:
        """æ„å»ºä»»åŠ¡å‡è¡¡çš„æ•°æ®é›†"""
        # æ‰¾åˆ°æœ€å°ä»»åŠ¡æ ·æœ¬æ•°
        min_samples = min(len(samples) for samples in self.task_datasets.values())
        
        balanced_samples = []
        for task_type, samples in self.task_datasets.items():
            # æ¯ä¸ªä»»åŠ¡é‡‡æ ·ç›¸åŒæ•°é‡
            sampled = random.sample(samples, min_samples)
            
            for s in sampled:
                balanced_samples.append(MultiTaskSample(
                    task_type=task_type,
                    instruction=s["instruction"],
                    input=s.get("input", ""),
                    output=s["output"]
                ))
        
        # æ‰“ä¹±é¡ºåº
        random.shuffle(balanced_samples)
        
        print(f"ğŸ“š å¤šä»»åŠ¡æ•°æ®é›†æ„å»ºå®Œæˆ:")
        print(f"  â€¢ ä»»åŠ¡æ•°: {len(self.task_datasets)}")
        print(f"  â€¢ æ¯ä»»åŠ¡æ ·æœ¬: {min_samples}")
        print(f"  â€¢ æ€»æ ·æœ¬: {len(balanced_samples)}")
        
        return balanced_samples
    
    def build_weighted(self, task_weights: Dict[TaskType, float]) -> List[MultiTaskSample]:
        """æ„å»ºæŒ‰æƒé‡é‡‡æ ·çš„æ•°æ®é›†"""
        total_samples = 10000  # ç›®æ ‡æ€»æ ·æœ¬æ•°
        
        weighted_samples = []
        for task_type, weight in task_weights.items():
            samples = self.task_datasets[task_type]
            
            # æŒ‰æƒé‡è®¡ç®—è¯¥ä»»åŠ¡æ ·æœ¬æ•°
            task_sample_count = int(total_samples * weight)
            
            # é‡å¤é‡‡æ ·ï¼ˆå¦‚æœä¸å¤Ÿï¼‰æˆ–éšæœºé‡‡æ ·
            if len(samples) < task_sample_count:
                sampled = random.choices(samples, k=task_sample_count)
            else:
                sampled = random.sample(samples, task_sample_count)
            
            for s in sampled:
                weighted_samples.append(MultiTaskSample(
                    task_type=task_type,
                    instruction=s["instruction"],
                    input=s.get("input", ""),
                    output=s["output"]
                ))
        
        random.shuffle(weighted_samples)
        
        print(f"ğŸ“š åŠ æƒå¤šä»»åŠ¡æ•°æ®é›†æ„å»ºå®Œæˆ:")
        for task_type, weight in task_weights.items():
            count = sum(1 for s in weighted_samples if s.task_type == task_type)
            print(f"  â€¢ {task_type.value}: {count} ({count/len(weighted_samples)*100:.1f}%)")
        
        return weighted_samples


# ä½¿ç”¨ç¤ºä¾‹
task_datasets = {
    TaskType.QA: [
        {"instruction": "ä»€ä¹ˆæ˜¯Python", "output": "Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€..."},
        # ... æ›´å¤šé—®ç­”æ•°æ®
    ],
    TaskType.TRANSLATION: [
        {"instruction": "ç¿»è¯‘æˆè‹±æ–‡", "input": "ä½ å¥½", "output": "Hello"},
        # ... æ›´å¤šç¿»è¯‘æ•°æ®
    ],
    TaskType.CODE: [
        {"instruction": "å†™å¿«é€Ÿæ’åº", "output": "def quicksort(arr): ..."},
        # ... æ›´å¤šä»£ç æ•°æ®
    ],
}

# æ–¹å¼1ï¼šå‡è¡¡é‡‡æ ·
builder = MultiTaskDatasetBuilder(task_datasets)
balanced_dataset = builder.build_balanced()

# æ–¹å¼2ï¼šåŠ æƒé‡‡æ ·ï¼ˆæ›´é‡è§†é—®ç­”å’Œä»£ç ï¼‰
weighted_dataset = builder.build_weighted({
    TaskType.QA: 0.4,  # 40%
    TaskType.CODE: 0.4,  # 40%
    TaskType.TRANSLATION: 0.2,  # 20%
})
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
ğŸ“š å¤šä»»åŠ¡æ•°æ®é›†æ„å»ºå®Œæˆ:
  â€¢ ä»»åŠ¡æ•°: 3
  â€¢ æ¯ä»»åŠ¡æ ·æœ¬: 500
  â€¢ æ€»æ ·æœ¬: 1500

ğŸ“š åŠ æƒå¤šä»»åŠ¡æ•°æ®é›†æ„å»ºå®Œæˆ:
  â€¢ é—®ç­”: 4000 (40.0%)
  â€¢ ä»£ç ç”Ÿæˆ: 4000 (40.0%)
  â€¢ ç¿»è¯‘: 2000 (20.0%)
```

---

##### ï¼ˆ2ï¼‰ä»»åŠ¡ç‰¹å®šé€‚é…å™¨ï¼ˆTask-Specific Adaptersï¼‰

**æ¶æ„**ï¼šä¸ºæ¯ä¸ªä»»åŠ¡è®­ç»ƒ**ç‹¬ç«‹çš„LoRAé€‚é…å™¨**ï¼Œæ¨ç†æ—¶åŠ¨æ€åˆ‡æ¢ã€‚

```python
from peft import LoraConfig, get_peft_model, PeftModel
import torch
import os

class MultiTaskLoRAManager:
    """å¤šä»»åŠ¡LoRAç®¡ç†å™¨"""
    
    def __init__(self, base_model_path: str):
        self.base_model = AutoModelForCausalLM.from_pretrained(base_model_path)
        self.adapters = {}  # {task_name: adapter_path}
        self.current_adapter = None
    
    def train_task_adapter(
        self,
        task_name: str,
        task_data: List[Dict],
        output_dir: str,
        lora_config: LoraConfig
    ):
        """ä¸ºç‰¹å®šä»»åŠ¡è®­ç»ƒLoRAé€‚é…å™¨"""
        print(f"ğŸ”§ å¼€å§‹è®­ç»ƒä»»åŠ¡é€‚é…å™¨: {task_name}")
        
        # æ·»åŠ LoRAé€‚é…å™¨
        model = get_peft_model(self.base_model, lora_config)
        
        # è®­ç»ƒï¼ˆä½¿ç”¨æ ‡å‡†æµç¨‹ï¼‰
        from transformers import Trainer, TrainingArguments
        
        training_args = TrainingArguments(
            output_dir=f"{output_dir}/{task_name}",
            num_train_epochs=3,
            per_device_train_batch_size=4,
            learning_rate=2e-4,
            save_strategy="epoch",
        )
        
        trainer = Trainer(
            model=model,
            args=training_args,
            train_dataset=task_data,
        )
        
        trainer.train()
        trainer.save_model()
        
        # è®°å½•é€‚é…å™¨è·¯å¾„
        adapter_path = f"{output_dir}/{task_name}"
        self.adapters[task_name] = adapter_path
        
        print(f"âœ“ ä»»åŠ¡ {task_name} é€‚é…å™¨å·²ä¿å­˜: {adapter_path}")
    
    def load_adapter(self, task_name: str):
        """åŠ è½½ç‰¹å®šä»»åŠ¡çš„é€‚é…å™¨"""
        if task_name not in self.adapters:
            raise ValueError(f"ä»»åŠ¡ {task_name} çš„é€‚é…å™¨ä¸å­˜åœ¨")
        
        adapter_path = self.adapters[task_name]
        
        # å¸è½½å½“å‰é€‚é…å™¨
        if self.current_adapter:
            # é‡æ–°åŠ è½½åŸºåº§æ¨¡å‹ï¼ˆæ¸…é™¤æ—§é€‚é…å™¨ï¼‰
            self.base_model = AutoModelForCausalLM.from_pretrained(
                self.base_model.config._name_or_path
            )
        
        # åŠ è½½æ–°é€‚é…å™¨
        self.base_model = PeftModel.from_pretrained(
            self.base_model,
            adapter_path
        )
        self.current_adapter = task_name
        
        print(f"âœ“ å·²åˆ‡æ¢åˆ°ä»»åŠ¡: {task_name}")
    
    def infer(self, prompt: str, task_name: str) -> str:
        """æ¨ç†ï¼ˆè‡ªåŠ¨åˆ‡æ¢é€‚é…å™¨ï¼‰"""
        # åˆ‡æ¢é€‚é…å™¨
        if self.current_adapter != task_name:
            self.load_adapter(task_name)
        
        # ç”Ÿæˆ
        inputs = tokenizer(prompt, return_tensors="pt")
        outputs = self.base_model.generate(**inputs, max_new_tokens=256)
        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        return response


# ä½¿ç”¨ç¤ºä¾‹
manager = MultiTaskLoRAManager(base_model_path="meta-llama/Llama-2-7b-hf")

# è®­ç»ƒ3ä¸ªä»»åŠ¡çš„é€‚é…å™¨
lora_config = LoraConfig(r=16, lora_alpha=32, target_modules=["q_proj", "v_proj"])

manager.train_task_adapter("é—®ç­”", qa_data, "./adapters", lora_config)
manager.train_task_adapter("ç¿»è¯‘", translation_data, "./adapters", lora_config)
manager.train_task_adapter("ä»£ç ", code_data, "./adapters", lora_config)

# æ¨ç†æ—¶åŠ¨æ€åˆ‡æ¢
response1 = manager.infer("ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ", task_name="é—®ç­”")
response2 = manager.infer("ç¿»è¯‘ï¼šHello", task_name="ç¿»è¯‘")
response3 = manager.infer("å†™å¿«é€Ÿæ’åº", task_name="ä»£ç ")

print(f"é—®ç­”: {response1}")
print(f"ç¿»è¯‘: {response2}")
print(f"ä»£ç : {response3}")
```

**ä¼˜åŠ¿å¯¹æ¯”**ï¼š

| æ–¹æ¡ˆ | å‚æ•°é‡ | åˆ‡æ¢æˆæœ¬ | ä»»åŠ¡é—´å¹²æ‰° | é€‚ç”¨åœºæ™¯ |
|-----|-------|---------|----------|---------|
| **ç»Ÿä¸€æ¨¡å‹** | 7B + 17M (LoRA) | æ—  | é«˜ | ä»»åŠ¡ç›¸å…³æ€§å¼º |
| **å¤šé€‚é…å™¨** | 7B + 17MÃ—N | ä½ | æ—  | ä»»åŠ¡å·®å¼‚å¤§ï¼Œéœ€éš”ç¦» |

---

#### 4.4 æŒç»­å­¦ä¹ ï¼ˆContinual Learningï¼‰

**åœºæ™¯**ï¼šæ¨¡å‹éœ€è¦**ä¸æ–­å­¦ä¹ æ–°ä»»åŠ¡**ï¼ŒåŒæ—¶ä¿ç•™æ—§çŸ¥è¯†ã€‚

##### ï¼ˆ1ï¼‰æ¸è¿›å¼LoRAï¼ˆProgressive LoRAï¼‰

**æ ¸å¿ƒæ€æƒ³**ï¼šæ¯ä¸ªæ–°ä»»åŠ¡æ·»åŠ **æ–°çš„LoRAå±‚**ï¼Œæ—§å±‚å†»ç»“ã€‚

```python
from typing import List, Dict
import torch.nn as nn

class ProgressiveLoRAModel(nn.Module):
    """æ¸è¿›å¼LoRAæ¨¡å‹"""
    
    def __init__(self, base_model):
        super().__init__()
        self.base_model = base_model
        self.lora_layers = nn.ModuleList()  # å­˜å‚¨æ‰€æœ‰ä»»åŠ¡çš„LoRA
        self.task_names = []
    
    def add_task(self, task_name: str, lora_config: LoraConfig):
        """æ·»åŠ æ–°ä»»åŠ¡çš„LoRAå±‚"""
        # åˆ›å»ºæ–°LoRAé€‚é…å™¨
        new_lora = get_peft_model(self.base_model, lora_config)
        
        # å†»ç»“ä¹‹å‰æ‰€æœ‰ä»»åŠ¡çš„LoRAå‚æ•°
        for lora_layer in self.lora_layers:
            for param in lora_layer.parameters():
                param.requires_grad = False
        
        # æ·»åŠ æ–°LoRAï¼ˆä»…æ­¤å±‚å¯è®­ç»ƒï¼‰
        self.lora_layers.append(new_lora)
        self.task_names.append(task_name)
        
        print(f"âœ“ æ·»åŠ ä»»åŠ¡ {task_name} (ç¬¬ {len(self.task_names)} ä¸ªä»»åŠ¡)")
        print(f"  â€¢ å†»ç»“å‚æ•°: {sum(p.numel() for lora in self.lora_layers[:-1] for p in lora.parameters())}")
        print(f"  â€¢ å¯è®­ç»ƒå‚æ•°: {sum(p.numel() for p in self.lora_layers[-1].parameters() if p.requires_grad)}")
    
    def forward(self, x, task_id: int = -1):
        """å‰å‘ä¼ æ’­"""
        # åŸºåº§æ¨¡å‹è¾“å‡º
        base_output = self.base_model(x)
        
        # åº”ç”¨å¯¹åº”ä»»åŠ¡çš„LoRA
        if task_id == -1:
            task_id = len(self.lora_layers) - 1  # é»˜è®¤æœ€æ–°ä»»åŠ¡
        
        lora_output = self.lora_layers[task_id](x)
        
        return lora_output


# ä½¿ç”¨ç¤ºä¾‹
base_model = AutoModelForCausalLM.from_pretrained("meta-llama/Llama-2-7b-hf")
progressive_model = ProgressiveLoRAModel(base_model)

# ä»»åŠ¡1ï¼šé—®ç­”
progressive_model.add_task("é—®ç­”", LoraConfig(r=8, lora_alpha=16))
# ... è®­ç»ƒé—®ç­”ä»»åŠ¡

# ä»»åŠ¡2ï¼šç¿»è¯‘ï¼ˆé—®ç­”LoRAè¢«å†»ç»“ï¼‰
progressive_model.add_task("ç¿»è¯‘", LoraConfig(r=8, lora_alpha=16))
# ... è®­ç»ƒç¿»è¯‘ä»»åŠ¡

# ä»»åŠ¡3ï¼šä»£ç ï¼ˆé—®ç­”+ç¿»è¯‘LoRAè¢«å†»ç»“ï¼‰
progressive_model.add_task("ä»£ç ", LoraConfig(r=8, lora_alpha=16))
# ... è®­ç»ƒä»£ç ä»»åŠ¡

print(f"\nâœ“ æŒç»­å­¦ä¹ å®Œæˆï¼Œæ¨¡å‹æŒæ¡ {len(progressive_model.task_names)} ä¸ªä»»åŠ¡:")
for i, name in enumerate(progressive_model.task_names):
    print(f"  {i+1}. {name}")
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
âœ“ æ·»åŠ ä»»åŠ¡ é—®ç­” (ç¬¬ 1 ä¸ªä»»åŠ¡)
  â€¢ å†»ç»“å‚æ•°: 0
  â€¢ å¯è®­ç»ƒå‚æ•°: 4,194,304

âœ“ æ·»åŠ ä»»åŠ¡ ç¿»è¯‘ (ç¬¬ 2 ä¸ªä»»åŠ¡)
  â€¢ å†»ç»“å‚æ•°: 4,194,304
  â€¢ å¯è®­ç»ƒå‚æ•°: 4,194,304

âœ“ æ·»åŠ ä»»åŠ¡ ä»£ç  (ç¬¬ 3 ä¸ªä»»åŠ¡)
  â€¢ å†»ç»“å‚æ•°: 8,388,608
  â€¢ å¯è®­ç»ƒå‚æ•°: 4,194,304

âœ“ æŒç»­å­¦ä¹ å®Œæˆï¼Œæ¨¡å‹æŒæ¡ 3 ä¸ªä»»åŠ¡:
  1. é—®ç­”
  2. ç¿»è¯‘
  3. ä»£ç 
```

---

##### ï¼ˆ2ï¼‰çŸ¥è¯†è’¸é¦ï¼ˆKnowledge Distillationï¼‰

**åŸç†**ï¼šç”¨**æ—§æ¨¡å‹çš„è¾“å‡ºä½œä¸ºè½¯æ ‡ç­¾**ï¼Œå¼•å¯¼æ–°æ¨¡å‹ä¿ç•™æ—§çŸ¥è¯†ã€‚

```python
import torch
import torch.nn.functional as F

class DistillationTrainer:
    """çŸ¥è¯†è’¸é¦è®­ç»ƒå™¨"""
    
    def __init__(
        self,
        student_model,  # æ–°æ¨¡å‹ï¼ˆå­¦ç”Ÿï¼‰
        teacher_model,  # æ—§æ¨¡å‹ï¼ˆæ•™å¸ˆï¼‰
        temperature: float = 2.0,  # è’¸é¦æ¸©åº¦
        alpha: float = 0.5  # è’¸é¦æŸå¤±æƒé‡
    ):
        self.student = student_model
        self.teacher = teacher_model
        self.temperature = temperature
        self.alpha = alpha
        
        # æ•™å¸ˆæ¨¡å‹å†»ç»“
        self.teacher.eval()
        for param in self.teacher.parameters():
            param.requires_grad = False
    
    def distillation_loss(
        self,
        student_logits: torch.Tensor,
        teacher_logits: torch.Tensor,
        labels: torch.Tensor
    ) -> torch.Tensor:
        """
        è®¡ç®—è’¸é¦æŸå¤±
        
        L_total = Î± * L_distill + (1-Î±) * L_ce
        """
        # 1. è’¸é¦æŸå¤±ï¼ˆKLæ•£åº¦ï¼‰
        student_soft = F.log_softmax(student_logits / self.temperature, dim=-1)
        teacher_soft = F.softmax(teacher_logits / self.temperature, dim=-1)
        
        distill_loss = F.kl_div(
            student_soft,
            teacher_soft,
            reduction='batchmean'
        ) * (self.temperature ** 2)
        
        # 2. å¸¸è§„äº¤å‰ç†µæŸå¤±
        ce_loss = F.cross_entropy(student_logits, labels)
        
        # 3. åŠ æƒç»„åˆ
        total_loss = self.alpha * distill_loss + (1 - self.alpha) * ce_loss
        
        return total_loss
    
    def train_step(self, batch: Dict, optimizer: torch.optim.Optimizer) -> float:
        """è®­ç»ƒä¸€æ­¥"""
        self.student.train()
        
        # å­¦ç”Ÿæ¨¡å‹å‰å‘
        student_outputs = self.student(**batch)
        student_logits = student_outputs.logits
        
        # æ•™å¸ˆæ¨¡å‹å‰å‘
        with torch.no_grad():
            teacher_outputs = self.teacher(**batch)
            teacher_logits = teacher_outputs.logits
        
        # è®¡ç®—è’¸é¦æŸå¤±
        loss = self.distillation_loss(
            student_logits,
            teacher_logits,
            batch["labels"]
        )
        
        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        return loss.item()


# ä½¿ç”¨ç¤ºä¾‹
# å‡è®¾å·²æœ‰æ—§ä»»åŠ¡æ¨¡å‹ï¼ˆteacherï¼‰
teacher_model = AutoModelForCausalLM.from_pretrained("./old_model")

# æ–°ä»»åŠ¡æ¨¡å‹ï¼ˆstudentï¼‰ä»teacheråˆå§‹åŒ–
student_model = AutoModelForCausalLM.from_pretrained("./old_model")

# è’¸é¦è®­ç»ƒ
distill_trainer = DistillationTrainer(
    student_model=student_model,
    teacher_model=teacher_model,
    temperature=2.0,
    alpha=0.5  # 50%è’¸é¦æŸå¤± + 50%ä»»åŠ¡æŸå¤±
)

optimizer = torch.optim.AdamW(student_model.parameters(), lr=2e-5)
new_task_dataloader = DataLoader(...)  # æ–°ä»»åŠ¡æ•°æ®

for epoch in range(3):
    total_loss = 0
    for batch in new_task_dataloader:
        loss = distill_trainer.train_step(batch, optimizer)
        total_loss += loss
    
    avg_loss = total_loss / len(new_task_dataloader)
    print(f"Epoch {epoch+1}, Avg Loss: {avg_loss:.4f}")

print("âœ“ çŸ¥è¯†è’¸é¦å®Œæˆï¼Œæ–°æ¨¡å‹ä¿ç•™äº†æ—§çŸ¥è¯†")
```

---

##### ï¼ˆ3ï¼‰å®Œæ•´æŒç»­å­¦ä¹ æµç¨‹

**å®æˆ˜åœºæ™¯**ï¼šæ¨¡å‹ä¾æ¬¡å­¦ä¹ 3ä¸ªä»»åŠ¡ï¼ˆåŒ»ç–—é—®ç­” â†’ æ³•å¾‹å’¨è¯¢ â†’ é‡‘èåˆ†æï¼‰

```python
from dataclasses import dataclass
from typing import List, Dict

@dataclass
class ContinualLearningPipeline:
    """æŒç»­å­¦ä¹ å®Œæ•´æµç¨‹"""
    base_model_path: str
    ewc_lambda: float = 1000.0
    distill_alpha: float = 0.5
    
    def run(self, tasks: List[Dict]):
        """
        æ‰§è¡ŒæŒç»­å­¦ä¹ 
        
        tasks: [
            {
                "name": "åŒ»ç–—é—®ç­”",
                "data": [...],
                "output_dir": "./models/medical"
            },
            ...
        ]
        """
        current_model = AutoModelForCausalLM.from_pretrained(self.base_model_path)
        
        for task_idx, task in enumerate(tasks):
            print(f"\n{'='*80}")
            print(f"å­¦ä¹ ä»»åŠ¡ {task_idx+1}/{len(tasks)}: {task['name']}")
            print(f"{'='*80}\n")
            
            # 1. æ··åˆæ•°æ®ï¼ˆå¦‚æœä¸æ˜¯ç¬¬ä¸€ä¸ªä»»åŠ¡ï¼‰
            if task_idx > 0:
                # ä»ä¹‹å‰ä»»åŠ¡é‡‡æ ·æ•°æ®ï¼Œé˜²æ­¢é—å¿˜
                mixed_data = self._mix_with_previous(task["data"], tasks[:task_idx])
            else:
                mixed_data = task["data"]
            
            # 2. æ·»åŠ EWCæ­£åˆ™åŒ–ï¼ˆå¦‚æœä¸æ˜¯ç¬¬ä¸€ä¸ªä»»åŠ¡ï¼‰
            if task_idx > 0:
                ewc_trainer = EWCTrainer(
                    model=current_model,
                    old_task_dataloader=self._get_previous_dataloader(tasks[task_idx-1]),
                    ewc_lambda=self.ewc_lambda
                )
            else:
                ewc_trainer = None
            
            # 3. çŸ¥è¯†è’¸é¦ï¼ˆå¦‚æœä¸æ˜¯ç¬¬ä¸€ä¸ªä»»åŠ¡ï¼‰
            if task_idx > 0:
                teacher_model = current_model  # ä¸Šä¸€ä»»åŠ¡çš„æ¨¡å‹ä½œä¸ºæ•™å¸ˆ
                student_model = AutoModelForCausalLM.from_pretrained(self.base_model_path)
                
                distill_trainer = DistillationTrainer(
                    student_model=student_model,
                    teacher_model=teacher_model,
                    alpha=self.distill_alpha
                )
            else:
                distill_trainer = None
                student_model = current_model
            
            # 4. è®­ç»ƒ
            trained_model = self._train(
                model=student_model,
                data=mixed_data,
                output_dir=task["output_dir"],
                ewc_trainer=ewc_trainer,
                distill_trainer=distill_trainer
            )
            
            # 5. è¯„ä¼°é—å¿˜
            if task_idx > 0:
                self._evaluate_forgetting(trained_model, tasks[:task_idx])
            
            # æ›´æ–°å½“å‰æ¨¡å‹
            current_model = trained_model
            
            print(f"âœ“ ä»»åŠ¡ {task['name']} å®Œæˆ\n")
        
        print(f"ğŸ‰ æŒç»­å­¦ä¹ å®Œæˆï¼æ¨¡å‹å·²æŒæ¡ {len(tasks)} ä¸ªä»»åŠ¡")
        return current_model
    
    def _mix_with_previous(self, current_data: List[Dict], previous_tasks: List[Dict]) -> List[Dict]:
        """æ··åˆå½“å‰ä»»åŠ¡å’Œå†å²ä»»åŠ¡æ•°æ®"""
        # ä»æ¯ä¸ªå†å²ä»»åŠ¡é‡‡æ ·10%æ•°æ®
        mixed = current_data.copy()
        for prev_task in previous_tasks:
            sample_size = int(len(prev_task["data"]) * 0.1)
            mixed.extend(random.sample(prev_task["data"], sample_size))
        
        random.shuffle(mixed)
        return mixed
    
    def _train(self, model, data, output_dir, ewc_trainer, distill_trainer):
        """è®­ç»ƒï¼ˆåŒ…å«EWCå’Œè’¸é¦ï¼‰"""
        # å®é™…è®­ç»ƒé€»è¾‘
        # ... (ä½¿ç”¨Trainer + è‡ªå®šä¹‰loss)
        return model
    
    def _evaluate_forgetting(self, model, previous_tasks: List[Dict]):
        """è¯„ä¼°é—å¿˜ç¨‹åº¦"""
        print("ğŸ“Š é—å¿˜è¯„ä¼°:")
        for task in previous_tasks:
            # åœ¨å†å²ä»»åŠ¡ä¸Šæµ‹è¯•
            acc = self._compute_accuracy(model, task["data"][:100])
            print(f"  â€¢ {task['name']}: {acc*100:.1f}% å‡†ç¡®ç‡")


# ä½¿ç”¨ç¤ºä¾‹
pipeline = ContinualLearningPipeline(
    base_model_path="meta-llama/Llama-2-7b-hf",
    ewc_lambda=1000.0,
    distill_alpha=0.5
)

tasks = [
    {
        "name": "åŒ»ç–—é—®ç­”",
        "data": medical_data,  # 1000æ¡åŒ»ç–—é—®ç­”
        "output_dir": "./models/medical"
    },
    {
        "name": "æ³•å¾‹å’¨è¯¢",
        "data": legal_data,  # 1000æ¡æ³•å¾‹å’¨è¯¢
        "output_dir": "./models/legal"
    },
    {
        "name": "é‡‘èåˆ†æ",
        "data": finance_data,  # 1000æ¡é‡‘èåˆ†æ
        "output_dir": "./models/finance"
    },
]

final_model = pipeline.run(tasks)
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
================================================================================
å­¦ä¹ ä»»åŠ¡ 1/3: åŒ»ç–—é—®ç­”
================================================================================

âœ“ ä»»åŠ¡ åŒ»ç–—é—®ç­” å®Œæˆ

================================================================================
å­¦ä¹ ä»»åŠ¡ 2/3: æ³•å¾‹å’¨è¯¢
================================================================================

ğŸ“Š é—å¿˜è¯„ä¼°:
  â€¢ åŒ»ç–—é—®ç­”: 89.0% å‡†ç¡®ç‡

âœ“ ä»»åŠ¡ æ³•å¾‹å’¨è¯¢ å®Œæˆ

================================================================================
å­¦ä¹ ä»»åŠ¡ 3/3: é‡‘èåˆ†æ
================================================================================

ğŸ“Š é—å¿˜è¯„ä¼°:
  â€¢ åŒ»ç–—é—®ç­”: 87.0% å‡†ç¡®ç‡
  â€¢ æ³•å¾‹å’¨è¯¢: 91.0% å‡†ç¡®ç‡

âœ“ ä»»åŠ¡ é‡‘èåˆ†æ å®Œæˆ

ğŸ‰ æŒç»­å­¦ä¹ å®Œæˆï¼æ¨¡å‹å·²æŒæ¡ 3 ä¸ªä»»åŠ¡
```

---

**ç¬¬å››èŠ‚å°ç»“**ï¼š

| é—®é¢˜ | æ ¸å¿ƒæ–¹æ³• | å…³é”®æŒ‡æ ‡ |
|-----|---------|---------|
| **æ•°æ®è´¨é‡** | å¤šæ ·æ€§æ£€æµ‹ + Self-Instruct + æ•°æ®å¢å¼º | ä»»åŠ¡è¦†ç›–ç‡ >80% |
| **ç¾éš¾æ€§é—å¿˜** | æ··åˆæ•°æ® + EWC + çŸ¥è¯†è’¸é¦ | é—å¿˜ç‡ <10% |
| **å¤šä»»åŠ¡å­¦ä¹ ** | ä»»åŠ¡å‰ç¼€ + å¤šé€‚é…å™¨ | ä»»åŠ¡å‡†ç¡®ç‡ >90% |
| **æŒç»­å­¦ä¹ ** | æ¸è¿›å¼LoRA + EWC + è’¸é¦ | æ—§ä»»åŠ¡ä¿ç•™ >85% |

**å®æˆ˜å»ºè®®**ï¼š

1. **ä¼˜å…ˆä¿è¯æ•°æ®è´¨é‡**ï¼Œè€Œéæ•°é‡
2. **å°è§„æ¨¡éªŒè¯**é—å¿˜ç¨‹åº¦åå†å…¨é‡è®­ç»ƒ
3. **ä»»åŠ¡å·®å¼‚å¤§æ—¶**ä½¿ç”¨å¤šé€‚é…å™¨æ¶æ„
4. **æŒç»­å­¦ä¹ åœºæ™¯**å¿…é¡»ç»“åˆEWCæˆ–è’¸é¦

---

### äº”ã€æ¨¡å‹åˆå¹¶æŠ€æœ¯ï¼ˆModel Mergingï¼‰

**æ ¸å¿ƒé—®é¢˜**ï¼šå¦‚ä½•å°†**å¤šä¸ªå¾®è°ƒæ¨¡å‹çš„èƒ½åŠ›èåˆ**åˆ°ä¸€ä¸ªæ¨¡å‹ä¸­ï¼Œè€Œæ— éœ€é‡æ–°è®­ç»ƒï¼Ÿ

**åº”ç”¨åœºæ™¯**ï¼š
- åˆå¹¶å¤šä¸ªä¸“å®¶æ¨¡å‹ï¼ˆåŒ»ç–—+æ³•å¾‹+é‡‘èï¼‰
- èåˆå¼€æºç¤¾åŒºçš„ä¼˜ç§€å¾®è°ƒæ¨¡å‹
- å¿«é€Ÿæ„å»ºå¤šèƒ½åŠ›æ¨¡å‹

---

#### 5.1 çº¿æ€§æ’å€¼åˆå¹¶ï¼ˆWeight Averagingï¼‰

**æœ€ç®€å•æ–¹æ³•**ï¼šå¯¹ä¸¤ä¸ªæ¨¡å‹çš„æƒé‡è¿›è¡Œ**åŠ æƒå¹³å‡**ã€‚

```python
import torch
from transformers import AutoModelForCausalLM
from typing import List, Dict

class LinearMerger:
    """çº¿æ€§æ’å€¼åˆå¹¶å™¨"""
    
    def merge(
        self,
        model_paths: List[str],
        weights: List[float],
        output_path: str
    ):
        """
        çº¿æ€§åˆå¹¶å¤šä¸ªæ¨¡å‹
        
        Args:
            model_paths: æ¨¡å‹è·¯å¾„åˆ—è¡¨
            weights: æƒé‡åˆ—è¡¨ï¼ˆéœ€å½’ä¸€åŒ–ï¼Œå’Œä¸º1ï¼‰
            output_path: è¾“å‡ºè·¯å¾„
        """
        # éªŒè¯æƒé‡
        assert abs(sum(weights) - 1.0) < 1e-6, "æƒé‡ä¹‹å’Œå¿…é¡»ä¸º1"
        assert len(model_paths) == len(weights), "æ¨¡å‹æ•°é‡ä¸æƒé‡æ•°é‡ä¸åŒ¹é…"
        
        print(f"ğŸ”€ å¼€å§‹çº¿æ€§åˆå¹¶ {len(model_paths)} ä¸ªæ¨¡å‹...")
        
        # åŠ è½½ç¬¬ä¸€ä¸ªæ¨¡å‹ä½œä¸ºåŸºç¡€
        merged_model = AutoModelForCausalLM.from_pretrained(model_paths[0])
        merged_state_dict = merged_model.state_dict()
        
        # åˆå§‹åŒ–ä¸º0ï¼ˆå‡†å¤‡åŠ æƒæ±‚å’Œï¼‰
        for key in merged_state_dict.keys():
            merged_state_dict[key] = torch.zeros_like(merged_state_dict[key])
        
        # åŠ æƒæ±‚å’Œ
        for model_path, weight in zip(model_paths, weights):
            print(f"  â€¢ åŠ è½½ {model_path} (æƒé‡={weight})")
            
            model = AutoModelForCausalLM.from_pretrained(model_path)
            state_dict = model.state_dict()
            
            for key in merged_state_dict.keys():
                merged_state_dict[key] += weight * state_dict[key]
        
        # åŠ è½½åˆå¹¶åçš„æƒé‡
        merged_model.load_state_dict(merged_state_dict)
        
        # ä¿å­˜
        merged_model.save_pretrained(output_path)
        print(f"âœ“ åˆå¹¶å®Œæˆï¼Œå·²ä¿å­˜åˆ°: {output_path}")
        
        return merged_model


# ä½¿ç”¨ç¤ºä¾‹
merger = LinearMerger()

# åˆå¹¶3ä¸ªæ¨¡å‹ï¼šåŒ»ç–—(40%) + æ³•å¾‹(40%) + é‡‘è(20%)
merged_model = merger.merge(
    model_paths=[
        "./models/medical",
        "./models/legal",
        "./models/finance"
    ],
    weights=[0.4, 0.4, 0.2],
    output_path="./models/merged_linear"
)
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
ğŸ”€ å¼€å§‹çº¿æ€§åˆå¹¶ 3 ä¸ªæ¨¡å‹...
  â€¢ åŠ è½½ ./models/medical (æƒé‡=0.4)
  â€¢ åŠ è½½ ./models/legal (æƒé‡=0.4)
  â€¢ åŠ è½½ ./models/finance (æƒé‡=0.2)
âœ“ åˆå¹¶å®Œæˆï¼Œå·²ä¿å­˜åˆ°: ./models/merged_linear
```

**å±€é™æ€§**ï¼š
- âŒ æ— æ³•å¤„ç†ä»»åŠ¡å†²çªï¼ˆå¦‚ä¸åŒä»»åŠ¡ä¿®æ”¹äº†åŒä¸€å‚æ•°ï¼‰
- âŒ æ€§èƒ½é€šå¸¸ä½äºå•ç‹¬è®­ç»ƒçš„å¤šä»»åŠ¡æ¨¡å‹
- âœ… é€Ÿåº¦å¿«ã€å®ç°ç®€å•

---

#### 5.2 SLERPï¼ˆSpherical Linear Interpolationï¼‰

**æ ¸å¿ƒæ€æƒ³**ï¼šåœ¨**çƒé¢ç©ºé—´**è¿›è¡Œæ’å€¼ï¼Œä¿æŒæƒé‡å‘é‡çš„æ¨¡é•¿ã€‚

**æ•°å­¦åŸç†**ï¼š
```
Î¸ = arccos(Î¸â‚ Â· Î¸â‚‚)
SLERP(Î¸â‚, Î¸â‚‚, t) = sin((1-t)Î¸)/sin(Î¸) Â· Î¸â‚ + sin(tÎ¸)/sin(Î¸) Â· Î¸â‚‚
```

```python
import torch
import math

class SLERPMerger:
    """SLERPçƒé¢æ’å€¼åˆå¹¶å™¨"""
    
    def slerp(
        self,
        v1: torch.Tensor,
        v2: torch.Tensor,
        t: float,
        eps: float = 1e-8
    ) -> torch.Tensor:
        """
        çƒé¢çº¿æ€§æ’å€¼
        
        Args:
            v1, v2: ä¸¤ä¸ªå‘é‡
            t: æ’å€¼ç³»æ•° [0, 1]
            eps: æ•°å€¼ç¨³å®šæ€§é˜ˆå€¼
        """
        # å½’ä¸€åŒ–
        v1_norm = v1 / (v1.norm() + eps)
        v2_norm = v2 / (v2.norm() + eps)
        
        # è®¡ç®—å¤¹è§’
        dot = (v1_norm * v2_norm).sum()
        dot = torch.clamp(dot, -1.0, 1.0)  # é˜²æ­¢æ•°å€¼è¯¯å·®
        theta = torch.acos(dot)
        
        # å¦‚æœå‘é‡å‡ ä¹å¹³è¡Œï¼Œé€€åŒ–ä¸ºçº¿æ€§æ’å€¼
        if theta.abs() < eps:
            return (1 - t) * v1 + t * v2
        
        # SLERPå…¬å¼
        sin_theta = torch.sin(theta)
        w1 = torch.sin((1 - t) * theta) / sin_theta
        w2 = torch.sin(t * theta) / sin_theta
        
        return w1 * v1 + w2 * v2
    
    def merge(
        self,
        model1_path: str,
        model2_path: str,
        t: float,
        output_path: str
    ):
        """
        SLERPåˆå¹¶ä¸¤ä¸ªæ¨¡å‹
        
        Args:
            model1_path, model2_path: ä¸¤ä¸ªæ¨¡å‹è·¯å¾„
            t: æ’å€¼ç³»æ•°ï¼Œ0=å®Œå…¨ä½¿ç”¨model1, 1=å®Œå…¨ä½¿ç”¨model2
            output_path: è¾“å‡ºè·¯å¾„
        """
        print(f"ğŸŒ å¼€å§‹SLERPåˆå¹¶ (t={t})...")
        
        # åŠ è½½æ¨¡å‹
        model1 = AutoModelForCausalLM.from_pretrained(model1_path)
        model2 = AutoModelForCausalLM.from_pretrained(model2_path)
        
        state_dict1 = model1.state_dict()
        state_dict2 = model2.state_dict()
        
        # åˆå¹¶åçš„state_dict
        merged_state_dict = {}
        
        for key in state_dict1.keys():
            w1 = state_dict1[key]
            w2 = state_dict2[key]
            
            # å±•å¹³ä¸ºå‘é‡è¿›è¡ŒSLERP
            w1_flat = w1.flatten()
            w2_flat = w2.flatten()
            
            merged_flat = self.slerp(w1_flat, w2_flat, t)
            
            # æ¢å¤åŸå§‹å½¢çŠ¶
            merged_state_dict[key] = merged_flat.reshape(w1.shape)
        
        # åŠ è½½åˆå¹¶æƒé‡
        merged_model = AutoModelForCausalLM.from_pretrained(model1_path)
        merged_model.load_state_dict(merged_state_dict)
        
        # ä¿å­˜
        merged_model.save_pretrained(output_path)
        print(f"âœ“ SLERPåˆå¹¶å®Œæˆï¼Œå·²ä¿å­˜åˆ°: {output_path}")
        
        return merged_model


# ä½¿ç”¨ç¤ºä¾‹
slerp_merger = SLERPMerger()

# åˆå¹¶åŒ»ç–—æ¨¡å‹å’Œæ³•å¾‹æ¨¡å‹ï¼ˆå„å 50%ï¼‰
merged_model = slerp_merger.merge(
    model1_path="./models/medical",
    model2_path="./models/legal",
    t=0.5,  # 50-50æ··åˆ
    output_path="./models/merged_slerp"
)
```

**SLERP vs çº¿æ€§æ’å€¼å¯¹æ¯”**ï¼š

| æ–¹æ³• | æƒé‡ç©ºé—´ | æ¨¡é•¿ä¿æŒ | é€‚ç”¨åœºæ™¯ |
|-----|---------|---------|---------|
| çº¿æ€§æ’å€¼ | æ¬§æ°ç©ºé—´ | âŒ å¦ | ç›¸ä¼¼ä»»åŠ¡ |
| SLERP | çƒé¢ç©ºé—´ | âœ… æ˜¯ | å·®å¼‚ä»»åŠ¡ï¼Œä¿æŒè¡¨è¾¾èƒ½åŠ› |

---

#### 5.3 TIESï¼ˆTrIm, Elect Sign & Mergeï¼‰

**æ ¸å¿ƒåˆ›æ–°**ï¼šè§£å†³ä»»åŠ¡å†²çªçš„**ä¸‰æ­¥æ³•**ã€‚

**ç®—æ³•æ­¥éª¤**ï¼š

1. **Trimï¼ˆä¿®å‰ªï¼‰**ï¼šå»é™¤ä¸é‡è¦çš„å‚æ•°å˜åŒ–
2. **Elect Signï¼ˆç¬¦å·é€‰ä¸¾ï¼‰**ï¼šè§£å†³å‚æ•°æ›´æ–°æ–¹å‘å†²çª
3. **Mergeï¼ˆåˆå¹¶ï¼‰**ï¼šæŒ‰é€‰å®šç¬¦å·åˆå¹¶å‚æ•°

```python
import torch
from typing import List, Dict
from collections import defaultdict

class TIESMerger:
    """TIESåˆå¹¶å™¨"""
    
    def __init__(self, trim_ratio: float = 0.2):
        """
        Args:
            trim_ratio: ä¿®å‰ªæ¯”ä¾‹ï¼Œå»é™¤å‰20%æœ€å°çš„å‚æ•°å˜åŒ–
        """
        self.trim_ratio = trim_ratio
    
    def merge(
        self,
        base_model_path: str,
        finetuned_model_paths: List[str],
        output_path: str
    ):
        """
        TIESåˆå¹¶å¤šä¸ªå¾®è°ƒæ¨¡å‹
        
        Args:
            base_model_path: åŸºåº§æ¨¡å‹è·¯å¾„
            finetuned_model_paths: å¾®è°ƒæ¨¡å‹è·¯å¾„åˆ—è¡¨
            output_path: è¾“å‡ºè·¯å¾„
        """
        print(f"ğŸ”— å¼€å§‹TIESåˆå¹¶ {len(finetuned_model_paths)} ä¸ªæ¨¡å‹...")
        
        # åŠ è½½åŸºåº§æ¨¡å‹
        base_model = AutoModelForCausalLM.from_pretrained(base_model_path)
        base_state = base_model.state_dict()
        
        # è®¡ç®—æ¯ä¸ªæ¨¡å‹çš„deltaï¼ˆå˜åŒ–é‡ï¼‰
        deltas = []
        for path in finetuned_model_paths:
            print(f"  â€¢ è®¡ç®— {path} çš„delta...")
            model = AutoModelForCausalLM.from_pretrained(path)
            state = model.state_dict()
            
            delta = {}
            for key in base_state.keys():
                delta[key] = state[key] - base_state[key]
            deltas.append(delta)
        
        # Step 1: Trimï¼ˆä¿®å‰ªä¸é‡è¦çš„å˜åŒ–ï¼‰
        print(f"  ğŸ“Œ Step 1: Trim (ä¿®å‰ªæ¯”ä¾‹={self.trim_ratio})")
        trimmed_deltas = self._trim(deltas)
        
        # Step 2: Elect Signï¼ˆç¬¦å·é€‰ä¸¾ï¼‰
        print(f"  ğŸ—³ï¸  Step 2: Elect Sign (ç¬¦å·é€‰ä¸¾)")
        elected_signs = self._elect_sign(trimmed_deltas)
        
        # Step 3: Mergeï¼ˆåˆå¹¶ï¼‰
        print(f"  ğŸ”€ Step 3: Merge (æŒ‰ç¬¦å·åˆå¹¶)")
        merged_delta = self._merge_with_sign(trimmed_deltas, elected_signs)
        
        # åº”ç”¨åˆ°åŸºåº§æ¨¡å‹
        merged_state = {}
        for key in base_state.keys():
            merged_state[key] = base_state[key] + merged_delta[key]
        
        # åŠ è½½å¹¶ä¿å­˜
        merged_model = AutoModelForCausalLM.from_pretrained(base_model_path)
        merged_model.load_state_dict(merged_state)
        merged_model.save_pretrained(output_path)
        
        print(f"âœ“ TIESåˆå¹¶å®Œæˆï¼Œå·²ä¿å­˜åˆ°: {output_path}")
        return merged_model
    
    def _trim(self, deltas: List[Dict]) -> List[Dict]:
        """Step 1: ä¿®å‰ªä¸é‡è¦çš„å‚æ•°å˜åŒ–"""
        trimmed_deltas = []
        
        for delta in deltas:
            trimmed_delta = {}
            for key, value in delta.items():
                # è®¡ç®—é˜ˆå€¼ï¼ˆä¿ç•™top (1-trim_ratio) çš„å˜åŒ–ï¼‰
                abs_values = value.abs().flatten()
                threshold = torch.quantile(abs_values, self.trim_ratio)
                
                # å°äºé˜ˆå€¼çš„ç½®é›¶
                mask = value.abs() >= threshold
                trimmed_delta[key] = value * mask
            
            trimmed_deltas.append(trimmed_delta)
        
        return trimmed_deltas
    
    def _elect_sign(self, deltas: List[Dict]) -> Dict:
        """Step 2: ç¬¦å·é€‰ä¸¾ï¼ˆå¤šæ•°æŠ•ç¥¨ï¼‰"""
        elected_signs = {}
        
        # è·å–æ‰€æœ‰å‚æ•°key
        keys = deltas[0].keys()
        
        for key in keys:
            # ç»Ÿè®¡æ¯ä¸ªä½ç½®çš„æ­£è´Ÿç¬¦å·
            stacked = torch.stack([d[key] for d in deltas])
            
            # æŠ•ç¥¨ï¼šæ­£æ•°+1ï¼Œè´Ÿæ•°-1ï¼Œ0ä¸æŠ•ç¥¨
            votes = torch.sign(stacked).sum(dim=0)
            
            # é€‰å‡ºå¤šæ•°ç¬¦å·
            elected_signs[key] = torch.sign(votes)
        
        return elected_signs
    
    def _merge_with_sign(
        self,
        deltas: List[Dict],
        elected_signs: Dict
    ) -> Dict:
        """Step 3: æŒ‰é€‰å®šç¬¦å·åˆå¹¶"""
        merged_delta = {}
        
        for key in deltas[0].keys():
            sign = elected_signs[key]
            
            # åªä¿ç•™ä¸é€‰å®šç¬¦å·ä¸€è‡´çš„å˜åŒ–
            aligned_deltas = []
            for delta in deltas:
                # ç¬¦å·ä¸€è‡´çš„ä¿ç•™ï¼Œä¸ä¸€è‡´çš„ç½®é›¶
                mask = torch.sign(delta[key]) == sign
                aligned = delta[key] * mask
                aligned_deltas.append(aligned)
            
            # å¹³å‡
            merged_delta[key] = torch.stack(aligned_deltas).mean(dim=0)
        
        return merged_delta


# ä½¿ç”¨ç¤ºä¾‹
ties_merger = TIESMerger(trim_ratio=0.2)

# åˆå¹¶3ä¸ªé¢†åŸŸä¸“å®¶æ¨¡å‹
merged_model = ties_merger.merge(
    base_model_path="meta-llama/Llama-2-7b-hf",
    finetuned_model_paths=[
        "./models/medical",
        "./models/legal",
        "./models/finance"
    ],
    output_path="./models/merged_ties"
)
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
ğŸ”— å¼€å§‹TIESåˆå¹¶ 3 ä¸ªæ¨¡å‹...
  â€¢ è®¡ç®— ./models/medical çš„delta...
  â€¢ è®¡ç®— ./models/legal çš„delta...
  â€¢ è®¡ç®— ./models/finance çš„delta...
  ğŸ“Œ Step 1: Trim (ä¿®å‰ªæ¯”ä¾‹=0.2)
  ğŸ—³ï¸  Step 2: Elect Sign (ç¬¦å·é€‰ä¸¾)
  ğŸ”€ Step 3: Merge (æŒ‰ç¬¦å·åˆå¹¶)
âœ“ TIESåˆå¹¶å®Œæˆï¼Œå·²ä¿å­˜åˆ°: ./models/merged_ties
```

---

#### 5.4 DAREï¼ˆDrop And REscaleï¼‰

**æ ¸å¿ƒæ€æƒ³**ï¼š**éšæœºä¸¢å¼ƒä¸€éƒ¨åˆ†å‚æ•°å˜åŒ–**ï¼Œç„¶åé‡æ–°ç¼©æ”¾ï¼Œå¢åŠ é²æ£’æ€§ã€‚

```python
import torch
import random

class DAREMerger:
    """DAREåˆå¹¶å™¨"""
    
    def __init__(self, drop_rate: float = 0.9):
        """
        Args:
            drop_rate: ä¸¢å¼ƒç‡ï¼Œ90%çš„å‚æ•°å˜åŒ–ä¼šè¢«éšæœºä¸¢å¼ƒ
        """
        self.drop_rate = drop_rate
    
    def merge(
        self,
        base_model_path: str,
        finetuned_model_paths: List[str],
        output_path: str
    ):
        """DAREåˆå¹¶"""
        print(f"ğŸ² å¼€å§‹DAREåˆå¹¶ (drop_rate={self.drop_rate})...")
        
        # åŠ è½½åŸºåº§æ¨¡å‹
        base_model = AutoModelForCausalLM.from_pretrained(base_model_path)
        base_state = base_model.state_dict()
        
        # è®¡ç®—deltaså¹¶åº”ç”¨DARE
        dare_deltas = []
        for path in finetuned_model_paths:
            print(f"  â€¢ å¤„ç† {path}...")
            model = AutoModelForCausalLM.from_pretrained(path)
            state = model.state_dict()
            
            # è®¡ç®—delta
            delta = {}
            for key in base_state.keys():
                delta[key] = state[key] - base_state[key]
            
            # åº”ç”¨DAREï¼ˆéšæœºä¸¢å¼ƒ + é‡ç¼©æ”¾ï¼‰
            dare_delta = self._apply_dare(delta)
            dare_deltas.append(dare_delta)
        
        # å¹³å‡åˆå¹¶
        merged_delta = {}
        for key in base_state.keys():
            stacked = torch.stack([d[key] for d in dare_deltas])
            merged_delta[key] = stacked.mean(dim=0)
        
        # åº”ç”¨åˆ°åŸºåº§æ¨¡å‹
        merged_state = {}
        for key in base_state.keys():
            merged_state[key] = base_state[key] + merged_delta[key]
        
        # ä¿å­˜
        merged_model = AutoModelForCausalLM.from_pretrained(base_model_path)
        merged_model.load_state_dict(merged_state)
        merged_model.save_pretrained(output_path)
        
        print(f"âœ“ DAREåˆå¹¶å®Œæˆï¼Œå·²ä¿å­˜åˆ°: {output_path}")
        return merged_model
    
    def _apply_dare(self, delta: Dict) -> Dict:
        """åº”ç”¨DAREï¼šéšæœºä¸¢å¼ƒ + é‡ç¼©æ”¾"""
        dare_delta = {}
        
        for key, value in delta.items():
            # ç”Ÿæˆéšæœºmaskï¼ˆä¿ç•™æ¦‚ç‡ = 1 - drop_rateï¼‰
            keep_prob = 1 - self.drop_rate
            mask = torch.bernoulli(
                torch.full_like(value, keep_prob, dtype=torch.float)
            ).bool()
            
            # ä¿ç•™çš„å‚æ•° / (1 - drop_rate) è¿›è¡Œé‡ç¼©æ”¾
            dare_delta[key] = value * mask / keep_prob
        
        return dare_delta


# ä½¿ç”¨ç¤ºä¾‹
dare_merger = DAREMerger(drop_rate=0.9)

merged_model = dare_merger.merge(
    base_model_path="meta-llama/Llama-2-7b-hf",
    finetuned_model_paths=[
        "./models/medical",
        "./models/legal",
        "./models/finance"
    ],
    output_path="./models/merged_dare"
)
```

**DAREåŸç†**ï¼š

1. **Drop**ï¼šéšæœºä¸¢å¼ƒ90%å‚æ•°å˜åŒ–ï¼ˆç±»ä¼¼Dropoutï¼‰
2. **REscale**ï¼šä¿ç•™çš„10%å‚æ•°Ã—10ï¼Œä¿æŒæœŸæœ›ä¸å˜
3. **æ•ˆæœ**ï¼šå¢åŠ é²æ£’æ€§ï¼Œå‡å°‘è¿‡æ‹Ÿåˆ

---

#### 5.5 Task Arithmeticï¼ˆä»»åŠ¡ç®—æœ¯ï¼‰

**æ ¸å¿ƒæ€æƒ³**ï¼šå°†ä»»åŠ¡è§†ä¸º**å‘é‡**ï¼Œæ”¯æŒåŠ å‡ä¹˜é™¤è¿ç®—ã€‚

**å…¬å¼**ï¼š
```
ä»»åŠ¡å‘é‡ Ï„ = Î¸_finetuned - Î¸_base
æ–°æ¨¡å‹ = Î¸_base + Î»â‚Â·Ï„â‚ + Î»â‚‚Â·Ï„â‚‚ + ...
```

```python
class TaskArithmeticMerger:
    """ä»»åŠ¡ç®—æœ¯åˆå¹¶å™¨"""
    
    def compute_task_vector(
        self,
        base_model_path: str,
        finetuned_model_path: str
    ) -> Dict:
        """è®¡ç®—ä»»åŠ¡å‘é‡ Ï„ = Î¸_ft - Î¸_base"""
        base_model = AutoModelForCausalLM.from_pretrained(base_model_path)
        ft_model = AutoModelForCausalLM.from_pretrained(finetuned_model_path)
        
        base_state = base_model.state_dict()
        ft_state = ft_model.state_dict()
        
        task_vector = {}
        for key in base_state.keys():
            task_vector[key] = ft_state[key] - base_state[key]
        
        return task_vector
    
    def add_task_vectors(
        self,
        base_model_path: str,
        task_vectors: List[Dict],
        coefficients: List[float],
        output_path: str
    ):
        """
        ä»»åŠ¡å‘é‡åŠ æ³•ï¼šÎ¸_new = Î¸_base + Î£ Î»áµ¢Â·Ï„áµ¢
        
        Args:
            base_model_path: åŸºåº§æ¨¡å‹
            task_vectors: ä»»åŠ¡å‘é‡åˆ—è¡¨
            coefficients: ç³»æ•°åˆ—è¡¨ Î»áµ¢
            output_path: è¾“å‡ºè·¯å¾„
        """
        print(f"â• ä»»åŠ¡ç®—æœ¯ï¼šåˆå¹¶ {len(task_vectors)} ä¸ªä»»åŠ¡å‘é‡...")
        
        # åŠ è½½åŸºåº§æ¨¡å‹
        base_model = AutoModelForCausalLM.from_pretrained(base_model_path)
        base_state = base_model.state_dict()
        
        # åŠ æƒæ±‚å’Œä»»åŠ¡å‘é‡
        combined_vector = {}
        for key in base_state.keys():
            combined_vector[key] = torch.zeros_like(base_state[key])
            
            for task_vec, coef in zip(task_vectors, coefficients):
                combined_vector[key] += coef * task_vec[key]
        
        # åº”ç”¨åˆ°åŸºåº§æ¨¡å‹
        new_state = {}
        for key in base_state.keys():
            new_state[key] = base_state[key] + combined_vector[key]
        
        # ä¿å­˜
        new_model = AutoModelForCausalLM.from_pretrained(base_model_path)
        new_model.load_state_dict(new_state)
        new_model.save_pretrained(output_path)
        
        print(f"âœ“ ä»»åŠ¡ç®—æœ¯å®Œæˆï¼Œå·²ä¿å­˜åˆ°: {output_path}")
        return new_model
    
    def negate_task(self, task_vector: Dict) -> Dict:
        """ä»»åŠ¡å‘é‡å–åï¼šæ¶ˆé™¤æŸä¸ªèƒ½åŠ›"""
        negated = {}
        for key, value in task_vector.items():
            negated[key] = -value
        return negated


# ä½¿ç”¨ç¤ºä¾‹
ta_merger = TaskArithmeticMerger()

# è®¡ç®—ä»»åŠ¡å‘é‡
base_path = "meta-llama/Llama-2-7b-hf"
medical_vec = ta_merger.compute_task_vector(base_path, "./models/medical")
legal_vec = ta_merger.compute_task_vector(base_path, "./models/legal")
finance_vec = ta_merger.compute_task_vector(base_path, "./models/finance")

# ä»»åŠ¡ç®—æœ¯ï¼šå¢å¼ºåŒ»ç–—å’Œæ³•å¾‹ï¼Œå‡å¼±é‡‘è
merged_model = ta_merger.add_task_vectors(
    base_model_path=base_path,
    task_vectors=[medical_vec, legal_vec, finance_vec],
    coefficients=[1.2, 1.2, -0.5],  # åŒ»ç–—Ã—1.2 + æ³•å¾‹Ã—1.2 - é‡‘èÃ—0.5
    output_path="./models/merged_arithmetic"
)

print("\nğŸ’¡ ä»»åŠ¡ç®—æœ¯ç¤ºä¾‹:")
print("  â€¢ åŒ»ç–—èƒ½åŠ› Ã— 1.2ï¼ˆå¢å¼ºï¼‰")
print("  â€¢ æ³•å¾‹èƒ½åŠ› Ã— 1.2ï¼ˆå¢å¼ºï¼‰")
print("  â€¢ é‡‘èèƒ½åŠ› Ã— -0.5ï¼ˆå‡å¼±/æ¶ˆé™¤ï¼‰")
```

**ä»»åŠ¡ç®—æœ¯çš„å¼ºå¤§ä¹‹å¤„**ï¼š

| æ“ä½œ | å…¬å¼ | æ•ˆæœ |
|-----|------|------|
| **å¢å¼º** | Î¸ + 1.5Â·Ï„ | å¼ºåŒ–æŸä¸ªä»»åŠ¡ |
| **å‡å¼±** | Î¸ + 0.3Â·Ï„ | è½»å¾®æ·»åŠ èƒ½åŠ› |
| **æ¶ˆé™¤** | Î¸ - Ï„ | å»é™¤æŸä¸ªä»»åŠ¡å½±å“ |
| **ç»„åˆ** | Î¸ + Ï„â‚ + Ï„â‚‚ | èåˆå¤šä¸ªä»»åŠ¡ |

---

#### 5.6 åˆå¹¶æ–¹æ³•å¯¹æ¯”ä¸é€‰æ‹©

**æ€§èƒ½å¯¹æ¯”å®éªŒ**ï¼ˆ7Bæ¨¡å‹ï¼Œ3ä»»åŠ¡åˆå¹¶ï¼‰ï¼š

| æ–¹æ³• | å¹³å‡å‡†ç¡®ç‡ | åˆå¹¶æ—¶é—´ | æ˜¾å­˜å ç”¨ | é€‚ç”¨åœºæ™¯ |
|-----|-----------|---------|---------|---------|
| çº¿æ€§æ’å€¼ | 78.5% | 5åˆ†é’Ÿ | 14GB | å¿«é€ŸåŸå‹ |
| SLERP | 81.2% | 8åˆ†é’Ÿ | 14GB | ä»»åŠ¡å·®å¼‚å¤§ |
| TIES | 85.3% | 15åˆ†é’Ÿ | 21GB | æœ‰ä»»åŠ¡å†²çª |
| DARE | 84.1% | 12åˆ†é’Ÿ | 18GB | éœ€è¦é²æ£’æ€§ |
| Task Arithmetic | 86.7% | 10åˆ†é’Ÿ | 18GB | çµæ´»è°ƒæ•´èƒ½åŠ› |

**é€‰æ‹©æŒ‡å—**ï¼š

```python
def recommend_merge_method(
    num_models: int,
    task_similarity: str,  # "high", "medium", "low"
    has_conflict: bool,
    need_flexibility: bool
) -> str:
    """æ¨èåˆå¹¶æ–¹æ³•"""
    
    if num_models == 2 and task_similarity == "high":
        return "çº¿æ€§æ’å€¼ï¼ˆæœ€å¿«ï¼‰"
    
    if task_similarity == "low":
        return "SLERPï¼ˆä¿æŒè¡¨è¾¾èƒ½åŠ›ï¼‰"
    
    if has_conflict:
        return "TIESï¼ˆè§£å†³å†²çªï¼‰"
    
    if need_flexibility:
        return "Task Arithmeticï¼ˆçµæ´»è°ƒæ•´ï¼‰"
    
    return "DAREï¼ˆå¹³è¡¡æ€§èƒ½ä¸é²æ£’æ€§ï¼‰"


# ä½¿ç”¨ç¤ºä¾‹
method = recommend_merge_method(
    num_models=3,
    task_similarity="medium",
    has_conflict=True,
    need_flexibility=False
)
print(f"æ¨èæ–¹æ³•: {method}")
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
æ¨èæ–¹æ³•: TIESï¼ˆè§£å†³å†²çªï¼‰
```

---

**ç¬¬äº”èŠ‚å°ç»“**ï¼š

æ¨¡å‹åˆå¹¶æŠ€æœ¯è®©æˆ‘ä»¬èƒ½å¤Ÿï¼š

1. **å¿«é€Ÿæ„å»ºå¤šèƒ½åŠ›æ¨¡å‹**ï¼ˆæ— éœ€é‡æ–°è®­ç»ƒï¼‰
2. **çµæ´»è°ƒæ•´èƒ½åŠ›ç»„åˆ**ï¼ˆTask Arithmeticï¼‰
3. **è§£å†³ä»»åŠ¡å†²çª**ï¼ˆTIESï¼‰
4. **ä¿æŒé²æ£’æ€§**ï¼ˆDAREï¼‰

**å®æˆ˜å»ºè®®**ï¼š

- åˆæ¬¡å°è¯•ï¼šçº¿æ€§æ’å€¼
- ç”Ÿäº§ç¯å¢ƒï¼šTIESæˆ–Task Arithmetic
- ç ”ç©¶æ¢ç´¢ï¼šTask Arithmeticï¼ˆæ”¯æŒåŠ å‡è¿ç®—ï¼‰

---

## ğŸ’¡ æ–°æ‰‹é—®ç­”ï¼šä»å›°æƒ‘åˆ°ç†è§£

> æœ¬èŠ‚è§£ç­”å¾®è°ƒè¿‡ç¨‹ä¸­æœ€å¸¸é‡åˆ°çš„6ä¸ªæ ¸å¿ƒå›°æƒ‘ï¼Œå¸®åŠ©ä½ å»ºç«‹æ­£ç¡®çš„ç›´è§‰ã€‚

---

### é—®é¢˜1ï¼šLoRAå’Œå…¨é‡å¾®è°ƒåˆ°åº•å·®åœ¨å“ªï¼Ÿä»€ä¹ˆæ—¶å€™å¿…é¡»ç”¨å…¨é‡å¾®è°ƒï¼Ÿ

**æ–°æ‰‹å›°æƒ‘**ï¼š

"æˆ‘çœ‹åˆ°å¾ˆå¤šæ•™ç¨‹è¯´LoRAæ€§èƒ½æ¥è¿‘å…¨é‡å¾®è°ƒ,ä½†ä¹Ÿæœ‰äººè¯´å…³é”®ä»»åŠ¡å¿…é¡»å…¨é‡å¾®è°ƒã€‚åˆ°åº•å·®åœ¨å“ª?"

**æœ¬è´¨å·®å¼‚ï¼ˆç”¨è£…ä¿®åšæ¯”å–»ï¼‰**ï¼š

**å…¨é‡å¾®è°ƒ = æ‹†æ‰æ•´æ ‹æˆ¿å­é‡å»º**
- å¯ä»¥æ”¹å˜ä¸€åˆ‡ï¼ˆå¢™ä½“ã€ç»“æ„ã€å¸ƒå±€ï¼‰
- æˆæœ¬é«˜ã€é£é™©å¤§ï¼ˆå¯èƒ½æŸååŸæœ‰ä»·å€¼ï¼‰
- ä½†æœ€ç»ˆæ•ˆæœæœ€ä¼˜

**LoRA = åœ¨æˆ¿å­é‡ŒåŠ è£…å®¶å…·å’Œè£…é¥°**
- åªèƒ½æ”¹å˜è¡¨é¢ï¼ˆå¢™çº¸ã€å®¶å…·ã€ç¯å…‰ï¼‰
- æˆæœ¬ä½ã€é£é™©å°ï¼ˆä¿ç•™åŸæœ‰ä»·å€¼ï¼‰
- å¤§å¤šæ•°æƒ…å†µä¸‹è¶³å¤Ÿå¥½

**å®éªŒæ•°æ®å¯¹æ¯”ï¼ˆLLaMA-7Bï¼ŒåŒ»ç–—é—®ç­”ä»»åŠ¡ï¼‰**ï¼š

| æŒ‡æ ‡ | å…¨é‡å¾®è°ƒ | LoRA r=8 | LoRA r=16 | å·®è· |
|-----|---------|----------|-----------|-----|
| å‡†ç¡®ç‡ | 94.2% | 92.8% | 93.5% | -1.4% |
| è®­ç»ƒæ—¶é—´ | 8å°æ—¶ | 3å°æ—¶ | 4å°æ—¶ | å‡å°‘62% |
| æ˜¾å­˜éœ€æ±‚ | 84GB | 16GB | 18GB | å‡å°‘81% |
| é—å¿˜ç‡ | 25% | 8% | 10% | å‡å°‘60% |
| å­˜å‚¨æˆæœ¬ | 13GB/ä»»åŠ¡ | 25MB/ä»»åŠ¡ | 50MB/ä»»åŠ¡ | å‡å°‘99.8% |

**å†³ç­–æ ‘ï¼šä»€ä¹ˆæ—¶å€™å¿…é¡»å…¨é‡å¾®è°ƒ?**

```
ä»»åŠ¡æ˜¯å¦å®‰å…¨å…³é”®ï¼ˆåŒ»ç–—è¯Šæ–­ã€è‡ªåŠ¨é©¾é©¶ï¼‰?
â”œâ”€ æ˜¯ â†’ æ€§èƒ½å·®è·ä¸å¯æ¥å— â†’ å…¨é‡å¾®è°ƒ
â””â”€ å¦ â†’ ç»§ç»­

æ€§èƒ½è¦æ±‚æ˜¯å¦æè‡´ï¼ˆéœ€è¦99.5%+ å‡†ç¡®ç‡ï¼‰?
â”œâ”€ æ˜¯ â†’ LoRAå¯èƒ½å·®1-2% â†’ å…¨é‡å¾®è°ƒ
â””â”€ å¦ â†’ ç»§ç»­

é¢„ç®—æ˜¯å¦å……è¶³ï¼ˆ>10ä¸‡ç¾å…ƒè®­ç»ƒæˆæœ¬ï¼‰?
â”œâ”€ å¦ â†’ ç”¨LoRA
â””â”€ æ˜¯ â†’ ç»§ç»­

æ•°æ®é‡æ˜¯å¦>100ä¸‡æ¡ä¸”è´¨é‡æé«˜?
â”œâ”€ æ˜¯ â†’ å…¨é‡å¾®è°ƒå¯èƒ½æœ‰é¢å¤–æ”¶ç›Š
â””â”€ å¦ â†’ LoRAè¶³å¤Ÿ

ä»»åŠ¡æ˜¯å¦éœ€è¦æ”¹å˜æ¨¡å‹åº•å±‚è¡¨ç¤ºï¼ˆå¦‚è·¨è¯­è¨€è¿ç§»ï¼‰?
â”œâ”€ æ˜¯ â†’ å…¨é‡å¾®è°ƒï¼ˆLoRAæ— æ³•æ”¹å˜åº•å±‚ç‰¹å¾ï¼‰
â””â”€ å¦ â†’ LoRA

æœ€ç»ˆæ¨èï¼šLoRA âœ…
```

**çœŸå®æ¡ˆä¾‹**ï¼š

**æ¡ˆä¾‹1ï¼šåŒ»ç–—è¯Šæ–­æ¨¡å‹**ï¼ˆæŸä¸‰ç”²åŒ»é™¢ï¼‰
- **å°è¯•**ï¼šLoRA r=16, æ•°æ®é‡2ä¸‡æ¡
- **ç»“æœ**ï¼šå‡†ç¡®ç‡92.1%ï¼Œä½†åŒ»ç”Ÿè¦æ±‚>95%
- **è§£å†³**ï¼šå…¨é‡å¾®è°ƒ â†’ 96.3%
- **æˆæœ¬**ï¼šè®­ç»ƒ8å¤©ï¼ŒA100Ã—8ï¼Œçº¦3ä¸‡ç¾å…ƒ
- **ç»“è®º**ï¼šå€¼å¾—ï¼Œå› ä¸ºå…³ä¹ç”Ÿå‘½

**æ¡ˆä¾‹2ï¼šå®¢æœèŠå¤©æœºå™¨äºº**ï¼ˆæŸç”µå•†å…¬å¸ï¼‰
- **å°è¯•**ï¼šå…¨é‡å¾®è°ƒï¼Œ10ä¸ªéƒ¨é—¨å„ä¸€ä¸ªæ¨¡å‹
- **é—®é¢˜**ï¼šæ¯ä¸ªéƒ¨é—¨éœ€è¦13GBå­˜å‚¨ï¼Œæˆæœ¬130GB
- **è§£å†³**ï¼šLoRA â†’ æ¯ä¸ªéƒ¨é—¨25MBé€‚é…å™¨
- **æ”¶ç›Š**ï¼šèŠ‚çœ99.8%å­˜å‚¨æˆæœ¬ + æ¨ç†æ—¶å¯åŠ¨æ€åˆ‡æ¢
- **ç»“è®º**ï¼šLoRAå®Œèƒœ

**å…³è”å»ºè®®**ï¼š

å¦‚æœLoRAæ•ˆæœä¸å¤Ÿå¥½ï¼Œä¸è¦ç«‹åˆ»å…¨é‡å¾®è°ƒï¼ŒæŒ‰ä¼˜å…ˆçº§å°è¯•ï¼š
1. å¢å¤§ç§©rï¼ˆ8â†’16â†’32ï¼‰
2. å°è¯•DoRAï¼ˆé€šå¸¸+2-4%æ€§èƒ½ï¼‰
3. å¢åŠ ç›®æ ‡æ¨¡å—ï¼ˆq_proj,v_proj â†’ å…¨éƒ¨æ³¨æ„åŠ›å±‚ï¼‰
4. æ”¹è¿›æ•°æ®è´¨é‡ï¼ˆè€Œéæ•°é‡ï¼‰
5. æœ€åæ‰è€ƒè™‘å…¨é‡å¾®è°ƒ

---

### é—®é¢˜2ï¼šä¸ºä»€ä¹ˆæœ‰äººè¯´LoRAä¼š"é—å¿˜"é¢„è®­ç»ƒçŸ¥è¯†ï¼Ÿ

**æ–°æ‰‹å›°æƒ‘**ï¼š

"å¬è¯´å¾®è°ƒä¼šè®©æ¨¡å‹'é—å¿˜'åŸæ¥çš„èƒ½åŠ›ï¼Œæ¯”å¦‚å¾®è°ƒå¯¹è¯åä»£ç èƒ½åŠ›å°±é€€åŒ–äº†ã€‚è¿™æ˜¯ä¸ºä»€ä¹ˆï¼ŸLoRAä¸æ˜¯åº”è¯¥æ›´å®‰å…¨å—ï¼Ÿ"

**ä»€ä¹ˆæ˜¯ç¾éš¾æ€§é—å¿˜ï¼Ÿï¼ˆç”¨ç”Ÿæ´»ä¾‹å­ï¼‰**

æƒ³è±¡ä½ æ˜¯ä¸ªå¨å¸ˆï¼š
- **é¢„è®­ç»ƒ**ï¼šå­¦ä¼šäº†åš100é“èœï¼ˆä¸­é¤ã€è¥¿é¤ã€çƒ˜ç„™ï¼‰
- **å¾®è°ƒ**ï¼šè€æ¿è¦æ±‚ä¸“é—¨ç»ƒä¹ åšå¯¿å¸
- **é—å¿˜**ï¼šç»ƒäº†1ä¸ªæœˆå¯¿å¸åï¼Œå‘ç°ä¹‹å‰çš„å·èœæ‰‹è‰ºç”Ÿç–äº†

è¿™å°±æ˜¯**ç¾éš¾æ€§é—å¿˜**ï¼ˆCatastrophic Forgettingï¼‰ï¼šæ–°ä»»åŠ¡è®­ç»ƒä¼šè¦†ç›–æ—§çŸ¥è¯†ã€‚

**æ•°å­¦æœ¬è´¨ï¼ˆæŠ€æœ¯è§£é‡Šï¼‰**ï¼š

ç¥ç»ç½‘ç»œé€šè¿‡è°ƒæ•´æƒé‡ $\theta$ æ¥å­¦ä¹ ã€‚æ¯ä¸ªä»»åŠ¡å¯¹åº”ä¸€ä¸ªæŸå¤±å‡½æ•° $\mathcal{L}$ï¼š

```
é¢„è®­ç»ƒï¼šæ‰¾åˆ° Î¸* ä½¿å¾— L_pretrain(Î¸*) æœ€å°
å¾®è°ƒï¼š  æ‰¾åˆ° Î¸' ä½¿å¾— L_finetune(Î¸') æœ€å°
```

é—®é¢˜ï¼š$\theta'$ å¯èƒ½è¿œç¦» $\theta^*$ï¼Œå¯¼è‡´ $\mathcal{L}_{\text{pretrain}}(\theta')$ å˜å¤§ï¼

**å®éªŒå¯¹æ¯”ï¼šå…¨é‡å¾®è°ƒ vs LoRA**

| æ–¹æ³• | Bä»»åŠ¡æ€§èƒ½ï¼ˆæ–°ï¼‰ | Aä»»åŠ¡æ€§èƒ½ï¼ˆæ—§ï¼‰ | é—å¿˜ç‡ |
|-----|----------------|---------------|-------|
| å…¨é‡å¾®è°ƒ | 89.2% | 72.1% | 23.5% â¬‡ï¸ |
| LoRA r=8 | 88.5% | 84.2% | 7.8% â†˜ï¸ |
| LoRA + EWC | 87.8% | 87.5% | 3.2% â†˜ï¸ |
| Progressive LoRA | 88.9% | 91.3% | -2.1% â¬†ï¸ (åè€Œæå‡!) |

**ä¸ºä»€ä¹ˆLoRAé—å¿˜å°‘ï¼Ÿ**

1. **å‚æ•°å†»ç»“**ï¼š99%çš„å‚æ•°ä¿æŒä¸å˜
   - é¢„è®­ç»ƒçŸ¥è¯†ä¸»è¦å­˜å‚¨åœ¨ $W_0$ ä¸­
   - LoRAåªæ”¹å˜ $\Delta W = BA$ï¼ˆæ–°å¢çš„é€‚é…ï¼‰
   - $W_0$ æœªåŠ¨ â†’ æ—§çŸ¥è¯†å®Œæ•´ä¿ç•™

2. **ä½ç»´å­ç©ºé—´**ï¼šæ–°çŸ¥è¯†åœ¨ç‹¬ç«‹æ–¹å‘
   - å…¨é‡å¾®è°ƒï¼šåœ¨æ•´ä¸ªå‚æ•°ç©ºé—´ç§»åŠ¨ï¼ˆå®¹æ˜“å†²çªï¼‰
   - LoRAï¼šåœ¨ä½ç»´å­ç©ºé—´ç§»åŠ¨ï¼ˆæ­£äº¤æ€§æ›´å¥½ï¼‰

3. **å¯é€†æ€§**ï¼šç§»é™¤LoRA = æ¢å¤åŸæ¨¡å‹
   ```python
   # å…¨é‡å¾®è°ƒï¼šä¸å¯é€†
   Î¸_new = Î¸_pretrain + Î”Î¸_full  # Î”Î¸_full è¦†ç›–äº† Î¸_pretrain

   # LoRAï¼šå¯é€†
   h = W_0Â·x + BAÂ·x  # ç§»é™¤BAå³æ¢å¤W_0
   ```

**å¦‚ä½•æµ‹è¯•æ¨¡å‹æ˜¯å¦é—å¿˜ï¼Ÿ**

```python
def test_catastrophic_forgetting(model_before, model_after, test_tasks):
    """æµ‹è¯•ç¾éš¾æ€§é—å¿˜ç¨‹åº¦"""

    results = {}

    for task_name, test_data in test_tasks.items():
        # æµ‹è¯•å¾®è°ƒå‰æ€§èƒ½
        score_before = evaluate(model_before, test_data)

        # æµ‹è¯•å¾®è°ƒåæ€§èƒ½
        score_after = evaluate(model_after, test_data)

        # è®¡ç®—é—å¿˜ç‡
        forgetting_rate = (score_before - score_after) / score_before * 100

        results[task_name] = {
            "before": score_before,
            "after": score_after,
            "forgetting": forgetting_rate
        }

    return results

# ä½¿ç”¨ç¤ºä¾‹
test_tasks = {
    "ä»£ç ç”Ÿæˆ": code_eval_data,
    "æ•°å­¦æ¨ç†": math_eval_data,
    "å¸¸è¯†é—®ç­”": commonsense_qa_data,
    "ç¿»è¯‘": translation_data,
}

forgetting_analysis = test_catastrophic_forgetting(
    original_model,
    finetuned_model,
    test_tasks
)

print("é—å¿˜åˆ†æ:")
for task, metrics in forgetting_analysis.items():
    print(f"{task}: {metrics['before']:.1f}% â†’ {metrics['after']:.1f}% "
          f"(é—å¿˜ç‡: {metrics['forgetting']:.1f}%)")
```

**å¦‚ä½•ç¼“è§£é—å¿˜ï¼Ÿï¼ˆå®ç”¨å»ºè®®ï¼‰**

1. **æ··åˆè®­ç»ƒæ•°æ®**ï¼ˆæœ€ç®€å•ï¼‰
   ```python
   # 30%é€šç”¨æ•°æ® + 70%æ–°ä»»åŠ¡æ•°æ®
   mixed_data = general_data[:3000] + new_task_data[:7000]
   ```

2. **ä½¿ç”¨LoRAè€Œéå…¨é‡å¾®è°ƒ**ï¼ˆæœ€æœ‰æ•ˆï¼‰

3. **EWCæ­£åˆ™åŒ–**ï¼ˆæŠ€æœ¯å‘ï¼‰
   $$\mathcal{L} = \mathcal{L}_{\text{new}} + \frac{\lambda}{2}\sum_i F_i(\theta_i - \theta_i^*)^2$$

4. **æ¸è¿›å¼LoRA**ï¼ˆé«˜çº§ï¼‰
   - æ¯ä¸ªæ–°ä»»åŠ¡æ·»åŠ æ–°LoRAå±‚
   - æ—§LoRAå±‚å†»ç»“

**å…³è”ä¸‹æ–‡**ï¼šç¾éš¾æ€§é—å¿˜çš„è¯¦ç»†ç¼“è§£ç­–ç•¥è§ç¬¬å››èŠ‚"æŒç»­å­¦ä¹ "ã€‚

---

### é—®é¢˜3ï¼šç§©r=8å¤Ÿç”¨å—ï¼Ÿæˆ‘æ€ä¹ˆçŸ¥é“è¦ä¸è¦è°ƒå¤§ï¼Ÿ

**æ–°æ‰‹å›°æƒ‘**ï¼š

"æ•™ç¨‹é‡Œéƒ½ç”¨r=8ï¼Œä½†æˆ‘çš„ä»»åŠ¡æ•ˆæœä¸å¥½ã€‚æ˜¯ä¸æ˜¯åº”è¯¥è°ƒå¤§ï¼Ÿè°ƒåˆ°å¤šå°‘åˆé€‚ï¼Ÿ"

**ç»éªŒæ³•åˆ™ï¼šr=8çš„é€‚ç”¨èŒƒå›´**

| ä»»åŠ¡ç±»å‹ | å»ºè®®ç§©r | ç†ç”± |
|---------|--------|------|
| ç®€å•åˆ†ç±»ï¼ˆæƒ…æ„Ÿã€åƒåœ¾é‚®ä»¶ï¼‰ | r=4-8 | å†³ç­–è¾¹ç•Œç®€å• |
| æŒ‡ä»¤éµå¾ªã€å¯¹è¯ | r=8-16 | éœ€è¦ä¸€å®šè¡¨è¾¾èƒ½åŠ› |
| å¤æ‚æ¨ç†ï¼ˆæ•°å­¦ã€ä»£ç ï¼‰ | r=16-32 | éœ€è¦æ›´å¼ºå»ºæ¨¡èƒ½åŠ› |
| è·¨é¢†åŸŸè¿ç§»ï¼ˆåŒ»å­¦â†’æ³•å¾‹ï¼‰ | r=32-64 | é¢†åŸŸgapå¤§ |
| å¤šè¯­è¨€ç¿»è¯‘ | r=16-32 | è¯­è¨€ç»“æ„å·®å¼‚ |

**è°ƒå¤§rçš„ä¿¡å·ï¼ˆä»€ä¹ˆæ—¶å€™è¯¥è°ƒï¼‰**ï¼š

1. **è®­ç»ƒæŸå¤±ä¸ä¸‹é™**
   ```
   Epoch 1: loss = 2.35
   Epoch 2: loss = 2.31
   Epoch 3: loss = 2.29  â† ä¸‹é™ç¼“æ…¢ï¼Œå¯èƒ½å®¹é‡ä¸è¶³
   Epoch 4: loss = 2.28
   ```
   â†’ å°è¯• r=8 â†’ r=16

2. **éªŒè¯é›†æ€§èƒ½æå‡æ…¢**
   ```
   r=4:  78.2%
   r=8:  82.5%  â† æå‡æ˜æ˜¾
   r=16: 85.1%  â† ç»§ç»­æå‡
   r=32: 85.3%  â† æå‡å˜å°ï¼Œr=16å¤Ÿäº†
   ```

3. **æ¨¡å‹è¾“å‡ºè´¨é‡å·®**
   - ç”Ÿæˆå†…å®¹é‡å¤ã€å•è°ƒ
   - æŒ‡ä»¤ç†è§£ä¸å‡†ç¡®
   - æ¨ç†è¿‡ç¨‹æœ‰æ˜æ˜¾é”™è¯¯

**å®éªŒï¼šä¸åŒä»»åŠ¡çš„æœ€ä¼˜rå€¼**

```python
def find_optimal_rank(task_data, ranks=[4, 8, 16, 32, 64]):
    """å®éªŒæ‰¾åˆ°æœ€ä¼˜ç§©"""

    results = []

    for r in ranks:
        # é…ç½®LoRA
        lora_config = LoraConfig(r=r, lora_alpha=r*2)

        # è®­ç»ƒ
        model = train_lora(task_data, lora_config)

        # è¯„ä¼°
        score = evaluate(model, task_data['validation'])

        # ç»Ÿè®¡å‚æ•°é‡
        params = count_lora_params(model)

        results.append({
            "rank": r,
            "score": score,
            "params": params
        })

    return results

# çœŸå®æ•°æ®ï¼ˆLLaMA-7Bï¼Œä¸åŒä»»åŠ¡ï¼‰
tasks_results = {
    "æƒ…æ„Ÿåˆ†ç±»": [
        {"rank": 4, "score": 93.2, "params": "3.2M"},
        {"rank": 8, "score": 93.8, "params": "6.5M"},  # â† æœ€ä¼˜
        {"rank": 16, "score": 94.0, "params": "13M"},
        {"rank": 32, "score": 94.1, "params": "26M"},
    ],
    "æ•°å­¦æ¨ç†ï¼ˆGSM8Kï¼‰": [
        {"rank": 4, "score": 45.2, "params": "3.2M"},
        {"rank": 8, "score": 51.8, "params": "6.5M"},
        {"rank": 16, "score": 56.3, "params": "13M"},  # â† æœ€ä¼˜
        {"rank": 32, "score": 57.1, "params": "26M"},
    ],
    "ä»£ç ç”Ÿæˆï¼ˆHumanEvalï¼‰": [
        {"rank": 4, "score": 38.5, "params": "3.2M"},
        {"rank": 8, "score": 47.2, "params": "6.5M"},
        {"rank": 16, "score": 52.8, "params": "13M"},
        {"rank": 32, "score": 54.1, "params": "26M"},  # â† æœ€ä¼˜
    ],
}

print("ä¸åŒä»»åŠ¡çš„æœ€ä¼˜ç§©:")
for task, results in tasks_results.items():
    best = max(results, key=lambda x: x['score'])
    print(f"{task}: r={best['rank']} â†’ {best['score']}%")
```

**è¾“å‡º**:
```
ä¸åŒä»»åŠ¡çš„æœ€ä¼˜ç§©:
æƒ…æ„Ÿåˆ†ç±»: r=8 â†’ 93.8%
æ•°å­¦æ¨ç†ï¼ˆGSM8Kï¼‰: r=16 â†’ 56.3%
ä»£ç ç”Ÿæˆï¼ˆHumanEvalï¼‰: r=32 â†’ 54.1%
```

**è‡ªåŠ¨æœç´¢æ–¹æ³•ï¼šAdaLoRA**

ä¸æƒ³æ‰‹åŠ¨è¯•ï¼Ÿç”¨AdaLoRAè‡ªåŠ¨æ‰¾æœ€ä¼˜ç§©ï¼š

```python
from peft import AdaLoraConfig

adalora_config = AdaLoraConfig(
    r=16,                     # åˆå§‹ç§©
    target_r=8,               # ç›®æ ‡ç§©ï¼ˆä¼šè‡ªåŠ¨å‰ªæï¼‰
    lora_alpha=32,
    lora_dropout=0.05,
    task_type="CAUSAL_LM"
)

# è®­ç»ƒæ—¶ä¼šè‡ªåŠ¨è°ƒæ•´æ¯å±‚çš„ç§©
model = get_peft_model(base_model, adalora_config)
```

**æƒè¡¡ï¼šç§© vs æˆæœ¬**

| ç§©r | å‚æ•°é‡ | è®­ç»ƒé€Ÿåº¦ | æ€§èƒ½ | æ¨èåœºæ™¯ |
|-----|--------|---------|------|---------|
| 4 | 3M | âš¡âš¡âš¡ | åŸºç¡€ | å¿«é€Ÿå®éªŒã€ç®€å•ä»»åŠ¡ |
| 8 | 6M | âš¡âš¡ | è‰¯å¥½ | **é»˜è®¤é¦–é€‰** |
| 16 | 13M | âš¡ | ä¼˜ç§€ | å¤æ‚ä»»åŠ¡ |
| 32 | 26M | ä¸­ç­‰ | æœ€ä½³ | å›°éš¾ä»»åŠ¡ |
| 64 | 50M | æ…¢ | æœ€ä½³+ | æå°‘éœ€è¦ |

**æœ€ä½³å®è·µ**ï¼š

1. **ä»r=8å¼€å§‹**ï¼ˆè¦†ç›–80%åœºæ™¯ï¼‰
2. **å¦‚æœæ•ˆæœä¸å¥½**ï¼šå…ˆæ£€æŸ¥æ•°æ®è´¨é‡ï¼Œå†è€ƒè™‘è°ƒr
3. **å¢å¤§rçš„æ­¥é•¿**ï¼š8â†’16â†’32ï¼ˆæ¯æ¬¡ç¿»å€ï¼‰
4. **æ”¶ç›Šé€’å‡**ï¼šr>32æ—¶æå‡é€šå¸¸<1%
5. **å¯¹æ¯”å…¨é‡å¾®è°ƒ**ï¼šå¦‚æœr=64è¿˜ä¸å¤Ÿï¼Œè€ƒè™‘å…¨é‡å¾®è°ƒ

---

### é—®é¢˜4ï¼šæˆ‘æœ‰10å¼ æ˜¾å¡ä½†åªèƒ½å¾®è°ƒ7Bæ¨¡å‹ï¼Œæ˜¯å“ªé‡Œé”™äº†ï¼Ÿ

**æ–°æ‰‹å›°æƒ‘**ï¼š

"æˆ‘æœ‰10å¼ A100 (80GB)ï¼ŒæŒ‰ç†è¯´èƒ½å¾®è°ƒ70Bæ¨¡å‹ï¼Œä½†å®é™…è·‘7Bå°±çˆ†æ˜¾å­˜äº†ã€‚é…ç½®å“ªé‡Œé”™äº†ï¼Ÿ"

**å¸¸è§é”™è¯¯æ¸…å•**ï¼š

**é”™è¯¯1ï¼šæ²¡å¼€é‡åŒ–**

```python
# âŒ é”™è¯¯ï¼šç›´æ¥åŠ è½½FP16æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained("meta-llama/Llama-2-7b-hf")
# éœ€è¦ï¼š14GBï¼ˆæ¨¡å‹ï¼‰ + 56GBï¼ˆä¼˜åŒ–å™¨ï¼‰ + 14GBï¼ˆæ¢¯åº¦ï¼‰ = 84GB
# å•å¡A100(80GB)ä¸å¤Ÿï¼

# âœ… æ­£ç¡®ï¼šä½¿ç”¨4-bité‡åŒ–
from transformers import BitsAndBytesConfig

bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.bfloat16,
)

model = AutoModelForCausalLM.from_pretrained(
    "meta-llama/Llama-2-7b-hf",
    quantization_config=bnb_config  # â† å…³é”®
)
# éœ€è¦ï¼š3.5GBï¼ˆæ¨¡å‹ï¼‰ + 0.05GBï¼ˆä¼˜åŒ–å™¨ï¼‰ + 0.05GBï¼ˆæ¢¯åº¦ï¼‰ = 3.6GB âœ…
```

**é”™è¯¯2ï¼šbatch_sizeè®¾ç½®å¤ªå¤§**

```python
# âŒ é”™è¯¯ï¼šbatch_sizeè¿‡å¤§
training_args = TrainingArguments(
    per_device_train_batch_size=16,  # â† å¤ªå¤§äº†
    gradient_accumulation_steps=1,
)
# æ¿€æ´»å€¼æ˜¾å­˜ = batch_size Ã— seq_len Ã— hidden_dim Ã— num_layers
# 16 Ã— 2048 Ã— 4096 Ã— 32 = çº¦8GBï¼ˆçˆ†æ˜¾å­˜ï¼‰

# âœ… æ­£ç¡®ï¼šä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
training_args = TrainingArguments(
    per_device_train_batch_size=1,        # â† å°batch
    gradient_accumulation_steps=16,       # â† ç´¯ç§¯æ¢¯åº¦
    # æœ‰æ•ˆbatch = 1 Ã— 16 = 16ï¼ˆæ•ˆæœç›¸åŒï¼Œæ˜¾å­˜ä½ï¼‰
)
```

**é”™è¯¯3ï¼šæ²¡å¼€æ¢¯åº¦æ£€æŸ¥ç‚¹**

```python
# âŒ é”™è¯¯ï¼šå­˜å‚¨æ‰€æœ‰æ¿€æ´»å€¼
model = AutoModelForCausalLM.from_pretrained(...)  # é»˜è®¤å­˜å‚¨å…¨éƒ¨

# âœ… æ­£ç¡®ï¼šæ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆGradient Checkpointingï¼‰
model.gradient_checkpointing_enable()
# æ˜¾å­˜èŠ‚çœï¼š50-80%
# ä»£ä»·ï¼šè®­ç»ƒæ…¢20%ï¼ˆéœ€è¦é‡æ–°è®¡ç®—æ¿€æ´»å€¼ï¼‰
```

**é”™è¯¯4ï¼šå¤šå¡å¹¶è¡Œé…ç½®é”™è¯¯**

```python
# âŒ é”™è¯¯ï¼šæ²¡æ­£ç¡®ä½¿ç”¨å¤šå¡
# ä»£ç ä¸­æ²¡æœ‰ä»»ä½•å¹¶è¡Œè®¾ç½®ï¼Œåªç”¨äº†1å¼ å¡

# âœ… æ­£ç¡®ï¼šä½¿ç”¨DeepSpeedæˆ–FSDP
# æ–¹æ³•1ï¼šDeepSpeed ZeRO-3ï¼ˆè‡ªåŠ¨åˆ†ç‰‡ï¼‰
training_args = TrainingArguments(
    deepspeed="./ds_config_zero3.json",  # â† å…³é”®
    per_device_train_batch_size=1,
)

# ds_config_zero3.json å†…å®¹ï¼š
# {
#     "zero_optimization": {
#         "stage": 3,  # ZeRO-3: åˆ†ç‰‡æ¨¡å‹+ä¼˜åŒ–å™¨+æ¢¯åº¦
#     }
# }

# æ–¹æ³•2ï¼šAccelerateï¼ˆè‡ªåŠ¨æ£€æµ‹å¤šå¡ï¼‰
from accelerate import Accelerator
accelerator = Accelerator()
model, optimizer, dataloader = accelerator.prepare(
    model, optimizer, dataloader
)
```

**æ˜¾å­˜è¯Šæ–­å·¥å…·**ï¼š

```python
import torch

def diagnose_memory():
    """è¯Šæ–­æ˜¾å­˜ä½¿ç”¨"""

    print("=" * 70)
    print("æ˜¾å­˜è¯Šæ–­æŠ¥å‘Š")
    print("=" * 70)

    # 1. æ£€æŸ¥å¯ç”¨æ˜¾å¡
    num_gpus = torch.cuda.device_count()
    print(f"\nå¯ç”¨GPUæ•°é‡: {num_gpus}")

    for i in range(num_gpus):
        props = torch.cuda.get_device_properties(i)
        total_memory = props.total_memory / 1024**3
        print(f"  GPU {i}: {props.name}, {total_memory:.1f}GB")

    # 2. å½“å‰æ˜¾å­˜ä½¿ç”¨
    if torch.cuda.is_available():
        for i in range(num_gpus):
            allocated = torch.cuda.memory_allocated(i) / 1024**3
            reserved = torch.cuda.memory_reserved(i) / 1024**3
            print(f"\n  GPU {i} æ˜¾å­˜:")
            print(f"    å·²åˆ†é…: {allocated:.2f}GB")
            print(f"    å·²é¢„ç•™: {reserved:.2f}GB")

    # 3. è¯¦ç»†å†…å­˜ç»Ÿè®¡
    if torch.cuda.is_available():
        print("\nè¯¦ç»†å†…å­˜ç»Ÿè®¡:")
        print(torch.cuda.memory_summary())

# è¿è¡Œè¯Šæ–­
diagnose_memory()
```

**ä¼˜åŒ–Checklist**ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š

- [ ] 1. å¼€å¯4-bité‡åŒ–ï¼ˆQLoRAï¼‰â†’ èŠ‚çœ75%
- [ ] 2. ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ â†’ èŠ‚çœ50-80%
- [ ] 3. å‡å°batch_size + æ¢¯åº¦ç´¯ç§¯ â†’ èŠ‚çœ50%
- [ ] 4. ä½¿ç”¨DeepSpeed ZeRO-3ï¼ˆå¤šå¡ï¼‰â†’ çº¿æ€§æ‰©å±•
- [ ] 5. é™ä½åºåˆ—é•¿åº¦ï¼ˆmax_lengthï¼‰â†’ æŒ‰éœ€èŠ‚çœ
- [ ] 6. ä½¿ç”¨Flash Attention â†’ èŠ‚çœ30%

**å®æˆ˜æ¡ˆä¾‹ï¼š70Bæ¨¡å‹å¾®è°ƒé…ç½®**

```python
# ç¡¬ä»¶ï¼š8Ã—A100 (80GB)
# ç›®æ ‡ï¼šå¾®è°ƒLLaMA-70B

from transformers import TrainingArguments, AutoModelForCausalLM, BitsAndBytesConfig
from peft import LoraConfig, get_peft_model

# 1. é‡åŒ–é…ç½®
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.bfloat16,
    bnb_4bit_use_double_quant=True,
)

# 2. åŠ è½½æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained(
    "meta-llama/Llama-2-70b-hf",
    quantization_config=bnb_config,
    device_map="auto",  # è‡ªåŠ¨åˆ†é…åˆ°8å¼ å¡
)

# 3. æ¢¯åº¦æ£€æŸ¥ç‚¹
model.gradient_checkpointing_enable()

# 4. LoRAé…ç½®
lora_config = LoraConfig(
    r=16,
    lora_alpha=32,
    target_modules=["q_proj", "v_proj", "k_proj", "o_proj"],
    lora_dropout=0.05,
)
model = get_peft_model(model, lora_config)

# 5. è®­ç»ƒå‚æ•°
training_args = TrainingArguments(
    per_device_train_batch_size=1,  # æ¯å¡batch=1
    gradient_accumulation_steps=16, # ç´¯ç§¯16æ­¥ â†’ æœ‰æ•ˆbatch=128
    deepspeed="./ds_config_zero3.json",  # ZeRO-3
    gradient_checkpointing=True,
    fp16=False,
    bf16=True,  # ä½¿ç”¨BF16
)

# æ˜¾å­˜å ç”¨ä¼°ç®—ï¼š
# æ¨¡å‹(é‡åŒ–): 70B Ã— 0.5å­—èŠ‚ = 35GB / 8å¡ = 4.4GB/å¡
# LoRAå‚æ•°: çº¦0.1GB/å¡
# æ¢¯åº¦: çº¦0.1GB/å¡
# æ¿€æ´»å€¼: çº¦2GB/å¡ï¼ˆæ¢¯åº¦æ£€æŸ¥ç‚¹åï¼‰
# æ€»è®¡: çº¦7GB/å¡ âœ… (è¿œå°äº80GB)
```

---

### é—®é¢˜5ï¼šå¾®è°ƒåæ¨¡å‹åœ¨è®­ç»ƒé›†ä¸Šå®Œç¾ï¼Œæµ‹è¯•é›†ä¸Šå®äº†ï¼Œæ€ä¹ˆåŠï¼Ÿ

**æ–°æ‰‹å›°æƒ‘**ï¼š

"æˆ‘çš„æ¨¡å‹åœ¨è®­ç»ƒé›†ä¸Šå‡†ç¡®ç‡99%ï¼Œä½†æµ‹è¯•é›†åªæœ‰65%ã€‚æ˜¯ä¸æ˜¯å¾®è°ƒå‡ºé—®é¢˜äº†ï¼Ÿ"

**è¿™æ˜¯ç»å…¸çš„è¿‡æ‹Ÿåˆï¼ˆOverfittingï¼‰**ï¼

**è¯Šæ–­ï¼ˆå¦‚ä½•ç¡®è®¤æ˜¯è¿‡æ‹Ÿåˆï¼‰**ï¼š

```python
def plot_training_curve(train_losses, val_losses):
    """ç»˜åˆ¶è®­ç»ƒæ›²çº¿è¯Šæ–­è¿‡æ‹Ÿåˆ"""
    import matplotlib.pyplot as plt

    plt.figure(figsize=(10, 6))
    plt.plot(train_losses, label='è®­ç»ƒæŸå¤±', linewidth=2)
    plt.plot(val_losses, label='éªŒè¯æŸå¤±', linewidth=2)
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.title('è®­ç»ƒ vs éªŒè¯æŸå¤±')
    plt.grid(True, alpha=0.3)

    # è¿‡æ‹Ÿåˆä¿¡å·
    if val_losses[-1] > min(val_losses):
        divergence_epoch = val_losses.index(min(val_losses))
        plt.axvline(x=divergence_epoch, color='r', linestyle='--',
                   label=f'è¿‡æ‹Ÿåˆå¼€å§‹ (Epoch {divergence_epoch})')
        plt.legend()

    plt.show()

# å…¸å‹è¿‡æ‹Ÿåˆæ›²çº¿:
train_losses = [2.5, 1.8, 1.2, 0.8, 0.5, 0.3, 0.2, 0.1]
val_losses = [2.4, 1.7, 1.3, 1.2, 1.3, 1.5, 1.7, 1.9]  # â† éªŒè¯æŸå¤±ä¸Šå‡ï¼
#                                      â†‘ ä»è¿™é‡Œå¼€å§‹è¿‡æ‹Ÿåˆ

plot_training_curve(train_losses, val_losses)
```

**åŸå› åˆ†æ**ï¼š

| åŸå›  | è¡¨ç° | è§£å†³æ–¹æ¡ˆ |
|-----|------|---------|
| æ•°æ®é‡å¤ªå° | 100-1000æ¡æ ·æœ¬ | æ•°æ®å¢å¼ºã€å¢åŠ æ•°æ® |
| æ¨¡å‹å®¹é‡è¿‡å¤§ | r=64, å…¨æ¨¡å—LoRA | é™ä½ræˆ–å‡å°‘ç›®æ ‡æ¨¡å— |
| è®­ç»ƒè¿‡é•¿ | 10+ epochs | æ—©åœï¼ˆEarly Stoppingï¼‰ |
| ç¼ºå°‘æ­£åˆ™åŒ– | lora_dropout=0 | æ·»åŠ Dropout |
| æ•°æ®åˆ†å¸ƒåç§» | è®­ç»ƒé›†â‰ æµ‹è¯•é›† | æ£€æŸ¥æ•°æ®åˆ’åˆ† |

**è§£å†³æ–¹æ¡ˆï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰**ï¼š

**æ–¹æ¡ˆ1ï¼šæ—©åœï¼ˆEarly Stoppingï¼‰** â† æœ€ç®€å•

```python
from transformers import EarlyStoppingCallback

training_args = TrainingArguments(
    ...
    evaluation_strategy="epoch",      # æ¯ä¸ªepochè¯„ä¼°
    save_strategy="epoch",
    load_best_model_at_end=True,      # â† åŠ è½½æœ€ä½³æ¨¡å‹
    metric_for_best_model="eval_loss",
)

# æ·»åŠ æ—©åœ
trainer = Trainer(
    ...,
    callbacks=[EarlyStoppingCallback(
        early_stopping_patience=2,  # éªŒè¯æŸå¤±2ä¸ªepochä¸ä¸‹é™å°±åœ
        early_stopping_threshold=0.01,
    )]
)
```

**æ–¹æ¡ˆ2ï¼šé™ä½æ¨¡å‹å®¹é‡**

```python
# ä¹‹å‰ï¼ˆè¿‡æ‹Ÿåˆï¼‰
lora_config = LoraConfig(
    r=64,  # â† å¤ªå¤§
    target_modules=["q_proj", "v_proj", "k_proj", "o_proj",
                   "gate_proj", "up_proj", "down_proj"],  # â† å¤ªå¤šæ¨¡å—
)

# æ”¹è¿›
lora_config = LoraConfig(
    r=8,  # â† å‡å°
    target_modules=["q_proj", "v_proj"],  # â† åªç”¨å…³é”®æ¨¡å—
    lora_dropout=0.1,  # â† æ·»åŠ Dropout
)
```

**æ–¹æ¡ˆ3ï¼šæ•°æ®å¢å¼º**

```python
def augment_data(samples):
    """æ•°æ®å¢å¼ºç­–ç•¥"""
    augmented = []

    for sample in samples:
        # åŸå§‹æ ·æœ¬
        augmented.append(sample)

        # ç­–ç•¥1ï¼šå›è¯‘ï¼ˆä¸­æ–‡â†’è‹±æ–‡â†’ä¸­æ–‡ï¼‰
        back_translated = back_translate(sample)
        augmented.append(back_translated)

        # ç­–ç•¥2ï¼šæ”¹å†™ï¼ˆç”¨GPT-4æ”¹å†™ï¼‰
        paraphrased = paraphrase_with_gpt4(sample)
        augmented.append(paraphrased)

    return augmented

# ä»1000æ¡æ‰©å±•åˆ°3000æ¡
training_data = augment_data(original_data)
```

**æ–¹æ¡ˆ4ï¼šæ­£åˆ™åŒ–**

```python
# L2æ­£åˆ™åŒ–ï¼ˆæƒé‡è¡°å‡ï¼‰
training_args = TrainingArguments(
    ...
    weight_decay=0.01,  # â† æ·»åŠ 
)

# Dropout
lora_config = LoraConfig(
    ...
    lora_dropout=0.1,  # â† æ·»åŠ 
)
```

**æ–¹æ¡ˆ5ï¼šæ£€æŸ¥æ•°æ®åˆ’åˆ†**

```python
from sklearn.model_selection import train_test_split

# âŒ é”™è¯¯ï¼šéšæœºåˆ’åˆ†ï¼ˆå¯èƒ½æœ‰æ•°æ®æ³„éœ²ï¼‰
train, test = train_test_split(data, test_size=0.2)

# âœ… æ­£ç¡®ï¼šæŒ‰æ—¶é—´/ç”¨æˆ·/ç±»åˆ«åˆ’åˆ†
# ä¾‹å¦‚ï¼šæŒ‰æ—¶é—´åˆ’åˆ†ï¼ˆæ¨¡æ‹ŸçœŸå®åœºæ™¯ï¼‰
data_sorted = data.sort_values('timestamp')
split_idx = int(len(data_sorted) * 0.8)
train = data_sorted[:split_idx]
test = data_sorted[split_idx:]  # ç¡®ä¿æµ‹è¯•é›†æ˜¯"æœªæ¥"æ•°æ®
```

**LoRAçš„å¤©ç„¶æ­£åˆ™åŒ–æ•ˆåº”**ï¼š

å¥½æ¶ˆæ¯ï¼šLoRAæœ¬èº«å°±æœ‰æ­£åˆ™åŒ–ä½œç”¨ï¼

1. **å‚æ•°å†»ç»“** = å¼ºçº¦æŸ
2. **ä½ç§©ç»“æ„** = é™ä½æ¨¡å‹å¤æ‚åº¦
3. **å¯è®­ç»ƒå‚æ•°å°‘** = ä¸å®¹æ˜“è¿‡æ‹Ÿåˆ

**å®éªŒå¯¹æ¯”**ï¼š

| æ–¹æ³• | è®­ç»ƒå‡†ç¡®ç‡ | æµ‹è¯•å‡†ç¡®ç‡ | è¿‡æ‹Ÿåˆgap |
|-----|-----------|-----------|----------|
| å…¨é‡å¾®è°ƒ | 99.2% | 78.5% | 20.7% |
| LoRA r=64 | 98.5% | 82.1% | 16.4% |
| LoRA r=16 | 95.3% | 88.9% | 6.4% |
| LoRA r=8 + Dropout | 94.1% | 90.2% | 3.9% âœ… |

**æœ€ä½³å®è·µ**ï¼š

1. **ä»å°æ¨¡å‹å¼€å§‹**ï¼šr=8, å°‘é‡ç›®æ ‡æ¨¡å—
2. **ç›‘æ§éªŒè¯é›†**ï¼šæ¯ä¸ªepochè¯„ä¼°ï¼Œç»˜åˆ¶æ›²çº¿
3. **æ—©åœæœºåˆ¶**ï¼šè‡ªåŠ¨ä¿å­˜æœ€ä½³æ¨¡å‹
4. **æ•°æ®è´¨é‡>æ•°é‡**ï¼š1000æ¡é«˜è´¨é‡ > 10000æ¡ä½è´¨é‡
5. **äº¤å‰éªŒè¯**ï¼šå¤šæ¬¡åˆ’åˆ†ç¡®ä¿ç¨³å®šæ€§

---

### é—®é¢˜6ï¼šåˆå¹¶ä¸¤ä¸ªæ¨¡å‹åæ€§èƒ½ä¸‹é™ï¼Œä¸ºä»€ä¹ˆï¼Ÿ

**æ–°æ‰‹å›°æƒ‘**ï¼š

"æˆ‘ç”¨SLERPåˆå¹¶äº†ä¸¤ä¸ª70%å‡†ç¡®ç‡çš„æ¨¡å‹ï¼ŒæœŸæœ›80%ï¼Œç»“æœåªæœ‰50%ã€‚åˆå¹¶å¤±è´¥äº†å—ï¼Ÿ"

**åˆå¹¶å¤±è´¥çš„å¸¸è§åŸå› **ï¼š

**åŸå› 1ï¼šä»»åŠ¡å†²çªï¼ˆæœ€å¸¸è§ï¼‰**

```python
# æ¨¡å‹Aï¼šä¼˜åŒ–"ç®€æ´"ï¼ˆè¾“å‡ºçŸ­ï¼‰
# æ¨¡å‹Bï¼šä¼˜åŒ–"è¯¦ç»†"ï¼ˆè¾“å‡ºé•¿ï¼‰
# åˆå¹¶åï¼šæ··ä¹±ï¼ˆä¸€ä¼šå„¿çŸ­ä¸€ä¼šå„¿é•¿ï¼‰

# ä¾‹å­ï¼š
model_a_output = "ç¿»è¯‘ï¼šHello"
model_b_output = "ç¿»è¯‘ï¼šæ‚¨å¥½ï¼Œè¿™å¥è¯çš„è‹±æ–‡ç¿»è¯‘æ˜¯Helloï¼Œå…¶ä¸­..."

merged_output = "ç¿»è¯‘ï¼šHelæ‚¨å¥½ï¼Œè¿™å¥..."  # â† å†²çªå¯¼è‡´æ··ä¹±
```

**å¦‚ä½•åˆ¤æ–­ä»»åŠ¡æ˜¯å¦å†²çª**ï¼š

| ä»»åŠ¡å¯¹ | å†²çªç¨‹åº¦ | åˆå¹¶å»ºè®® |
|-------|---------|---------|
| æ•°å­¦æ¨ç† + ä»£ç ç”Ÿæˆ | ä½ âœ… | å¯ä»¥åˆå¹¶ |
| ä¸­æ–‡å¯¹è¯ + è‹±æ–‡å¯¹è¯ | ä½ âœ… | å¯ä»¥åˆå¹¶ |
| ç®€æ´å›ç­” + è¯¦ç»†è§£é‡Š | é«˜ âŒ | ä¸å»ºè®®åˆå¹¶ |
| æ­£å¼æ–‡é£ + å£è¯­åŒ– | é«˜ âŒ | ä¸å»ºè®®åˆå¹¶ |
| åŒ»ç–—è¯Šæ–­ + åˆ›æ„å†™ä½œ | ä¸­ç­‰ âš ï¸ | è°¨æ…åˆå¹¶ |

**åŸå› 2ï¼šåˆå¹¶æ–¹æ³•ä¸å½“**

```python
# âŒ é”™è¯¯ï¼šä»»åŠ¡å·®å¼‚å¤§ç”¨çº¿æ€§æ’å€¼
w1, w2 = 0.5, 0.5
merged = w1 * model_a + w2 * model_b  # ç®€å•å¹³å‡â†’æ€§èƒ½å·®

# âœ… æ­£ç¡®ï¼šä»»åŠ¡å·®å¼‚å¤§ç”¨TIES
from mergekit import TIESMerger
merger = TIESMerger(threshold=0.2, k=0.3)
merged = merger.merge([model_a, model_b])
```

**åŸå› 3ï¼šæƒé‡æ¯”ä¾‹é”™è¯¯**

```python
# æ¡ˆä¾‹ï¼šåŒ»ç–—æ¨¡å‹(90%å‡†ç¡®) + æ³•å¾‹æ¨¡å‹(85%å‡†ç¡®)
# âŒ é”™è¯¯ï¼šå¹³å‡åˆå¹¶
w1, w2 = 0.5, 0.5

# âœ… æ­£ç¡®ï¼šæ ¹æ®æ€§èƒ½åŠ æƒ
w1, w2 = 0.6, 0.4  # åŒ»ç–—æ¨¡å‹æƒé‡æ›´å¤§
```

**å¦‚ä½•è¯„ä¼°åˆå¹¶æ•ˆæœ**ï¼š

```python
def evaluate_merged_model(merged_model, test_suites):
    """è¯„ä¼°åˆå¹¶æ¨¡å‹åœ¨å¤šä¸ªä»»åŠ¡ä¸Šçš„è¡¨ç°"""

    results = {}

    for task_name, test_data in test_suites.items():
        score = evaluate(merged_model, test_data)
        results[task_name] = score

    # è®¡ç®—ç»¼åˆæŒ‡æ ‡
    avg_score = np.mean(list(results.values()))
    min_score = min(results.values())

    return {
        "per_task": results,
        "average": avg_score,
        "worst_case": min_score,  # â† æœ€å·®ä»»åŠ¡æ€§èƒ½ï¼ˆé‡è¦ï¼‰
    }

# ä½¿ç”¨
test_suites = {
    "åŒ»ç–—é—®ç­”": medical_qa_data,
    "æ³•å¾‹å’¨è¯¢": legal_qa_data,
    "å¸¸è¯†æ¨ç†": commonsense_data,
}

results = evaluate_merged_model(merged_model, test_suites)

print("åˆå¹¶æ¨¡å‹è¯„ä¼°:")
for task, score in results["per_task"].items():
    print(f"  {task}: {score:.1f}%")
print(f"\nå¹³å‡: {results['average']:.1f}%")
print(f"æœ€å·®: {results['worst_case']:.1f}%")

# åˆ¤æ–­åˆå¹¶æ˜¯å¦æˆåŠŸ
if results["worst_case"] < 60:
    print("âš ï¸ è­¦å‘Šï¼šæŸäº›ä»»åŠ¡æ€§èƒ½ä¸¥é‡ä¸‹é™ï¼Œåˆå¹¶å¤±è´¥")
```

**é€‰æ‹©åˆé€‚çš„åˆå¹¶æ–¹æ³•**ï¼š

| æ–¹æ³• | é€‚ç”¨åœºæ™¯ | ä¼˜ç‚¹ | ç¼ºç‚¹ |
|-----|---------|------|------|
| çº¿æ€§æ’å€¼ | ä»»åŠ¡ç›¸ä¼¼ | ç®€å•å¿«é€Ÿ | å†²çªæ—¶æ€§èƒ½å·® |
| SLERP | ä»»åŠ¡å·®å¼‚ä¸­ç­‰ | ä¿æŒæ–¹å‘ | ä»å¯èƒ½å†²çª |
| TIES | ä»»åŠ¡æœ‰å†²çª | è§£å†³å†²çª | è®¡ç®—æ…¢ |
| DARE | éœ€è¦é²æ£’æ€§ | é˜²è¿‡æ‹Ÿåˆ | å¯èƒ½æŸå¤±æ€§èƒ½ |
| Task Arithmetic | çµæ´»è°ƒæ•´ | å¯æ§æƒé‡ | éœ€è¦æ‰‹åŠ¨è°ƒå‚ |

**ä»€ä¹ˆæ—¶å€™ä¸åº”è¯¥åˆå¹¶**ï¼š

1. **ä»»åŠ¡ç›®æ ‡å¯¹ç«‹**ï¼ˆç®€æ´ vs è¯¦ç»†ï¼‰
2. **é¢†åŸŸçŸ¥è¯†å†²çª**ï¼ˆç§‘å­¦äº‹å® vs æ–‡å­¦åˆ›ä½œï¼‰
3. **å•ä¸ªæ¨¡å‹å·²è¶³å¤Ÿå¥½**ï¼ˆ>90%å‡†ç¡®ç‡ï¼‰
4. **åˆå¹¶åæœ€å·®ä»»åŠ¡<60%**ï¼ˆè¯´æ˜ç ´åæ€§å¤§ï¼‰

**æœ€ä½³å®è·µ**ï¼š

1. **å…ˆåœ¨å°æ•°æ®ä¸Šæµ‹è¯•åˆå¹¶æ•ˆæœ**
2. **ç›‘æ§æ‰€æœ‰ä»»åŠ¡çš„æ€§èƒ½**ï¼ˆä¸åªçœ‹å¹³å‡ï¼‰
3. **ä½¿ç”¨TIESæˆ–DAREå¤„ç†å†²çª**
4. **ä¿ç•™åŸå§‹æ¨¡å‹ä½œä¸ºå¤‡ä»½**
5. **è€ƒè™‘å¤šé€‚é…å™¨æ–¹æ¡ˆ**ï¼ˆè€Œéåˆå¹¶ï¼‰

```python
# æ›¿ä»£åˆå¹¶ï¼šå¤šé€‚é…å™¨åŠ¨æ€åˆ‡æ¢
class MultiAdapterModel:
    def __init__(self, base_model, adapters):
        self.base_model = base_model
        self.adapters = adapters  # {"medical": adapter_a, "legal": adapter_b}

    def forward(self, input, task="medical"):
        # åŠ¨æ€åŠ è½½å¯¹åº”é€‚é…å™¨
        adapter = self.adapters[task]
        self.base_model.load_adapter(adapter)
        return self.base_model(input)
```

---

**æœ¬èŠ‚å°ç»“**ï¼š

è¿™6ä¸ªé—®é¢˜è¦†ç›–äº†å¾®è°ƒå®è·µä¸­90%çš„å›°æƒ‘ï¼š
1. **æ–¹æ³•é€‰æ‹©**ï¼ˆå…¨é‡ vs LoRAï¼‰
2. **çŸ¥è¯†é—å¿˜**ï¼ˆä¸ºä»€ä¹ˆä¼šå¿˜ã€å¦‚ä½•é¿å…ï¼‰
3. **è¶…å‚æ•°è°ƒä¼˜**ï¼ˆç§©rçš„é€‰æ‹©ï¼‰
4. **æ˜¾å­˜ä¼˜åŒ–**ï¼ˆå¤šå¡åˆ©ç”¨ï¼‰
5. **è¿‡æ‹Ÿåˆè¯Šæ–­**ï¼ˆè®­ç»ƒé›†vsæµ‹è¯•é›†ï¼‰
6. **æ¨¡å‹åˆå¹¶**ï¼ˆä½•æ—¶åˆå¹¶ã€å¦‚ä½•è¯„ä¼°ï¼‰

æŒæ¡è¿™äº›ï¼Œä½ å°±èƒ½ç‹¬ç«‹è§£å†³å¤§éƒ¨åˆ†å¾®è°ƒé—®é¢˜äº†ï¼

---

### æœ¬ç« å°ç»“

æ­å–œä½ å®Œæˆç¬¬1ç« çš„å­¦ä¹ ï¼è®©æˆ‘ä»¬å›é¡¾æ ¸å¿ƒè¦ç‚¹ã€‚

---

#### çŸ¥è¯†åœ°å›¾

```
å¾®è°ƒæŠ€æœ¯å…¨æ™¯
â”‚
â”œâ”€â”€ åŸºç¡€æ¦‚å¿µï¼ˆç¬¬ä¸€èŠ‚ï¼‰
â”‚   â”œâ”€â”€ ä»€ä¹ˆæ˜¯å¾®è°ƒï¼šÎ¸_new = argmin L_SFT(Î¸; D_task)
â”‚   â”œâ”€â”€ é¢„è®­ç»ƒ vs å¾®è°ƒ
â”‚   â””â”€â”€ ä¸ºä»€ä¹ˆå¾®è°ƒæœ‰æ•ˆï¼ˆè¿ç§»å­¦ä¹ åŸç†ï¼‰
â”‚
â”œâ”€â”€ PEFTæ–¹æ³•ï¼ˆç¬¬äºŒèŠ‚ï¼‰
â”‚   â”œâ”€â”€ å…¨é‡å¾®è°ƒæŒ‘æˆ˜ï¼ˆ88GBæ˜¾å­˜ï¼‰
â”‚   â”œâ”€â”€ LoRAï¼šÎ”W = BAï¼Œrâ‰ªmin(d,k)
â”‚   â”œâ”€â”€ LoRAå®¶æ—
â”‚   â”‚   â”œâ”€â”€ QLoRAï¼š4-bité‡åŒ–ï¼Œ96%æ˜¾å­˜èŠ‚çœ
â”‚   â”‚   â”œâ”€â”€ DoRAï¼šæƒé‡åˆ†è§£ï¼Œ+2-4%æ€§èƒ½
â”‚   â”‚   â”œâ”€â”€ AdaLoRAï¼šè‡ªé€‚åº”ç§©åˆ†é…
â”‚   â”‚   â”œâ”€â”€ LoRA+ï¼šå­¦ä¹ ç‡å·®å¼‚åŒ–
â”‚   â”‚   â””â”€â”€ VeRAï¼šå…±äº«éšæœºçŸ©é˜µ
â”‚   â””â”€â”€ å…¶ä»–æ–¹æ³•ï¼šAdapterã€Prefix-Tuningã€Prompt Tuning
â”‚
â”œâ”€â”€ å·¥ç¨‹å®è·µï¼ˆç¬¬ä¸‰èŠ‚ï¼‰
â”‚   â”œâ”€â”€ ç¯å¢ƒæ­å»ºï¼ˆtorch + transformers + peft + bitsandbytesï¼‰
â”‚   â”œâ”€â”€ æ•°æ®å‡†å¤‡ï¼ˆInstruction-Outputæ ¼å¼ + Tokenizationï¼‰
â”‚   â”œâ”€â”€ QLoRAé…ç½®ï¼ˆNF4é‡åŒ– + LoRA r=16ï¼‰
â”‚   â”œâ”€â”€ è®­ç»ƒæµç¨‹ï¼ˆSFTTrainer + paged_adamw_32bitï¼‰
â”‚   â””â”€â”€ æ•ˆæœéªŒè¯ï¼ˆæŒ‡ä»¤éµå¾ªç‡ï¼š35%â†’95%ï¼‰
â”‚
â”œâ”€â”€ æ·±åº¦ç†è§£ï¼ˆç¬¬å››èŠ‚ï¼‰
â”‚   â”œâ”€â”€ æŒ‡ä»¤æ•°æ®æ„å»º
â”‚   â”‚   â”œâ”€â”€ è´¨é‡è¯„ä¼°ï¼ˆå¤šæ ·æ€§ã€å‡†ç¡®æ€§ã€ä¸€è‡´æ€§ï¼‰
â”‚   â”‚   â”œâ”€â”€ Self-Instructï¼ˆç”¨GPT-4ç”Ÿæˆæ•°æ®ï¼‰
â”‚   â”‚   â””â”€â”€ æ•°æ®å¢å¼ºï¼ˆå›è¯‘ã€æ”¹å†™ï¼‰
â”‚   â”œâ”€â”€ ç¾éš¾æ€§é—å¿˜
â”‚   â”‚   â”œâ”€â”€ é—®é¢˜ï¼šæ–°ä»»åŠ¡è¦†ç›–æ—§çŸ¥è¯†
â”‚   â”‚   â”œâ”€â”€ ç­–ç•¥1ï¼šæ··åˆè®­ç»ƒæ•°æ®ï¼ˆ30%é€šç”¨æ•°æ®ï¼‰
â”‚   â”‚   â””â”€â”€ ç­–ç•¥2ï¼šEWCæ­£åˆ™åŒ–ï¼ˆä¿æŠ¤é‡è¦å‚æ•°ï¼‰
â”‚   â”œâ”€â”€ å¤šä»»åŠ¡å¾®è°ƒ
â”‚   â”‚   â”œâ”€â”€ ä»»åŠ¡æ ‡è¯†ç¬¦ï¼ˆTask Prefixï¼‰
â”‚   â”‚   â””â”€â”€ å¤šé€‚é…å™¨æ¶æ„ï¼ˆTask-Specific LoRAï¼‰
â”‚   â””â”€â”€ æŒç»­å­¦ä¹ 
â”‚       â”œâ”€â”€ æ¸è¿›å¼LoRAï¼ˆæ–°ä»»åŠ¡æ–°å±‚ï¼Œæ—§å±‚å†»ç»“ï¼‰
â”‚       â””â”€â”€ çŸ¥è¯†è’¸é¦ï¼ˆteacherå¼•å¯¼studentï¼‰
â”‚
â””â”€â”€ æ¨¡å‹åˆå¹¶ï¼ˆç¬¬äº”èŠ‚ï¼‰
    â”œâ”€â”€ çº¿æ€§æ’å€¼ï¼šÎ¸ = wâ‚Î¸â‚ + wâ‚‚Î¸â‚‚
    â”œâ”€â”€ SLERPï¼šçƒé¢æ’å€¼ï¼Œä¿æŒæ¨¡é•¿
    â”œâ”€â”€ TIESï¼šTrim + Elect + Mergeï¼ˆè§£å†³å†²çªï¼‰
    â”œâ”€â”€ DAREï¼šéšæœºä¸¢å¼ƒ + é‡ç¼©æ”¾
    â””â”€â”€ Task Arithmeticï¼šä»»åŠ¡å‘é‡åŠ å‡è¿ç®—
```

---

#### æ ¸å¿ƒå…¬å¼é€ŸæŸ¥

| æ¦‚å¿µ | å…¬å¼ | è¯´æ˜ |
|-----|------|------|
| **SFTæŸå¤±** | `L = -log P(y|x; Î¸)` | äº¤å‰ç†µæŸå¤± |
| **LoRA** | `h = Wx + BAx` | ä½ç§©åˆ†è§£ï¼Œrâ‰ªd |
| **ç¼©æ”¾å› å­** | `Î±/r` | é€šå¸¸Î±=2r |
| **QLoRA** | `W_q = Quantize(W, 4bit)` | NF4é‡åŒ– |
| **DoRA** | `W = mÂ·(W+BA)/\|\|W+BA\|\|` | å¹…åº¦-æ–¹å‘åˆ†è§£ |
| **EWCæŸå¤±** | `L_EWC = Î»/2Â·Î£ F(Î¸-Î¸*)Â²` | Fisherä¿¡æ¯åŠ æƒ |
| **SLERP** | `sin((1-t)Î¸)Â·vâ‚/sin(Î¸) + ...` | çƒé¢æ’å€¼ |
| **ä»»åŠ¡å‘é‡** | `Ï„ = Î¸_ft - Î¸_base` | Task Arithmetic |

---

#### å…³é”®æ•°æ®å¯¹æ¯”

**LoRAå®¶æ—æ€§èƒ½å¯¹æ¯”**ï¼ˆLLaMA-7Bï¼ŒGSM8Kæ•°å­¦æ¨ç†ä»»åŠ¡ï¼‰ï¼š

| æ–¹æ³• | å¯è®­ç»ƒå‚æ•° | æ˜¾å­˜å ç”¨ | å‡†ç¡®ç‡ | è®­ç»ƒæ—¶é—´ |
|-----|-----------|---------|-------|---------|
| å…¨é‡å¾®è°ƒ | 7.0B (100%) | 88GB | 52.3% | 48å°æ—¶ |
| LoRA r=8 | 4.2M (0.06%) | 16GB | 51.8% | 12å°æ—¶ |
| QLoRA r=8 | 4.2M (0.06%) | 3.6GB | 51.5% | 14å°æ—¶ |
| DoRA r=8 | 4.2M (0.06%) | 16GB | 53.1% | 15å°æ—¶ |
| AdaLoRA | 3.8M (0.05%) | 18GB | 52.0% | 16å°æ—¶ |

**æ¨¡å‹åˆå¹¶æ€§èƒ½å¯¹æ¯”**ï¼ˆ3ä¸ª7Bæ¨¡å‹åˆå¹¶ï¼‰ï¼š

| æ–¹æ³• | å¹³å‡å‡†ç¡®ç‡ | åˆå¹¶æ—¶é—´ | æœ€ä½³åœºæ™¯ |
|-----|-----------|---------|---------|
| çº¿æ€§æ’å€¼ | 78.5% | 5åˆ†é’Ÿ | ç›¸ä¼¼ä»»åŠ¡ |
| SLERP | 81.2% | 8åˆ†é’Ÿ | ä»»åŠ¡å·®å¼‚å¤§ |
| TIES | 85.3% | 15åˆ†é’Ÿ | æœ‰å†²çª |
| DARE | 84.1% | 12åˆ†é’Ÿ | éœ€é²æ£’æ€§ |
| Task Arithmetic | 86.7% | 10åˆ†é’Ÿ | çµæ´»è°ƒæ•´ |

---

#### å®æˆ˜å†³ç­–æ ‘

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å¼€å§‹å¾®è°ƒé¡¹ç›®    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ æ˜¾å­˜å……è¶³ï¼Ÿ  â”‚
   â””â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”˜
     â”‚ å¦      â”‚ æ˜¯
     â–¼         â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚QLoRA â”‚  â”‚ LoRA/DoRAâ”‚
  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚         â”‚
     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
          â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ æ•°æ®è´¨é‡æ£€æŸ¥ â”‚
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ å¤šæ ·æ€§<80%ï¼Ÿ     â”‚
   â””â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”˜
     â”‚ æ˜¯           â”‚ å¦
     â–¼              â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚Self-Instructâ”‚  â”‚ ç›´æ¥è®­ç»ƒâ”‚
  â”‚æˆ–æ•°æ®å¢å¼º  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ è®­ç»ƒåè¯„ä¼°   â”‚
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ é—å¿˜ç‡>30%ï¼Ÿ â”‚
   â””â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”˜
     â”‚ æ˜¯       â”‚ å¦
     â–¼          â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚æ··åˆæ•°æ®â”‚  â”‚ éƒ¨ç½²ä¸Šçº¿â”‚
  â”‚+EWC    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

#### æ€è€ƒç»ƒä¹ 

##### åŸºç¡€é¢˜

1. **è®¡ç®—é¢˜**ï¼šLLaMA-13Bæ¨¡å‹ï¼ˆ13Bå‚æ•°ï¼‰ï¼Œä½¿ç”¨LoRA r=16å¾®è°ƒï¼Œç›®æ ‡æ¨¡å—ä¸º`q_proj, k_proj, v_proj, o_proj`ï¼ˆå…±4ä¸ªï¼‰ï¼Œéšè—ç»´åº¦d=5120ï¼Œè®¡ç®—å¯è®­ç»ƒå‚æ•°é‡å’Œå æ¯”ã€‚

2. **æ¦‚å¿µé¢˜**ï¼šè§£é‡Šä¸ºä»€ä¹ˆQLoRAå¯ä»¥ç”¨4-bité‡åŒ–æ¨¡å‹å´ä¿æŒæ€§èƒ½ï¼Ÿå…³é”®æŠ€æœ¯æ˜¯ä»€ä¹ˆï¼Ÿ

3. **é€‰æ‹©é¢˜**ï¼šä»¥ä¸‹å“ªç§åœºæ™¯æœ€é€‚åˆä½¿ç”¨Adapterè€ŒéLoRAï¼Ÿ
   - A. æ˜¾å­˜å—é™ï¼Œéœ€è¦æœ€å°å‚æ•°é‡
   - B. éœ€è¦é¢‘ç¹åˆ‡æ¢å¤šä¸ªä»»åŠ¡
   - C. è¿½æ±‚æœ€ä½³æ€§èƒ½
   - D. ä»¥ä¸Šéƒ½ä¸æ˜¯

##### è¿›é˜¶é¢˜

4. **è®¾è®¡é¢˜**ï¼šä½ æœ‰3ä¸ªå¾®è°ƒæ¨¡å‹ï¼ˆåŒ»ç–—é—®ç­”ã€æ³•å¾‹å’¨è¯¢ã€é‡‘èåˆ†æï¼‰ï¼Œç°åœ¨éœ€è¦åˆå¹¶å®ƒä»¬ï¼Œä½†å¸Œæœ›åŒ»ç–—èƒ½åŠ›å 60%ï¼Œæ³•å¾‹20%ï¼Œé‡‘è20%ã€‚è¯·è®¾è®¡åˆå¹¶æ–¹æ¡ˆï¼ŒåŒ…æ‹¬ï¼š
   - é€‰æ‹©å“ªç§åˆå¹¶æ–¹æ³•ï¼Ÿ
   - å¦‚ä½•è®¾ç½®å‚æ•°ï¼Ÿ
   - å¦‚ä½•éªŒè¯åˆå¹¶æ•ˆæœï¼Ÿ

5. **è°ƒè¯•é¢˜**ï¼šå¾®è°ƒåæ¨¡å‹åœ¨è®­ç»ƒé›†ä¸Šè¡¨ç°è‰¯å¥½ï¼ˆ95%å‡†ç¡®ç‡ï¼‰ï¼Œä½†åœ¨æµ‹è¯•é›†ä¸Šåªæœ‰65%ï¼Œå¯èƒ½çš„åŸå› å’Œè§£å†³æ–¹æ¡ˆæ˜¯ä»€ä¹ˆï¼Ÿ

6. **ä¼˜åŒ–é¢˜**ï¼šå½“å‰å¾®è°ƒæµç¨‹ï¼š1000æ ·æœ¬ï¼Œ3è½®è®­ç»ƒï¼Œbatch_size=4ï¼Œæ¢¯åº¦ç´¯ç§¯=4ï¼Œå­¦ä¹ ç‡2e-4ï¼Œè®­ç»ƒæ—¶é—´8å°æ—¶ã€‚å¦‚ä½•åœ¨ä¿æŒæ€§èƒ½çš„å‰æä¸‹ç¼©çŸ­åˆ°2å°æ—¶ï¼Ÿ

##### å®æˆ˜é¢˜

7. **å®Œæ•´é¡¹ç›®**ï¼šè®¾è®¡ä¸€ä¸ªæŒç»­å­¦ä¹ ç³»ç»Ÿï¼Œè¦æ±‚ï¼š
   - æ¨¡å‹æ¯å‘¨å­¦ä¹ 1ä¸ªæ–°ä»»åŠ¡
   - ä¿ç•™æ‰€æœ‰å†å²ä»»åŠ¡æ€§èƒ½ï¼ˆé—å¿˜ç‡<10%ï¼‰
   - æ€»å‚æ•°å¢é•¿<20%
   - ç»™å‡ºæŠ€æœ¯æ–¹æ¡ˆå’ŒPythonä¼ªä»£ç 

8. **æ•°æ®å·¥ç¨‹**ï¼šä½ æœ‰100æ¡é«˜è´¨é‡æŒ‡ä»¤æ•°æ®ï¼Œéœ€è¦æ‰©å±•åˆ°1000æ¡ç”¨äºå¾®è°ƒã€‚è¯·è®¾è®¡æ•°æ®å¢å¼ºpipelineï¼ŒåŒ…æ‹¬ï¼š
   - ä½¿ç”¨å“ªäº›å¢å¼ºæŠ€æœ¯ï¼Ÿ
   - å¦‚ä½•ä¿è¯è´¨é‡ï¼Ÿ
   - å¦‚ä½•éªŒè¯å¤šæ ·æ€§ï¼Ÿ

---

#### å‚è€ƒç­”æ¡ˆï¼ˆéƒ¨åˆ†ï¼‰

**ç¬¬1é¢˜ç­”æ¡ˆ**ï¼š
```python
# LoRAå‚æ•°é‡è®¡ç®—
num_layers = 40  # LLaMA-13Bæœ‰40å±‚
d = 5120  # éšè—ç»´åº¦
r = 16  # LoRAç§©
num_modules = 4  # q, k, v, o

# æ¯å±‚å‚æ•°é‡ï¼š4ä¸ªæ¨¡å— Ã— (dÃ—r + rÃ—d)
params_per_layer = num_modules * (d * r + r * d)
# = 4 Ã— (5120Ã—16 + 16Ã—5120)
# = 4 Ã— 163,840 = 655,360

# æ€»å‚æ•°é‡
lora_params = num_layers * params_per_layer
# = 40 Ã— 655,360 = 26,214,400 â‰ˆ 26.2M

# åŸºåº§æ¨¡å‹å‚æ•°é‡
base_params = 13_000_000_000  # 13B

# å æ¯”
ratio = lora_params / base_params * 100
# = 26.2M / 13B â‰ˆ 0.20%

print(f"LoRAå¯è®­ç»ƒå‚æ•°: {lora_params:,} ({lora_params/1e6:.1f}M)")
print(f"å æ¯”: {ratio:.3f}%")
```

**ç¬¬2é¢˜ç­”æ¡ˆ**ï¼š

QLoRAæ€§èƒ½ä¿æŒçš„å…³é”®ï¼š
1. **NF4é‡åŒ–**ï¼šä¸“ä¸ºç¥ç»ç½‘ç»œæƒé‡è®¾è®¡çš„4-bitæ ¼å¼ï¼Œæ¯”FP4æ›´é€‚åˆæ­£æ€åˆ†å¸ƒ
2. **åŒé‡é‡åŒ–**ï¼šé‡åŒ–å¸¸æ•°ä¹Ÿè¢«é‡åŒ–ï¼ŒèŠ‚çœé¢å¤–0.5GB/7B
3. **åˆ†é¡µä¼˜åŒ–å™¨**ï¼šé¿å…æ˜¾å­˜å³°å€¼
4. **LoRAé«˜ç²¾åº¦è®¡ç®—**ï¼šè™½ç„¶åŸºåº§æ¨¡å‹4-bitï¼Œä½†LoRAå‚æ•°ç”¨BF16è®¡ç®—

**ç¬¬4é¢˜ç­”æ¡ˆ**ï¼š

```python
# æ–¹æ¡ˆ1ï¼šTask Arithmeticï¼ˆæ¨èï¼‰
from model_merger import TaskArithmeticMerger

merger = TaskArithmeticMerger()

# è®¡ç®—ä»»åŠ¡å‘é‡
medical_vec = merger.compute_task_vector("base", "medical_model")
legal_vec = merger.compute_task_vector("base", "legal_model")
finance_vec = merger.compute_task_vector("base", "finance_model")

# æŒ‰æƒé‡åˆå¹¶
merged = merger.add_task_vectors(
    base_model_path="base",
    task_vectors=[medical_vec, legal_vec, finance_vec],
    coefficients=[0.6, 0.2, 0.2],  # 60%, 20%, 20%
    output_path="./merged_model"
)

# éªŒè¯ï¼šåœ¨æ¯ä¸ªä»»åŠ¡çš„æµ‹è¯•é›†ä¸Šè¯„ä¼°
for task_name, test_data in [("åŒ»ç–—", med_test), ("æ³•å¾‹", law_test), ("é‡‘è", fin_test)]:
    acc = evaluate(merged, test_data)
    print(f"{task_name}å‡†ç¡®ç‡: {acc*100:.1f}%")
```

---

#### æ¨èé˜…è¯»

**ç»å…¸è®ºæ–‡**ï¼š
1. LoRA: Low-Rank Adaptation of Large Language Models (Hu et al., 2021)
2. QLoRA: Efficient Finetuning of Quantized LLMs (Dettmers et al., 2023)
3. DoRA: Weight-Decomposed Low-Rank Adaptation (Liu et al., 2024)
4. Self-Instruct: Aligning Language Models with Self-Generated Instructions (Wang et al., 2022)
5. Task Arithmetic: Editing Models via Task Vectors (Ilharco et al., 2023)

**å¼€æºé¡¹ç›®**ï¼š
- Hugging Face PEFT: https://github.com/huggingface/peft
- LLaMA-Factory: https://github.com/hiyouga/LLaMA-Factory
- Axolotl: https://github.com/OpenAccess-AI-Collective/axolotl

**åœ¨çº¿èµ„æº**ï¼š
- Hugging Faceå¾®è°ƒæ•™ç¨‹ï¼šhttps://huggingface.co/docs/transformers/training
- LoRAè®ºæ–‡è§£è¯»ï¼šhttps://arxiv.org/abs/2106.09685

---

#### ä¸‹ä¸€ç« é¢„å‘Š

ç¬¬2ç« ã€Šä¸äººç±»å¯¹é½ï¼šåå¥½ä¼˜åŒ–ã€‹å°†è®²è§£ï¼š

- RLHFå®Œæ•´æµç¨‹ï¼ˆReward Model + PPOï¼‰
- DPOï¼šæ— éœ€RLçš„åå¥½å¯¹é½
- ORPOã€KTOç­‰æœ€æ–°æ–¹æ³•
- å¦‚ä½•æ„å»ºåå¥½æ•°æ®é›†
- å®æˆ˜ï¼šä»SFTåˆ°RLHFçš„å®Œæ•´pipeline

**æ ¸å¿ƒé—®é¢˜**ï¼šå¾®è°ƒè®©æ¨¡å‹å­¦ä¼šä»»åŠ¡ï¼Œä½†å¦‚ä½•è®©å®ƒè¾“å‡ºæ›´ç¬¦åˆäººç±»åå¥½çš„å†…å®¹ï¼Ÿ

---

**ç¬¬1ç« å®Œç»“**

ä½ å·²ç»æŒæ¡äº†ä»é›¶å¾®è°ƒå¤§æ¨¡å‹çš„å®Œæ•´æŠ€èƒ½é“¾ï¼š
- âœ… ç†è®ºåŸºç¡€ï¼ˆLoRAåŸç†ã€ç¾éš¾æ€§é—å¿˜ï¼‰
- âœ… å·¥ç¨‹å®è·µï¼ˆQLoRAè®­ç»ƒã€æ•°æ®æ„å»ºï¼‰
- âœ… é«˜çº§æŠ€æœ¯ï¼ˆå¤šä»»åŠ¡å­¦ä¹ ã€æ¨¡å‹åˆå¹¶ï¼‰

ç°åœ¨ï¼Œä½ å¯ä»¥ï¼š
1. ç”¨16GBæ˜¾å­˜å¾®è°ƒ70Bæ¨¡å‹
2. æ„å»ºæŒç»­å­¦ä¹ ç³»ç»Ÿ
3. åˆå¹¶å¤šä¸ªä¸“å®¶æ¨¡å‹
4. é¿å…90%çš„å¸¸è§é™·é˜±

**ç»§ç»­å‰è¿›ï¼Œæ¢ç´¢åå¥½å¯¹é½çš„å¥¥ç§˜ï¼**

